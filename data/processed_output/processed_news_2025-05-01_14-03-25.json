[
    {
        "title": "🤡什么鬼？两行代码就能适应任何屏幕？",
        "url": "https://juejin.cn/post/7497895954101403688",
        "source": "juejin",
        "hot": 6570,
        "time": "",
        "timestamp": 1745810808000,
        "extracted_time": "2025-04-28T03:26:48+00:00",
        "content": "你可能想不到，只用两行 CSS，就能让你的卡片、图片、内容块自动适应各种屏幕宽度，彻底摆脱复杂的媒体查询！\n秘诀就是 CSS Grid 的 auto-fill\n和 auto-fit\n。\n马上教你用！✨\n🧩 基础概念\n假设你有这样一个需求：\n- 一排展示很多卡片\n- 每个卡片最小宽度 200px，剩余空间平均分配\n- 屏幕变窄时自动换行\n只需在父元素加两行 CSS 就能实现：\n/* 父元素 */\n.grid {\ndisplay: grid;\ngrid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n}\n/* 子元素 */\n.item {\nheight: 200px;\nbackground-color: rgb(141, 141, 255);\nborder-radius: 10px;\n}\n下面详细解释这行代码的意思：\ngrid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n这是 CSS Grid 布局里定义列宽的常用写法，逐个拆解如下：\n1. grid-template-columns\n- 作用：定义网格容器里有多少列，以及每列的宽度。\n2. repeat(auto-fit, ...)\nrepeat\n是个重复函数，表示后面的模式会被重复多次。auto-fit\n是一个特殊值，意思是：自动根据容器宽度，能放下几个就放几个，每列都用后面的规则。- 容器宽度足够时，能多放就多放，放不下就自动换行。\n3. minmax(200px, 1fr)\nminmax\n也是一个函数，意思是：每列最小200px，最大可以占1fr（剩余空间的平分）- 具体来说：\n- 当屏幕宽度很窄时，每列最小宽度是200px，再窄就会换行。\n- 当屏幕宽度变宽，卡片会自动拉伸，每列最大可以占据剩余空间的等分（\n1fr\n），让内容填满整行。\n4. 综合起来\n- 这行代码的意思就是：\n- 网格会自动生成多列，每列最小200px，最大可以平分一行的剩余空间。\n- 屏幕宽了就多显示几列，屏幕窄了就少显示几列，自动换行，自适应各种屏幕！\n- 不需要媒体查询，布局就能灵活响应。\n总结一句话：\ngrid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n让你的网格卡片最小200px，最大自动填满一行，自动适应任何屏幕，布局永远美观！\n这里还能填 auto-fill\n，和 auto-fit\n有啥区别？\n🥇 auto-fill 和 auto-fit 有啥区别？\n1. auto-fill\n🧱 尽可能多地填充列，即使没有内容也会“占位”\n- 会自动创建尽可能多的列轨道（包括空轨道），让网格尽量填满容器。\n- 适合需要“列对齐”或“固定网格数”的场景。\n2. auto-fit\n🧱 自动适应内容，能合并多余空列，不占位\n- 会自动“折叠”没有内容的轨道，让现有的内容尽量拉伸占满空间。\n- 适合希望内容自适应填满整行的场景。\n👀 直观对比\n假设容器宽度能容纳 10 个 200px 的卡片，但你只放了 5 个卡片：\nauto-fill\n会保留 10 列宽度，5 个卡片在前五列，后面五列是“空轨道”。auto-fit\n会折叠掉后面五列，让这 5 个卡片拉伸填满整行。\n👇 Demo 代码：\nauto-fill\nitem1\nitem2\nitem3\nitem4\nitem5\nauto-fit\nitem1\nitem2\nitem3\nitem4\nitem5\n.grid-fill {\ndisplay: grid;\ngrid-template-columns: repeat(auto-fill, minmax(200px, 1fr));\ngap: 16px;\nmargin-bottom: 40px;\n}\n.grid-fit {\ndisplay: grid;\ngrid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\ngap: 16px;\n}\n.grid-fill div {\nbackground: #08f700;\n}\n.grid-fit div {\nbackground: #f7b500;\n}\n.grid-fill div,\n.grid-fit div {\npadding: 24px;\nfont-size: 18px;\nborder-radius: 8px;\ntext-align: center;\n}\n兼容性\n🎯 什么时候用 auto-fill，什么时候用 auto-fit？\n-\n希望每行“有多少内容就撑多宽”，用\nauto-fit\n适合卡片式布局、相册、响应式按钮等。 -\n希望“固定列数/有占位”，用\nauto-fill\n比如表格、日历，或者你希望网格始终对齐，即使内容不满。\n📝 总结\n| 属性 | 空轨道 | 内容拉伸 | 适用场景 |\n|---|---|---|---|\n| auto-fill | 保留 | 否 | 固定列数、占位网格 |\n| auto-fit | 折叠 | 是 | 流式布局、拉伸填充 |\n🌟 小结\nauto-fill\n更像“占位”，auto-fit\n更像“自适应”- 推荐大部分响应式卡片用\nauto-fit\n- 善用\nminmax\n配合，让列宽自适应得更自然\n只需两行代码，你的页面就能优雅适配各种屏幕！\n觉得有用就点赞收藏吧，更多前端干货持续更新中！🚀✨",
        "summary": "新闻介绍了如何使用CSS Grid的auto-fit和auto-fill功能，仅用两行代码实现响应式布局，使卡片、图片等内容块自动适应不同屏幕宽度，无需复杂的媒体查询。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "腾讯 Kuikly 正式开源，了解一下这个基于 Kotlin 的全平台框架",
        "url": "https://juejin.cn/post/7497558282410115091",
        "source": "juejin",
        "hot": 5238,
        "time": "",
        "timestamp": 1745747846000,
        "extracted_time": "2025-04-27T09:57:26+00:00",
        "content": "在 3月的时候通过 《腾讯 TDF 即将开源 Kuikly 跨端框架，Kotlin 支持全平台》 我们大致知道了 Kuikly 的基本情况，Kuikly 是一个面向终端技术栈的跨端开发框架，完全基于kotlin语言开发，提供原生的性能和体验。\n按照官方的说法：\nKuikly\n是基于Kotlin Multiplatform 的 UI 与逻辑全面跨端综合解决方案，由腾讯大前端领域 Oteam（公司级）推出，目的在于提供一套一码多端、极致易用、动态灵活的全平台高性能开发框架。\n当然，虽然是全平台，但是目前暂时只开源了 Android 和 iOS，鸿蒙部分 5 月才开源，而 Web 和 小程序暂定是 Q2：\n官方表示 Kuikly 在腾讯内部本身已经支持了小程序 + H5 ，后续会分步骤开放，可能下一期还不会是所有小程序平台。\n那 Kuikly 如何实现跨平台？目前 Kuikly 主要是在 KMP 的基础上实现的自研 DSL 来构建 UI ，比如 iOS 平台的 UI 能力就是 UIkit ，而大家更熟悉的 Compose 支持，目前还处于开发过程中：\nSwiftUI 和 Compose 无法直接和 Kuikly 一起使用，但是 Kuikly 可以在 DSL 语法和 UI 组件属性对齐两者的写法，变成一个类 Compose 和 SwiftUI 的 UI 框架，也就是 Compose DSL 大概就是让 Kuikly 更像 Compose ，而不是直接适配 Compose ？\n那么大家可能会有疑问，既然借助了平台控件的能力，那它和 RN 有什么区别？\n首先 Kuikly 是直接从编译产物的角度实现跨平台，它的编译产物与原生一致，和 RN 是在运行时转换为原生控件不同，Kotlin 是直接编译为对应平台的原生代码，所以在运行时其实就类似原生 code 。\n那 Kuikly 又如何保证多端 UI 一致？答案是 Kuikly 实现了自己的一套「薄原生层」。\n首先在 Kotlin 层，Kuikly 将虚拟 Dom 方案优化为直调方案，这里 Kotlin View API 直调，避免 JSON 序列化/反序列化损耗，同时只维护一棵树，更轻量和O(1)同步UI更新：\n之后，Kuikly 使用“非常薄”的原生层，该原生层只暴露最基本和无逻辑的 UI 组件（原子组件），也就是 Kuikly 在 UI 上只用了最基本的原生层 UI ，真正的 UI 逻辑主要在共享的 Kotlin 代码来实现：\n通过将 UI 逻辑抽象到共享的 Kotlin 层，减少平台特定 UI 差异或行为差异的可能性，「薄原生层」充当一致的渲染目标，确保 Kotlin 定义的 UI 元素在所有平台上都以类似的方式显示。\n也就是说，Kuikly 虽然会依赖原生平台的控件，但是大部分控件的实现都已经被「提升」到 Kuikly 自己的 Kotlin 共享层，目前 Kuikly 实现了 60% UI 组件的纯 Kotlin 组合封装实现，不需要 Native 提供原子控件 ：\n最容易出现不一致的高阶组件都通过 Kotlin 实现，比如 List 列表控件，Kuikly 通过对齐 Native 的 List 内部实现原理，然后再用 Kotlin 重写一次，从而实现真正的高一致性 UI 组件跨平台实现。\n所以基于上面的内容，我们再来看 Kuikly UI 官方提供的结构图，是不是就清晰了很多：\n- Core 模块提供了统一的 UI 逻辑实现和 API 接口\n- Render 模块负责在 Android、iOS、HarmonyOS、H5 以及各种小程序等多个平台上实现 UI 的渲染 。\n另外在 Kuikly 领域，还有一套名为 KuiklyBase 服务，它是独立于 Kuikly UI 之外，为 Kuikly 提供基础设施支持，比如为 iOS、Android 和鸿蒙三大移动平台提供了统一的底层基建能力：\nKuiklyBase 强调在不同平台之间实现高性能的逻辑共享 ，它更像是 KMP 的进一步定制，KuiklyBase 兼容标准的 Kotlin Multiplatform 组件，允许复用成熟的 KMP 组件，比如有些业务各端都已经有 UI 层的实现，仅仅需要非 UI 的业务逻辑实现跨端，而通过 KuiklyBase 的基础设施，也可以满足这种场景的需求。\n另外 KuiklyBase 还提供了对 HarmonyOS 平台的全面支持，包括 KN HarmonyOS 编译、调试和构建能力。\n也就是 Kuikly 在鸿蒙有支持 Kotlin Native 高性能版本。\n同时，KuiklyBase 还提供了强大的多线程和协程能力，支持复杂业务逻辑的跨平台并行处理，以满足高性能场景的需求。\n并且在开发工具链方面，KuiklyBase 覆盖了从脚手架搭建到调试、构建、发布和监控的整个流程，特别是支持和 Bugly 和 Shiply 联动提供配套能力。\n最后，KuiklyBase 还内置了性能优化工具，并针对 HarmonyOS 和 iOS 提供了优化的调试体验 。\n目前使用 KuiklyBase 业务的团队：腾讯视频、浏览器、新闻、输入法、理财通····\n当然，这里需要注意的是， KuiklyBase 和 KuiklyUI 一起使用，某种情况下会存在场景冲突：\n- KuiklyUI 的 iOS 和鸿蒙动态化方案主要利用了 Kotlin/JS 编译成 js 产物，动态下发到宿主的js引擎去执行\n- KuiklyBase 利用 Kotlin/Native 编译成高性能的二进制产物执行，因此没有解耦 KuiklyBase 的 KMP 组件，在 iOS 和鸿蒙在动态化场景需要注意兼容\n所以，动态化决定了你优先使用哪个支持：\n-\n无动态化诉求场景: KuiklyBase + KuiklyUI = 完美\n-\n有动态化诉求场景: KuiklyBase 兼容 js 动态化方案还没完成，短期方案可利用 KuiklyUI 的 Module 方案来作为替代\n上面问题的核心其实是，KuiklyBase 组件因为是 KMP 组件，没有和平台做解耦，动态化时产物会运行在 js 环境中，由于 js 单线程，无法直接提供平台能力等的限制，所以决定了动态化部分不能直接使用多线程和平台能力。\n所以业务在开发过程中需要特别注意在调用平台 KMP 组件能力的时候，需要通过 Kuikly Module 方式进行解耦调用，避免直接依赖。\nKuikly\n作为一个跨端的 UI 框架, 他本身不具备调用平台 API 的能力, 但是Kuikly\n提供了一套Module\n机制，可以通过Module\n机制将平台的 API 暴露给Kuikly\n侧调用，同时Kuikly\n内置了一些通用的Module\n, 如果这些Module\n不满足 业务诉求时, 可以通过扩展原生 API 自定义Module\n, 将更多的宿主平台 API 暴露给Kuikly\n侧使用。\n在 KuiklyUI 内部，模块页面分为两种类型：可动态化类型(内置和动态灵活切换)和纯内置类型(只能内置) ：\n而可动态化类型部分：\n- 不可直接依赖平台能力\n- 不可使用多线程和协程\n- 不可依赖内置部分\n- 不可依赖使用到了平台能力或多线程协程等能力的 KMP 组件，如果无法避免需要使用相关能力，就需要前面提到额 Kuikly Module 进行解耦调用\n核心就是，动态化的只能是 JS 。\n最后，以下是 Kuikly 工程的项目结构说明：\n.\n├── core # 跨平台模块，实现各个平台响应式 UI、布局算法、Bridge 通信等核心能力\n├── src\n├── commanMain # 跨平台共享代码、定义跨平台接口\n├── androidMain # Android 平台实现代码 （aar）\n├── jvmMain # 泛 JVM 平台代码（不涉及 Android API）（jar）\n├── iosMain # iOS 平台实现代码（framework）\n├── core-render-android # android 平台的渲染器模块\n├── core-render-ios # iOS 平台的渲染器模块\n├── core-annotations # 注解模块，定义业务注解 @Page\n├── core-ksp # 注解处理模块，生成 Core 入口文件\n├── buildSrc # 编译脚本，用于编译、打包、分包产物相关脚本\n├── demo # DSL 示例代码\n├── androidApp # Android 宿主壳工程\n└── iosApp # iOS 宿主壳工程\n还有需要注意的是，之前的 Kuikly 的插件还不支持 K2 模式，所以如果你的 IDE 是 K2 模式，需要关闭 K2 才能支持插件：\n而一天之后，已经是 1.0.3 版本，此时 KuiklyTemplate 插件也支持了最新的 K2 模式：\n针对 Mac 用户还提供 kdoctor CI 支持：\n另外，Kuikly 未来也会兼容 Compose DSL ，但是大概率不会是原本的 Compose ，而是类 Compose 的代码组织方式。\n另外，在混合开发领域，在原有 App 集成 Kuikly ，可以把它简单当作如系统 webview 的概念来使用，但是如果在原生列表中嵌入 Kuikly view，目前会因为 Kuikly 本身的异步机制，导致无法同原生列表其它卡片同时生存layout和view结果，造成显示上的不同步。\n可以看到，Kuikly 总得来说还是一个类 RN 框架，但是它又不像 RN 一样的运行时 OEM 原生控件，而是在编译成完成转化为原生代码，并且它抽象出了统一的 「薄原生层」，让大量高阶控件在共享的 Kotlin 层完成实现，只让少量 native 层提供原子组件能力，从而尽可能实现 UI 的多端统一，类似于把原生控件单做 “Canvas\" 效果使用。\n总的来说，Kuikly 既能实现接近原生的性能体验和原生的开发体验，又能提供良好的动态化能力，看起来还是不错的选择。\n最后，官方表示 Kuikly 对于 Android 的同学家基本没有学习成本，只要使用过响应式开发的都能上手，而对于 iOS 同学而已，大概就是需要熟悉一下 Kotlin 语法，不过 Kotlin 和 Swift 相近度挺高，所以上手也不会太困难。\n目前 Kuikly 已经在 QQ、QQ音乐、QQ浏览器、腾讯新闻、搜狗输入法、应用宝、全民K歌、酷狗音乐、酷我音乐、自选股、ima.copilot、微视等多款产品中使用，那么，你觉得你会愿意尝试 Kuikly 吗？",
        "summary": "腾讯开源了 Kuikly 跨平台开发框架，基于 Kotlin 实现，支持 Android、iOS 和鸿蒙，未来将扩展至 Web 和小程序。该框架通过自研 DSL 和薄原生层实现高性能、一致的 UI 跨平台开发。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "🔥 我的开源项目火了！竟被各个公众号转发",
        "url": "https://juejin.cn/post/7497183377655087158",
        "source": "juejin",
        "hot": 3168,
        "time": "",
        "timestamp": 1745725447000,
        "extracted_time": "2025-04-27T03:44:07+00:00",
        "content": "前言🌟\n两个月前我写了个摸鱼岛摸鱼网站，从 10 个小功能到现在 20～30个功能，少了不了摸鱼岛的用户的支持以及 pr ，大家的开源精神给我摸鱼岛加了很多助力，还被 DeepSeek 收录以及各个公众号转发，今天也是重新排版，带来摸鱼岛 2.0 的介绍文档，此项目开源，只希望获取各位的小小 star 🌟即是给我的最大鼓励。\n[!NOTE] 本项目为开源项目，使用者必须在网站标注作者名称以及指向本项目的链接。如果不想保留署名，必须首先获得授权。不得用于非法用途。\n[!NOTE]\n在线体验地址🔗\n最新版（域名 2025.09 过期）：fish.codebug.icu/ 稳定版：yucoder.cn/\n后端地址🌈：github.com/lhccong/fis…\n前端地址🏖️：github.com/lhccong/fis…\n[!WARNING] 私部署时记得修改后端接口地址路径指向。\n✨ 开源🌟一站式摸鱼网 ✨\n部署教程 · 目前现状 · 意见反馈 · 截图展示 · 在线演示 · 开源与贡献 · 相关项目 · 赞赏支持\n-\nDeepSeek\n-\n小红书\n- 微信公众号\n功能\n-\n支持多种数据源聚合：\n- [✅] 知乎热榜\n- [✅] 微博热榜\n- [✅] 虎扑步行街热榜\n- [✅] 编程导航热榜\n- [✅] CSDN 热榜\n- [✅] 掘金热榜\n- [✅] B 站热门\n- [✅] 抖音热搜\n- [✅] 网易云热歌榜（支持网站点击播放）\n- [✅] 什么值得买热榜\n- [✅] 待补充...\n-\n每日待办功能。\n-\n摸鱼聊天室：\n- [✅] 发送 emoji 表情包\n- [✅] 发送搜狗在线表情包\n- [✅] 支持网站链接解析\n- [✅] 支持 markdown 文本解析\n- [✅] 支持 AI 助手回答（接入硅基流动模型）\n- [✅] 头像框功能\n- [✅] 用户地理位置显示功能\n- [✅] 用户称号功能\n- [✅] 五子棋、象棋对战邀请功能\n- [✅] 积分红包🧧发送功能\n- [✅] 支持用户 CV 发送图片功能\n-\n摸鱼阅读：\n- [✅] 在线搜书功能\n- [✅] 小窗口观看功能\n- [✅] 支持自定义书源\n-\n小游戏：\n- [✅] 五子棋（人机/在线对战）\n- [✅] 象棋（人机/在线对战）\n- [✅] 2048\n-\n工具箱：\n- [✅] JSON 格式化\n- [✅] 文本比对\n- [✅] 聚合翻译\n- [✅] Git 提交格式生成\n- [✅] AI 智能体\n- [✅] AI 周报助手\n-\n头像框兑换功能。\n-\n其他：\n- [✅] 音乐播放器\n- [✅] 下班薪资计算器（放假倒计时）\n- [✅] 修改网站图标\n- [✅] 网站标题闪烁消息提醒\n- [✅] 摸鱼初始页\n截图展示\n信息聚合\n每日待办\n摸鱼室\n摸鱼阅读\n小游戏\n- 五子棋\n- 象棋\n- 2048\n工具箱\n- JSON 格式化工具\n- 文本比对\n头像框兑换\n目前现状\n- 各大公众号转发。\n-\n用户突破 1k 的个人网站。\n-\n最高峰实时在线人数达 80 +。\n部署教程\n后端\n-\n执行初始化 SQL create_table.sql\n-\n更改 MySQL 地址、Redis 地址、Minio 地址、邮箱发送配置\n-\nMaven 打包\n-\ndocker 部署\n-\ndockerfile 文件\nFROM openjdk:8 ENV workdir=/cong/fish COPY . ${workdir} WORKDIR ${workdir} EXPOSE 8123 CMD [\"java\",\"-jar\",\"-Duser.timezone=GMT+08\",\"fish-island-backend-0.0.1-SNAPSHOT.jar\"]\n-\n打包命令\ndocker build -f ./dockerfile -t fish . 启动命令：docker run -d -e TZ=CST -p 8123:8123 -p 8090:8090 --name \"fish\" fish:latest\n-\nnginx 配置\nserver { listen 80; listen [::]:80; server_name moyuapi.codebug.icu; rewrite ^(.*) https://$server_name$1 permanent; } server { listen 443 ssl; server_name moyuapi.codebug.icu; ssl_certificate /etc/nginx/ssl/cert.pem; ssl_certificate_key /etc/nginx/ssl/key.pem; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / { root /usr/share/nginx/fish; index index.html; try_files $uri $uri/ /index.html; } location /fish/ { proxy_pass http://fish:8123/; } # WebSocket代理配置，处理 wss:// 请求 location /ws/ { proxy_pass http://fish:8090/; # 后端 WebSocket 服务地址 proxy_http_version 1.1; # 使用 HTTP/1.1 协议，WebSocket 需要这个版本 proxy_set_header Upgrade $http_upgrade; # 必须设置这些头来支持 WebSocket 协议的升级 proxy_set_header Connection 'upgrade'; # 维持 WebSocket 连接 proxy_set_header Host $host; # 确保 Host 头部传递正确 proxy_cache_bypass $http_upgrade; # 禁用缓存 } location /sogou-api/ { proxy_pass https://pic.sogou.com/; proxy_set_header Host pic.sogou.com; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_ssl_server_name on; # 解决 CORS 问题 add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Methods \"GET, POST, OPTIONS\"; add_header Access-Control-Allow-Headers \"DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range\"; add_header Access-Control-Expose-Headers \"Content-Length,Content-Range\"; # 处理 OPTIONS 预检请求 if ($request_method = OPTIONS) { return 204; } } location /holiday/ { proxy_pass https://date.appworlds.cn/; # 保持目标 API 的 Host，避免返回默认网页 proxy_set_header Host date.appworlds.cn; # 伪装成浏览器，防止服务器根据 User-Agent 返回 HTML proxy_set_header User-Agent \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"; # 强制服务器返回 JSON，而不是 HTML proxy_set_header Accept \"application/json\"; # CORS 允许跨域 add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Methods \"GET, POST, OPTIONS\"; add_header Access-Control-Allow-Headers \"DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range\"; add_header Access-Control-Expose-Headers \"Content-Length,Content-Range\"; # 处理 OPTIONS 预检请求 if ($request_method = OPTIONS) { return 204; } } location /img-api/ { proxy_pass https://i.111666.best/; proxy_set_header Host pic.sogou.com; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_ssl_server_name on; # 解决 CORS 问题 add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Methods \"GET, POST, OPTIONS\"; add_header Access-Control-Allow-Headers \"DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range\"; add_header Access-Control-Expose-Headers \"Content-Length,Content-Range\"; # 处理 OPTIONS 预检请求 if ($request_method = OPTIONS) { return 204; } } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } }\n前端\n- 修改 src/constants/index.ts 的接口地址。\n- max build --打包命令。\n- 部署 dist 文件。\n开源与贡献\n项目支持者 🔥\n前端贡献者 🌟\n后端贡献者 🌟:\n📌 贡献方式\n如果你也有希望聚合的数据源不妨来参加一下贡献，将你的数据源爬取出来放入其中。\n1️⃣ 页面元素抓取\n📌 适用于：目标网站未提供 API，数据嵌入在 HTML 结构中。\n✅ 贡献要求\n-\n推荐使用：\nJsoup\n（Java）BeautifulSoup\n（Python）Cheerio\n（Node.js）\n-\n选择器精准：避免因页面结构变化导致抓取失败。\n-\n减少 HTTP 请求：优化抓取效率，避免重复请求。\n-\n遵守网站爬取规则（\nrobots.txt\n）。\n💡 示例代码\nDocument doc = Jsoup.connect(\"https://example.com\").get();\nString title = doc.select(\"h1.article-title\").text();\n2️⃣ 页面接口返回数据抓取\n📌 适用于：目标网站提供 API，可直接调用接口获取 JSON/XML 数据。\n✅ 贡献要求\n-\n推荐使用：\nHttpClient\n（Java）axios\n（Node.js）requests\n（Python）\n-\n分析 API 请求：确保请求参数完整（\nheaders\n、cookies\n、token\n）。 -\n减少不必要的请求：优化调用频率，避免触发反爬机制。\n-\n异常处理：确保代码稳定运行。\n💡 示例代码\nString apiUrl = \"https://api.example.com/data\";\nString response = HttpRequest.get(apiUrl).execute().body();\nJSONObject json = JSON.parseObject(response);\n🔗 数据源注册\n数据抓取完成后，需要注册数据源，以便系统能够正确使用。\n🚀 注册流程\n-\n添加数据源 Key：\n/src/main/java/com/cong/fishisland/model/enums/HotDataKeyEnum.java\n定义新的数据源 Key。 -\n更新数据源映射：\n/src/main/java/com/lhccong/fish/backend/config/DatabaseConfig.java\n文件中，添加新的数据源配置。\n-\n创建数据源类：\nsrc/main/java/com/cong/fishisland/datasource\n目录下，新建数据源类，继承DataSource\n，实现getHotPost\n方法。\n-\n实现数据获取逻辑：\n- 按照\nHotPostDataVO\n格式返回数据。 - 使用\n@Builder\n注解，确保数据能正确解析。\n- 按照\n💡 示例代码\nHotPostDataVO.builder()\n.title(title)\n.url(url)\n.followerCount(followerCount)\n.excerpt(excerpt)\n.build();\n🚀 贡献流程\n- Fork 仓库 ➜ 点击 GitHub 右上角\nFork\n按钮。 - 创建分支 ➜ 推荐使用有意义的分支名，如\nfeature/data-scraper-optimization\n。 - 提交代码 ➜ 确保代码可读性高，符合规范。\n- 提交 Pull Request（PR） ➜ 详细描述您的更改内容，并关联相关 issue（如有）。\n- 等待审核 ➜ 维护者会进行代码审核并合并。\n以上讲解如果对你有帮助，不妨给我的项目点个小小的 star 🌟，成为一下我的精神股东呢\n🎉 感谢您的贡献！\n您的每一份贡献都让 fish-island 变得更好！💪",
        "summary": "一位开发者开源了名为‘摸鱼岛’的网站，功能包括聚合多个平台热榜、摸鱼聊天室、小游戏、工具箱等，项目被多个公众号转发，用户量超过1000，支持部署和定制。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "产品：上传图片拖拽一下怎么了 ?",
        "url": "https://juejin.cn/post/7497597555347259443",
        "source": "juejin",
        "hot": 3096,
        "time": "",
        "timestamp": 1745738666000,
        "extracted_time": "2025-04-27T07:24:26+00:00",
        "content": "前戏\n一、需求背景：一个产品经理的执念 📌\n\"小X啊，这个商品详情页的图片要能拖动排序，就像手机相册那样丝滑！\"\n—— 来自产品经理的第7次需求变更\n作为前端炒粉，面对这个\"简单\"需求时，我望着Element Plus官方文档陷入了沉思 🤔。el-upload组件虽然能完美处理上传，但原生并不支持已上传图片的拖拽排序。于是，当然是选择满足他啦...\n一、需求背景\n言归歪传，在管理后台开发中，经常需要实现图片上传与排序功能。Element Plus的el-upload组件虽然提供了基础的图片上传功能，但原生并不支持已上传图片的拖拽排序。下面将基于el-upload组件，结合HTML5拖放API，实现图片上传后的拖拽排序的基本功能。\n二、实现效果\n- 上传后的图片支持拖拽交换位置\n- 实时预览拖拽后的排序效果\n三、核心实现分析：魔法背后的秘密 🧙\n1. 模板结构解析🛠️\n2. 逻辑实现🎨\n拖拽二部曲 📦→📦\n🎯第一步：拖拽开始事件处理：dragstart\n- 获取当前拖拽项的索引\n- 将索引存入数据传输对象\nconst handleDragStart = (event, file, type: string) => {\n// 图片列表\nconst imgList = userInfo.picturePc;\nconst index = imgList.findIndex(element => element === file);\nevent.dataTransfer.setData('index', index.toString());\n}\n🎯第二步：拖拽释放事件处理：handleDrop\n- 获取目标位置索引\n- 阻止默认行为\n- 获取拖拽源索引\n- 创建数组副本（保证响应式更新）\n- 执行数组元素移动\n- 更新图片列表\nconst handleDrop = (event, file, type) => {\n// 获取目标位置索引\nconst index = imgList.findIndex(element => element === file);\n// 阻止默认行为\nevent.preventDefault();\n// 获取拖拽源索引\nconst draggedIndex = Number(event.dataTransfer.getData('index'));\n// 创建数组副本（保证响应式更新）\nconst updatedList = [...imgList];\n// 执行数组元素移动\nconst [draggedItem] = updatedList.splice(draggedIndex, 1);\nupdatedList.splice(index, 0, draggedItem);\n// 更新对应类型的图片列表\nuserInfo.picturePc = updatedList\n}\n四、关键点\n1. HTML5拖放API\ndraggable=\"true\"\n：使元素可拖拽@dragstart\n：拖拽开始时触发@drop\n：拖拽释放时触发@dragover.prevent\n：阻止默认拖拽行为dataTransfer\n：跨事件数据传输对象\n2. 数组操作技巧\n// 删除并插入元素的经典写法\nconst updatedList = [...originalList];\nconst [movedItem] = updatedList.splice(oldIndex, 1);\nupdatedList.splice(newIndex, 0, movedItem);\n3. 响应式更新\n通过创建数组副本并重新赋值，触发Vue的响应式更新：\nuserInfo.pictureMobile = updatedList\n五、踩坑日记：程序员的自我修养 📖\n🚧 坑1：幽灵图片问题\n现象：拖拽时出现半透明残影\n解法：给拖拽元素添加CSS样式\n.dragging-item {\nopacity: 0.5;\ntransform: rotate(3deg);\n}\n🚧 坑2：移动端兼容性\n现象：手机滑动触发页面滚动\n解法：添加touch-action样式\n.mobile-container {\ntouch-action: none;\n}\n六、完整实现流程\n- 🎯 初始化el-upload组件，禁用自动上传\n- ✨ 通过file-list绑定图片数据源\n- 🔮 自定义文件项模板，添加拖拽事件\n- ⚡ 实现拖拽开始时的索引记录\n- 🌈 处理拖拽释放时的元素交换）\n- 🧪更新响应式数据触发视图刷新\n七、总结\n通过结合el-upload的文件管理能力和HTML5原生拖放API，简单实现了直观的图片拖拽排序功能。\n这种方案具有以下优势：\n| 优势 | 说明 |\n|---|---|\n| 轻量级 | 无需额外依赖库 |\n| 高兼容 | 基于原生API实现 |\n| 易扩展 | 支持多场景类型参数 |",
        "summary": "文章介绍如何在Element Plus的el-upload组件中，通过HTML5拖放API实现图片上传后的拖拽排序功能，包括拖拽事件处理和数组操作技巧。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "⚡⚡⚡尤雨溪宣布开发 Vite Devtools，这两个很哇塞 🚀 Vite 的插件，你一定要知道！",
        "url": "https://juejin.cn/post/7498258715231354906",
        "source": "juejin",
        "hot": 2097,
        "time": "",
        "timestamp": 1745858604000,
        "extracted_time": "2025-04-28T16:43:24+00:00",
        "content": "前言\n尤雨溪团队月初宣布, VoidZero\n团队以及 NuxtLabs\n合作开发全新的 Vite DevTools。\n文章链接：voidzero.dev/posts/voidz…\n未来 Vite DevTools\n将支持插件管道可视化、打包分析和性能优化建议等功能。\n在 Vite DevTools\n问世之前，我们暂时可以使用下面的两个插件替代一段时间！\n往期精彩推荐\n- 🚀🚀🚀 神了！RedwoodJS 轻松碾压 NextJS，成了我的最爱❤️\n- 🚀🚀🚀 2025 年了，我不允许你还不知道 vite-plugin-pwa\n- 🚀 REST API 还是 ✈️ GraphQL ❓\n- 更多精彩文章欢迎关注我的公众号：萌萌哒草头将军\n正文\nSonda 插件\n功能\nSonda\n是一款用于分析和可视化 Vite\n构建产物的开源工具。它会在每次构建后生成交互式报告，展示打包文件的体积分布（如 Treemap\n图）、依赖关系树、各模块占用空间等信息，帮助开发者快速定位体积异常或性能瓶颈。\n适用场景\n当项目构建完成后，需要对输出文件大小和依赖结构进行分析时，可使用 Sonda\n。它特别适合用于性能优化、验证代码拆分效果或查找冗余依赖等场景。\n安装与使用\n首先安装 Sonda 插件：\nnpm install sonda --save-dev\n然后在 vite.config.js\n中配置插件并启用 source map：\nimport { defineConfig } from 'vite';\nimport Sonda from 'sonda/vite';\nexport default defineConfig({\nbuild: {\nsourcemap: true,\n},\nplugins: [ Sonda() ],\n});\n配置完成后，每次执行构建命令，Sonda\n会在输出目录中生成可交互的分析报告。开发者可通过浏览器查看详细的打包体积和依赖信息。\nvite-plugin-inspect 插件\n功能\nvite-plugin-inspect\n可以在本地开发服务器上开启调试页面，展示 Vite 插件的调用链和模块处理的中间状态。使用该插件时，开发者可以实时查看每个模块经过不同插件处理后的变化，有助于调试构建过程、检查插件执行顺序或编写自定义插件时定位问题。\n值得一提的是，上期我们介绍的 vite-plugin-vue-devtool 就是使用的 vite-plugin-inspect\n，属于是被官方手编了！\n适用场景\n当对 Vite 构建输出不符合预期，或需要深入了解各插件如何转换代码时，可以启用该插件。例如排查某段代码为何未被某个插件处理，或分析插件执行时序等。\n安装与使用\n先执行安装命令：\nnpm install -D vite-plugin-inspect\n然后在 vite.config.js\n中引入并启用插件：\n// vite.config.js\nimport Inspect from 'vite-plugin-inspect';\nexport default {\nplugins: [ Inspect() ]\n}\n启动开发服务器后，打开浏览器访问 http://localhost:5173/__inspect/\n，即可查看插件处理流程界面，包括各模块的中间状态和插件变换过程。\n最后\n相信这两个插件可以在一定程度上替代一段时间 vite-devtool\n的功能了，也希望 它可以早日和大家见面！\n往期精彩推荐\n- 🚀🚀🚀 神了！RedwoodJS 轻松碾压 NextJS，成了我的最爱❤️\n- 🚀🚀🚀 2025 年了，我不允许你还不知道 vite-plugin-pwa\n- 🚀 REST API 还是 ✈️ GraphQL ❓\n- 更多精彩文章欢迎关注我的公众号：萌萌哒草头将军",
        "summary": "尤雨溪团队宣布与 VoidZero 和 NuxtLabs 合作开发 Vite DevTools，支持插件管道可视化、打包分析等功能。目前可使用 Sonda 和 vite-plugin-inspect 插件作为替代。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "别说了别说了 ，Trae 已经在不停优化迭代了",
        "url": "https://juejin.cn/post/7497821254205456410",
        "source": "juejin",
        "hot": 1602,
        "time": "",
        "timestamp": 1745764997000,
        "extracted_time": "2025-04-27T14:43:17+00:00",
        "content": "我正在参加Trae「超级体验官」创意实践征文，本文所使用的 Trae 免费下载链接：www.trae.com.cn/?utm_source…\n一. 前言\n上次简单体验了一把才发布的 Trae ，上一次尝试用 AI 做了一个小工具 ，有好有坏 ，但是整体效果一般。\n但是 Trae 确实是在不断迭代的 ， 感觉到应该是听取了很多的建议 ，这一次再来尝试一下 ，更新后的 Trae 是否能快速帮我完成项目的搭建和开发流程。\n二. 新功能整理\n本次大更新后 ，Trae 多了一些重点的功能 ：\nAI Agent (智能体) ：能够处理更复杂的业务需求\nAI Agent 扩展了传统的 AI 工具用法 ，在任务复杂度 ， 自主性和灵活性等方面都有极大的提升。\n举个例子 ，常规 AI 的功能类似于 \"高级百科搜索\" ，而智能体的定位是 ：\"智能助理\" 。 Agent 可以实现类似于写代码 ，发邮件 ，API 调用 等更加复杂的功能 ，提高生产力。\n智能体一般体现在四大优势 ： 规划 + 记忆 + 工具调用 + 行动。\n- 规划 = 拆分任务+流转把控+动态决策+推理链路\n- 行动 = 选择并执行外部操作+反馈评估+实时修正+直至任务闭环\n- PS ： 说的很玄乎 ，使用上是这样体现的 ：\nMCP : 提供外部统一扩展 ，可以通过 MCP 调用外部工具的现有功能\n为了方便理解 ，先简单的阐述一下 MCP 的作用 ：\nMCP（Model Context Protocol）就是给AI模型提供的“万能适配器”（类似USB-C接口），让AI模型和各种各样的外部工具、数据库、文件系统等用同一种“语言”交流\nTare 可以在应用市场中直接添加 ，或者连接特定智能体 ，现在主要有这些 ：\n- Puppeteer/Browserbase：浏览器自动化操作、网页抓取\n- PostgreSQL / SQLite / MySQL： 数据库交互\n- Figma : 连接图像界面\n- GitLab / Git ： 读取 Git 文件\n类似的工具还有很多 ，这里就不赘述了。 除了使用现成的应用 ，还可以自己创建 MCP Server ，作为远端工具提供支持。\n上下文 ： 能够更好的理解业务和上下文的关系\n- 通过这种圈定上下文的方式 ，内容可以更加准确\n三. 功能的具体体验\n3.1 体验一 ： 代码理解和生成的能力\n- 问题一 ： 让它参考一个页面 ，去生成相关的页面 ，提供了页面的元素\n- 问题二 ： 让他补充了页面的关联关系 ，让侧边栏加入新页面\n- 阶段总结 ：\n单看效果 ，页面要的元素都有了 ，但是没有去思考最终的布局效果 。 不过这个能理解 ，毕竟是基于一个成熟的开源脚手架 ，逻辑还是很复杂的 ，指望全部理解 ，那还是困难了一点\n3.2 体验二 ： 开源代码的整合能力\n提问 ： 开源项目元素整合\n给我准备一个新页面 ，里面需要整合 以下页面的元素 ：\n1. 视图 ViewInterface 里面的 TreeFrame\n2. 导航里面的 面包学\n3. 菜单和工具栏 里面的 命令栏 @Workspace\n总结 ：\n- 整体效果还是可以接受了 ，我需要的3个元素都准确找到了 ，也成功的加入到了新页面中\n- 格式上没有太大的问题 （有一部分原因是开源框架隔离做的很好 ，没有格式打架）\n代码效果 ：\n- 主要的元素都精准识别到了\n# coding:utf-8\nfrom PyQt6.QtCore import Qt\nfrom PyQt6.QtWidgets import QVBoxLayout, QWidget\nfrom qfluentwidgets import BreadcrumbBar, CommandBar, Action, FluentIcon\nfrom .gallery_interface import GalleryInterface\nfrom .view_interface import TreeFrame\nfrom ..common.translator import Translator\nclass IntegratedViewInterface(GalleryInterface):\n\"\"\" 集成视图界面，包含 TreeFrame、面包屑导航和命令栏 \"\"\"\ndef __init__(self, parent=None):\nt = Translator()\nsuper().__init__(\ntitle=t.tr('集成视图'),\nsubtitle=\"集成 Tree、面包屑和命令栏\",\nparent=parent\n)\nself.setObjectName('integratedViewInterface')\n# 主容器\nmainWidget = QWidget(self)\nmainLayout = QVBoxLayout(mainWidget)\nmainLayout.setContentsMargins(24, 24, 24, 24)\nmainLayout.setSpacing(18)\n# 1. 面包屑导航 SimpleCard\nbreadcrumb = BreadcrumbBar(self)\nitems = [self.tr(\"首页\"), self.tr(\"文档\"), self.tr(\"学习\"), self.tr(\"示例\")]\nfor i in items:\nbreadcrumb.addItem(i, i)\nself.addSimpleCard(self.tr(\"面包屑导航\"), breadcrumb)\n# 2. 命令栏 SimpleCard\ncommandBar = CommandBar(self)\ncommandBar.addActions([\nAction(FluentIcon.ADD, self.tr('添加')),\nAction(FluentIcon.EDIT, self.tr('编辑')),\nAction(FluentIcon.DELETE, self.tr('删除')),\nAction(FluentIcon.FOLDER, self.tr('刷新'))\n])\nself.addSimpleCard(self.tr(\"命令栏\"), commandBar)\n# 3. TreeFrame SimpleCard\ntreeFrame = TreeFrame(self)\nself.addSimpleCard(self.tr(\"树结构\"), treeFrame)\n# 示例卡片\nself.addExampleCard(\ntitle=self.tr('集成视图示例'),\nwidget=mainWidget,\nsourcePath='',\nstretch=1\n)\n四. 使用感受\n4.1 关于智能体 ：\n智能体在代码开发中还是很有作用的 ，他会把任务拆分成一个个更细的场景 ，从而让处理的结果更加精准。\n- 一句话生成的桌面有用 ，提供了将近6个文件 ，以及额外的处理\n4.2 关于 MCP ：\n现阶段的 MCP 还是偏向于工具 ，没有直接为代码提供能力 ，常见的比如帮你提交下代码 ，查个数据什么的 。 总体来说能协助开发的还是太少了 ，个人感觉有点鸡肋。\n但是有一些 MCP 还是有点作用的 ，比如 Brave search MCP 可以进行联网搜索， github 可以连接代码库 ，filesystem 等\n等后续功能更丰富了 ，应该有更好的使用场景。\n// S1 : 安装 filesystem MCP Server 到本地\nnpm install -g @modelcontextprotocol/server-filesystem\n// S2 : 启动 ，并且设置本地文件路径\nnpx -y @modelcontextprotocol/server-filesystem D:\\ai\\mcp\n// S3 : Trae 配置 MCP (ZH这里)\n{\n\"mcpServers\": {\n\"filesystem\": {\n\"command\": \"npx\",\n\"args\": [\n\"-y\",\n\"@modelcontextprotocol/server-filesystem\",\n\"D:\\\\ai\\\\mcp\"\n]\n}\n}\n}\n// S3 : 使用一下\n总结\n- 和上一次体验后 ，体验感有不少提升 ，至少不会让大家骂骂咧咧了 （GPT4.1 体验哦）\n- 新功能最有用的是上下文的管控 ，感觉到范围更精准了 ，不会内容漂移\n- 其他的功能 ，MCP 个人没找到好用的场景 ，对于开发没太大的提升 (\n也没深入用\n) - GPT4.1 高峰时候要排队 ，未来不确定会不会直接变成收费\n- 大范围的代码处理还是缺乏方向感 ，建议还是小区域的代码优化和生成\n总结一下 ：\n- 谈不上已经很好用了 ，但是一直在进步 ， 比上次感受要强很多\n- 高度依赖好的模型 ，模型越好 ，效果越好 。有条件的还是要使用上外版\n- 指望代替你的工作不现实 ，但是可以帮你加速你的工作效率 ，空余时间摸摸鱼\n最后的最后 ❤️❤️❤️👇👇👇\n- 👈 欢迎关注 ，超200篇优质文章，未来持续高质量输出 🎉🎉\n- 🔥🔥🔥 系列文章集合，高并发，源码应有尽有 👍👍\n- 走过路过不要错过 ，知识无价还不收钱 ❗❗",
        "summary": "文章介绍了Trae的最新更新，包括AI Agent功能的增强、MCP协议的引入以及对代码理解和生成能力的提升，展示了其在开发流程中的应用。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Cursor 最强竞争对手来了，专治复杂大项目，免费一个月",
        "url": "https://juejin.cn/post/7497885437966958604",
        "source": "juejin",
        "hot": 1548,
        "time": "",
        "timestamp": 1745821568000,
        "extracted_time": "2025-04-28T06:26:08+00:00",
        "content": "Augment Agent 发布后，国内的自媒体现在清一色都是上面的画风👆\n到处都是“再见 Cursor” 之类的言论👀\n什么？你还不知道发生了什么？看图👇\n实际上很多文章作者在此之前可能根本就没有听说过这个产品~\nAugment Code 其实早就存在了，它创立于 2022 年，由两位科技巨头前员工联合创办：曾在微软担任高级软件开发工程师的 Igor Ostrovsky 以及谷歌前人工智能研究员 Guy Gur-Ari。这家公司截止目前已完成了 2.7 亿美元融资，估值已攀升至近 9.77 亿美元。\n与 Cursor 相比，Augment Code 有两个明显的区别：\n- Augment Code 直接提供了 Vim Plugin 的 AI 编码产品，除此之外，还支持 Jetbrains、VS Code、GitHub 以及 Slack，你想要的它都有。\n- Cursor 是基于 Claude 模型开发的，而 Augment Code 一开始就自己训练模型，优势显而易见：只要模型能力有了大的突破，就一定能碾压 Cursor。\n4 月 3 号他们发布了 Augment Agent，专为大型代码库打造，具备 20 万 tokens 的超长上下文、持久记忆和深度工具集成。不过产品形态却不是一个全新的 IDE，而是作为 IDE 的插件。\n按照惯例，评分榜是一定要刷的，按照官方说法，Augment Agent 在 SWE-bench Verified 行业基准测试中已经拿到了第一名，超过了 Claude 3.7 Sonnet 和 o1 推理模型。\n先来看看它有哪些功能：\n深入骨髓的“代码库理解”\n它不像其他工具那样只看当前文件或者一点点上下文，而是会努力去学习和理解你的整个项目，包括代码结构、依赖关系、不同模块是怎么交互的等等。这样一来，它给出的建议、生成的代码，甚至是帮你重构，都会更有针对性，更贴合你项目的实际情况。\n🧩 持久记忆\nAugment Agent 会自动适应你的工作方式：\n- 学习你的编码风格\n- 记住之前的代码重构\n- 根据你的习惯和约定进行调整\n这个记忆会随着时间慢慢积累，形成自己的个人风格，无需在每个会话中重新引导。\n只要点击对话框这个位置，就可以看到持久化记忆内容了：\n⚙️ 完整开发工作流\n除了能无缝集成到 VS Code、JetBrains 这些主流 IDE 里，Augment Code 还能跟你常用的项目管理工具（比如 Jira、Linear）、文档工具（比如 Confluence、Notion）打通，让 AI 的能力更好地融入你的整个开发工作流。\n而且无需切换工具，即可完成从工单到代码再到 PR 的整个流程，只需要使用以下这些指令即可：\n@GitHub\n: 创建分支、提交代码、发起 PR@Linear\n: 问题检测与解决@Notion\n、@JIRA\n、@Confluence\n: 将上下文信息转化为实际代码\n🐛 可视化调试\n只需要拖入截图，Augment Agent 就能自动识别 UI 问题（CSS、布局、逻辑），并提供修复建议。\n🛡️ 版本控制\n每一步操作都会被记录，每一次编辑都可以撤销。\nAugment Agent 在执行操作前会创建检查点，让你在拥有完全控制权的同时，不会降低开发效率。\n总结一下，Augment Agent 的核心理念就是：要想真正帮到开发者，光会写代码还不够，必须得先深度理解你那庞大又复杂的代码库。\n再来看一下定价：\n专业版定价 30$ 每月，还有企业版，同时也支持免费版。不过好消息是：目前可以免费无限次使用。\n赶紧用起来！！！\nAugment Code 试用\n既然 Augment 可以作为 VS Code 和 Jetbrains 的插件，而 Sealos DevBox 也是支持 VS Code 和 Jetbrains 远程开发的，嘿嘿，那我就拿 DevBox 远程开发环境来开发测试吧，即用即开，对本地环境不会有丝毫的污染。\n至于其他好处嘛，看图👇\n安装 Augment 插件\n以 VS Code 为例，我们来安装插件：\n安装完成后需要登录，登录之后就可以使用了。\n创建 DevBox 开发环境\n在浏览器中打开 Sealos Cloud，在控制台中找到并点击 \"DevBox\" 图标，进入 DevBox 界面，点击\"新建项目\"按钮，进入项目配置页面。\n在\"运行环境\"配置区域：\n- 选择适合您项目的开发框架或编程语言。\n- 使用资源配置滑块，根据项目需求设置 CPU 核心数和内存大小。\n在\"网络配置\"区域，您需要进行以下设置：\n- 端口配置： - 设置应用程序的主要访问端口。 - 如需添加更多端口，可点击\"添加端口\"进行配置。\n- 公网访问设置： - 开启此选项后，外部用户可通过域名从公网访问您的应用。 - 默认关闭，根据需要开启。\n- 域名设置： - 系统默认提供一个 Sealos 子域名。 - 如需使用自定义域名，可点击\"自定义域名\"并按提示操作。\n确认所有配置无误后，点击\"新建项目\"按钮完成创建。\n点击创建后，Sealos DevBox 将自动完成以下配置：\n- 按照设定分配计算资源（CPU、内存）。\n- 配置选定的开发环境（框架/语言环境）。\n- 设置网络参数和域名解析。\n配置完成后，就可以使用 VS Code 连接开发了。\nVS Code 连接开发环境\n在 DevBox 的项目列表中找到您刚刚创建的项目，在\"操作\"列中，点击 VS Code 图标。\n接下来系统会自动在您的本地计算机上启动 VS Code，然后 VS Code 会弹出提示窗口，引导您安装 DevBox 插件：\n安装完成后，VS Code 将会自动与您的 DevBox 开发环境建立远程连接。\n安装 Augment 插件到远程环境\n远程开发环境中无法使用本地安装的 Augment 插件，所以我们需要在远程开发环境独立安装 Augment 插件：\n安装完成后就可以使用了：\n问题 1：Sealos DevBox 原理\nDevBox 挺有意思的，就是不知道它是怎么实现的，刚好 Sealos 是完全开源的嘛，给 Augment 扫描一下问问看👀\n在 VS Code 中打开终端，先把当前项目根目录下所有文件都删了，然后再克隆 Sealos 仓库到当前目录：\nrm -rf {*,.*}\ngit clone https://github.com/labring/sealos .\n开始提问！\n整体架构解释的没啥问题。\n再来看看后端实现部分：\n这里提到了 3 个核心的自定义资源：\nDevbox\n：定义了开发环境规格Runtime\n：定义了开发环境的运行时DevBoxRelease\n：用于管理 DevBox 的版本发布\n并且还给出了相应的核心字段和控制器实现，这不比我自己直接啃源码香？👍\n不止这些，后面还介绍了前端实现等等，我就不放图了。\n问题 2: Sealos DevBox 冷关机实现\n接下来我又问了 Sealos DevBox 的冷关机原理：\n它给我洋洋洒洒解释了一大堆，非常详细，还给出了具体的代码实现，太长了，我就截个片段吧：\n我们直接看最后总结部分：\n理解到位，冷关机除了会删除 Pod，还会删除对应的 Service 和 Ingress，这样关机之后就不会进行任何计费了，是不是还有同学不知道这个新操作呢？快去试试冷关机，能省一笔是一笔！\n为了便于理解，我还让它给我画了冷关机的详细交互图。\n这是它给出的冷关机过程中各组件之间的时序交互图：\n这是它给出的冷关机的核心流程和各个阶段：\n这是它给出的冷关机过程中各组件之间的数据流和交互关系：\n还有还有，它还给出了 DevBox 在冷关机过程中的状态转换图：\n你这。。我这。。哎呀，你看你。。。\n问题 3：做一个案例页面\n我让它帮我给 Sealos 官网新增一个案例页面，提示词非常的朴素，没有什么花里胡哨的 prompt 技巧：\n我想新增一个 Case 页面，请参考这个产品的 Case 页面给我提供一些详细的设计方案：xxxxx\n它自己会主动去访问我提供的参考页面，然后开始实现我的需求。\n中间的 debug 过程我就不细说了，最终的成品是这样的：\n现在这个案例页面已经上线了。\n顺便说一句：我根本不懂前端\n（全文完）",
        "summary": "Augment Code 推出其 AI 编码工具 Augment Agent，专为大型代码库设计，支持多种开发工具，具备持久记忆和深度理解项目能力，目前提供免费试用。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "深夜突袭，阿里 Qwen3 登顶全球开源王座！暴击 DeepSeek-R1，2 小时狂揽 17k 星",
        "url": "https://juejin.cn/post/7498291170903375881",
        "source": "juejin",
        "hot": 1206,
        "time": "",
        "timestamp": 1745895992000,
        "extracted_time": "2025-04-29T03:06:32+00:00",
        "content": "【新智元导读】阿里 Qwen3 凌晨开源，正式登顶全球开源大模型王座！它的性能全面超越 DeepSeek-R1 和 OpenAI o1，采用 MoE 架构，总参数 235B，横扫各大基准。这次开源的 Qwen3 家族，8 款混合推理模型全部开源，免费商用。\n就在今天凌晨，备受全球期待的阿里新一代通义千问模型 Qwen3 开源！\n一经问世，它立刻登顶全球最强开源模型王座。\n它的参数量仅为 DeepSeek-R1 的 1/3，但成本大幅下降，性能全面超越 R1、OpenAI-o1 等全球顶尖模型。\nQwen3 是国内首个「混合推理模型」，「快思考」与「慢思考」集成进同一个模型，对简单需求可低算力「秒回」答案，对复杂问题可多步骤「深度思考」，大大节省算力消耗。\n它采用混合专家（MoE）架构，总参数量 235B，激活仅需 22B。\n它的预训练数据量达 36T ，并在后训练阶段多轮强化学习，将非思考模式无缝整合到思考模型中。\n一经诞生，Qwen3 立刻横扫各大基准。\n而且，性能大幅提升的同时，它的部署成本还大幅下降，仅需 4 张 H20 即可部署 Qwen3 满血版，显存占用仅为性能相近模型的 1/3！\n亮点总结：\n· 各种尺寸的稠密模型和混合专家（MoE）模型，包括 0.6B、1.7B、4B、8B、14B、32B 以及 30B-A3B 和 235B-A22B。\n· 能够在思考模式（用于复杂的逻辑推理、数学和编码）和非思考模式（用于高效的通用聊天）之间无缝切换，从而确保在各种场景中实现最佳性能。\n· 推理能力显著增强，在数学、代码生成和常识逻辑推理方面，超越了之前处于思考模式下的 QwQ 和处于非思考模式下的 Qwen2.5 instruct 模型。\n· 更符合人类偏好，擅长创意写作、角色扮演、多轮对话和指令遵循，从而提供更自然、引人入胜和更真实的对话体验。\n· 精通 AI 智能体能力，支持在思考和非思考模式下与外部工具的精确集成，并在复杂的基于智能体的任务中，在开源模型中实现了领先的性能。\n· 首次支持 119 种语言和方言，具有强大的多语言指令跟随和翻译能力。\n目前，Qwen 3 已同步上线魔搭社区、Hugging Face、GitHub，并可在线体验。\n全球开发者、研究机构和企业均可免费下载模型并商用，也可以通过阿里云百炼调用 Qwen3 的 API 服务。个人用户可立即通过通义 APP 直接体验 Qwen3，夸克也即将全线接入 Qwen3。\n在线体验：chat.qwen.ai/\n魔搭社区：modelscope.cn/collections…\nHugging Face：huggingface.co/collections…\nGitHub：github.com/QwenLM/Qwen…\n至此，阿里通义已开源 200 余个模型，全球下载量超 3 亿次，千问衍生模型数超 10 万个，彻底超越美国 Llama，成为全球第一开源模型！\nQwen 3 家族登场\n8 款「混合推理」模型全开源\n这次，阿里一口气开源了 8 款混合推理模型，包括 2 款 30B、235B 的 MoE 模型，以及 0.6B、1.7B、4B、8B、14B、32B 等 6 款稠密模型，均采用 Apache 2.0 许可。\n其中，每款模型均斩获同尺寸开源模型 SOTA。\nQwen3 的 30B 参数 MoE 模型实现了 10 倍以上的模型性能杠杆提升，仅激活 3B 就能媲美上代 Qwen2.5-32B 模型性能。\nQwen3 的稠密模型性能继续突破，一半的参数量可实现同样的高性能，如 32B 版本的 Qwen3 模型可跨级超越 Qwen2.5-72B 性能。\n同时，所有 Qwen3 模型都是混合推理模型，API 可按需设置「思考预算」（即预期最大深度思考的 tokens 数量），进行不同程度的思考，灵活满足 AI 应用和不同场景对性能和成本的多样需求。\n比如，4B 模型是手机端的绝佳尺寸；8B 可在电脑和汽车端侧丝滑部署应用；32B 最受企业大规模部署欢迎，有条件的开发者也可轻松上手。\n开源模型新王，刷新纪录\nQwen3 在推理、指令遵循、工具调用、多语言能力等方面均大幅增强，即创下所有国产模型及全球开源模型的性能新高——\n在奥数水平的 AIME25 测评中，Qwen3 斩获 81.5 分，刷新开源纪录。\n在考察代码能力的 LiveCodeBench 评测中，Qwen3 突破 70 分大关，表现甚至超过 Grok3。\n在评估模型人类偏好对齐的 ArenaHard 测评中，Qwen3 以 95.6 分超越了 OpenAI-o1 及 DeepSeek-R1。\n具体来说，旗舰模型 Qwen3-235B-A22B 与其他顶级模型（如 DeepSeek-R1、o1、o3-mini、Grok-3 和 Gemini-2.5-Pro）相比，在编码、数学、通用能力等各项基准测试中，成绩都相当亮眼。\n此外，小型混合专家模型 Qwen3-30B-A3B 虽然激活参数只有 QwQ-32B 的十分之一，但性能却更胜一筹。\n甚至是 Qwen3-4B 这样的小模型，也能媲美 Qwen2.5-72B-Instruct 的性能。\n经过微调的模型，如 Qwen3-30B-A3B，及其预训练版本（如 Qwen3-30B-A3B-Base），现在都可在 Hugging Face、ModelScope 和 Kaggle 等平台上找到。\n对于部署，阿里推荐使用 SGLang 和 vLLM 等框架。对于本地使用，强烈推荐 Ollama、LMStudio、MLX、llama.cpp 和 KTransformers 等工具。\n无论研究、开发还是生产环境，Qwen3 都可轻松集成到各种工作流程中。\n利好智能体 Agent 和大模型应用爆发\n可以说，Qwen3 为即将到来的智能体 Agent 和大模型应用爆发提供了更好的支持。\n在评估模型 Agent 能力的 BFCL 评测中，Qwen3 创下 70.8 的新高，超越 Gemini2.5-Pro、OpenAI-o1 等顶尖模型，这将大幅降低 Agent 调用工具的门槛。\n同时，Qwen3 原生支持 MCP 协议，并具备强大的工具调用能力，结合封装了工具调用模板和工具调用解析器的 Qwen-Agent 框架。\n这将大大降低编码复杂性，实现高效的手机及电脑 Agent 操作等任务。\n主要特点\n混合推理模式\nQwen3 模型引入了一种混合问题解决方式。它们支持两种模式：\n-\n思考模式：在该模式下，模型会逐步推理，然后给出答案。这适合需要深入思考的复杂问题。\n-\n非思考模式：在该模式下，模型会快速给出答案，适用于对速度要求较高的简单问题。\n这种灵活性，让用户可以根据任务的复杂程度，控制模型的推理过程。\n例如，难题可以通过扩展推理来解决，而简单的问题可以直接回答，而不会延迟。\n至关重要的是，这两种模式的结合，大大提高了模型稳定高效地控制推理资源的能力。\n如上所示，Qwen3 表现出可扩展且平滑的性能改进，这与分配的计算推理预算直接相关。\n这种设计使用户能够更轻松地配置特定于任务的预算，从而在成本效率和推理质量之间实现更优化的平衡。\n多语言支持\nQwen3 模型支持 119 种语言和方言。\n如此广泛的多语言能力，也意味着 Qwen 3 有极大潜力创建风靡全球的国际应用。\n更强大的智能体能力\n阿里对 Qwen3 模型进行了优化，以提高编码和智能体能力，并且还加强了对 MCP 的支持。\n下面这个示例，很好地展示了 Qwen3 是如何思考并与环境交互的。\n36 万亿 token，多阶段训练\n作为千问系列最强模型，Qwen3 究竟是如何实现如此惊艳的表现？\n接下来，一起扒一扒 Qwen3 背后技术细节。\n预训练\n与 Qwen2.5 相比，Qwen3 预训练数据集规模几乎是上一代两倍，从 18 万亿个 token 扩展到了 36 万亿个 token。\n它覆盖了 119 种语言和方言，不仅来源于网络，还包括从 PDF 等文档中提取文本内容。\n为了确保数据质量，团队利用 Qwen2.5-VL 提取文档文本，并通过 Qwen2.5 优化提取内容的准确性。\n此外，为了提升模型在数学和代码领域的表现，Qwen3 还通过 Qwen2.5-Math 和 Qwen2.5-Coder 生成大量合成数据，包括教科书、问答对和代码片段。\nQwen3 预训练过程，一共分为三个阶段，逐步提升模型的能力：\n第一阶段（S1）：基础语言能力构建\n使用超 30 万亿个 token，以 4k 上下文长度进行预训练。这一阶段为模型奠定了扎实的语言能力和通用知识基础。\n第二阶段（S2）：知识稠密型优化\n通过增加 STEM、编码和推理任务等知识稠密型数据的比例，模型在额外 5 万亿和 token 上继续训练，进一步提升专业能力的表现。\n第三阶段（S3）：上下文能力扩展\n利用高质量上下文数据，将模型的上下文长度扩展至 32k，确保其能够处理复杂、超长输入。\n得益于模型架构优化、数据规模扩展和更高效的训练方法，Qwen3 Dense 基础模型展现出亮眼的性能。\n如下表所示，Qwen3-1.7B/4B/8B/14B/32B-Base 可以媲美 Qwen2.5-3B/7B/14B/32B/72B-Base，以更小的参数量达到更大模型的水平。\n尤其是，在 STEM、编码和推理等领域，Qwen3 Dense 基础模型甚至优于更大的 Qwen2.5 模型。\n更令人瞩目的是，Qwen3 MoE 模型仅用 10% 激活参数，即可实现 Qwen2.5 Dense 基础模型相似的性能。\n这不仅大幅降低了训练和推理成本，还为模型的实际部署提供了更高的灵活性。\n后训练\n为了打造一个既能进行复杂推理，又能快速响应的混合模型，Qwen3 设计了一个四阶段后训练流程。\n- 长思维链冷启动\n使用多样化的长思维链数据，覆盖数学、编码、逻辑推理和 STEM 问题，训练模型掌握基本的推理能力。\n- 长思维链强化学习\n通过扩展 RL 的计算资源，结合基于规则的奖励机制，提升模型在探索和利用推理路径方面的能力。\n- 思维模式融合\n使用长思维链数据和指令微调数据进行微调，将快速反应能力融入推理模型，确保模型在复杂任务中既精准又高效。\n此数据由第二阶段的增强思考模型生成，确保推理和快速响应能力的无缝融合。\n- 通用强化学习\n在 20 多个通用领域任务，如指令遵循、格式遵循和智能体能力中应用 RL，进一步提升模型的通用性和鲁棒性，同时纠正不良行为。\n全网好评如潮\nQwen3 开源不到 3 小时，GitHub 狂揽 17k 星，彻底点燃了开源社区的热情。开发者们纷纷下载，开启了极速测试。\n苹果工程师 Awni Hannun 宣布，Qwen3 已经得到 MLX 框架支持。\n而且，不论是 iPhone（0.6B, 4B），还是 MacBook（8B, 30B, 3B/30B MoE）、M2/M3 Ultra（22B/235B MoE）消费级设备，均可本地跑。\n他在 M2 Ultra 上运行了 Qwen3 235B MoE，生成速度高达 28 token/s。\n有网友实测后发现，与 Qwen3 大小相同的 Llama 模型，简直不在一个级别上。前者推理更深入，保持更长上下文，还能解决更难的问题。\n还有人表示，Qwen3 就像是一个 DeepSeek 时刻。\n官方指南\n如何用 Qwen3 进行开发\n这次，阿里还放出了在不同框架上使用 Qwen3 的简单指南。\n首先，这是一个在 Hugging Face transformers 中使用 Qwen3-30B-A3B 的标准示例：\nfrom modelscope import AutoModelForCausalLM, AutoTokenizer\nmodel_name = \"Qwen/Qwen3-30B-A3B\"\n# load the tokenizer and the model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\nmodel_name,\ntorch_dtype=\"auto\",\ndevice_map=\"auto\"\n)\n# prepare the model input\nprompt = \"Give me a short introduction to large language model.\"\nmessages = [\n{\"role\": \"user\", \"content\": prompt}\n]\ntext = tokenizer.apply_chat_template(\nmessages,\ntokenize=False,\nadd_generation_prompt=True,\nenable_thinking=True # Switch between thinking and non-thinking modes. Default is True.\n)\nmodel_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n# conduct text completion\ngenerated_ids = model.generate(\n**model_inputs,\nmax_new_tokens=32768\n)\noutput_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n# parsing thinking content\ntry:\n# rindex finding 151668 ()\nindex = len(output_ids) - output_ids[::-1].index(151668)\nexcept ValueError:\nindex = 0\nthinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\ncontent = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\nprint(\"thinking content:\", thinking_content)\nprint(\"content:\", content)\n要关闭推理功能，只需更改参数 enable_thinking，如下所示：\ntext = tokenizer.apply_chat_template(\nmessages,\ntokenize=False,\nadd_generation_prompt=True,\nenable_thinking=False # True is the default value for enable_thinking.\n)\n对于部署，可以使用 sglang>=0.4.6.post1 或 vllm>=0.8.4 创建与 OpenAI 兼容的 API 端点：\nSGLang：\npython -m sglang.launch_server --model-path Qwen/Qwen3-30B-A3B --reasoning-parser qwen3\nvLLM：\nvllm serve Qwen/Qwen3-30B-A3B --enable-reasoning --reasoning-parser deepseek_r1\n如果将其用于本地开发，则可以通过运行简单的命令 ollama run qwen3:30b-a3b 来使用 ollama 运行模型，或者，也可使用 LMStudio、llama.cpp 和 ktransformers 在本地进行构建。\n高级用法\n团队提供了一种软切换机制，当 enable_thinking=True 时，用户可以通过该机制动态控制模型的行为。\n具体来说，可以将 / think 和 / no_think 添加到用户提示或系统消息中，以逐轮切换模型的思考模式。该模型将遵循多轮对话中最近的指令。\n下面就是一个多轮对话的示例：\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nclass QwenChatbot:\ndef __init__(self, model_):\nself.tokenizer = AutoTokenizer.from_pretrained(model_name)\nself.model = AutoModelForCausalLM.from_pretrained(model_name)\nself.history = []\ndef generate_response(self, user_input):\nmessages = self.history + [{\"role\": \"user\", \"content\": user_input}]\ntext = self.tokenizer.apply_chat_template(\nmessages,\ntokenize=False,\nadd_generation_prompt=True\n)\ninputs = self.tokenizer(text, return_tensors=\"pt\")\nresponse_ids = self.model.generate(**inputs, max_new_tokens=32768)[0][len(inputs.input_ids[0]):].tolist()\nresponse = self.tokenizer.decode(response_ids, skip_special_tokens=True)\n# Update history\nself.history.append({\"role\": \"user\", \"content\": user_input})\nself.history.append({\"role\": \"assistant\", \"content\": response})\nreturn response\n# Example Usage\nif __name__ == \"__main__\":\nchatbot = QwenChatbot()\n# First input (without /think or /no_think tags, thinking mode is enabled by default)\nuser_input_1 = \"How many r's in strawberries?\"\nprint(f\"User: {user_input_1}\")\nresponse_1 = chatbot.generate_response(user_input_1)\nprint(f\"Bot: {response_1}\")\nprint(\"----------------------\")\n# Second input with /no_think\nuser_input_2 = \"Then, how many r's in blueberries? /no_think\"\nprint(f\"User: {user_input_2}\")\nresponse_2 = chatbot.generate_response(user_input_2)\nprint(f\"Bot: {response_2}\")\nprint(\"----------------------\")\n# Third input with /think\nuser_input_3 = \"Really? /think\"\nprint(f\"User: {user_input_3}\")\nresponse_3 = chatbot.generate_response(user_input_3)\nprint(f\"Bot: {response_3}\")\n智能体功能的使用\nQwen3 在工具调用方面的表现非常出色。\n团队建议开发者使用 Qwen-Agent，来充分利用 Qwen3 的智能体功能。\nQwen-Agent 在内部集成了工具调用模板和解析器，从而大大降低了编码的复杂程度。\n要定义可用的工具，可以使用 MCP 配置文件，使用 Qwen-Agent 的集成工具，或者自己集成其他工具。\n参考资料：",
        "summary": "阿里开源新一代通义千问模型Qwen3，性能全面超越DeepSeek-R1和OpenAI o1，采用MoE架构，参数量达235B，支持混合推理，部署成本大幅降低，并已上线多个平台供全球开发者免费使用。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "你真的会用 return 吗？—— 11个值得借鉴的 return 写法",
        "url": "https://juejin.cn/post/7497804336568582183",
        "source": "juejin",
        "hot": 1206,
        "time": "",
        "timestamp": 1745766672000,
        "extracted_time": "2025-04-27T15:11:12+00:00",
        "content": "前言\nreturn\n这个关键字，相信大家每天都在用。\n它就像一把锤子，敲打着我们代码里的每一个出口。\n但扪心自问，我们真的把这把锤子用好了吗？\n今天，不想聊什么高深莫测的设计模式，也不敢妄称“最佳实践”。\n只想结合自己这些年在项目摸爬滚打中踩过的一些坑、积累的一点心得，和大家分享一些关于 return\n的、或许能让我们的代码更规范、更优雅、更易读的写法。\n权当抛砖引玉，希望能引发大家的一些思考。\n耐心看完，你一定有所收获。\n正文\n1. 提前返回（卫语句）：让主逻辑更清晰\n这是最常见也是非常推荐的一种模式。\n核心思想是：在方法开头处理掉所有“异常”或“特殊”情况，让方法的主体部分专注于核心逻辑。\n反面教材 ❌：\npublic void processData(Data data) {\nif (data != null) {\nif (data.isValid()) {\nif (checkPermission(data)) {\n// 核心逻辑开始...\nSystem.out.println(\"处理数据：\" + data.getContent());\n// ...\n// 大量核心代码嵌套在这里\n// ...\nSystem.out.println(\"处理完成\");\n} else {\nSystem.out.println(\"权限不足\");\n}\n} else {\nSystem.out.println(\"数据无效\");\n}\n} else {\nSystem.out.println(\"数据为null\");\n}\n}\n很难评，嵌套过深，核心逻辑被包裹在层层 if-else\n中，可读性太差。\n推荐写法 ✅：\npublic void processData(Data data) {\nif (data == null) {\nSystem.out.println(\"数据为null\");\nreturn; // 提前返回\n}\nif (!data.isValid()) {\nSystem.out.println(\"数据无效\");\nreturn; // 提前返回\n}\nif (!checkPermission(data)) {\nSystem.out.println(\"权限不足\");\nreturn; // 提前返回\n}\n// --- 核心逻辑开始 ---\n// 经过前面的卫语句检查，这里的data一定是有效且有权限的\nSystem.out.println(\"处理数据：\" + data.getContent());\n// ...\n// 核心代码不再嵌套，非常清晰\n// ...\nSystem.out.println(\"处理完成\");\n}\n通过提前 return\n，避免了深层嵌套，让主要的处理流程更加顺畅，代码逻辑一目了然。\n配得上“优雅”二字。\n2. 避免 return\n后的 else\n块\n当 if\n分支中包含 return\n语句时，其后的代码天然就是 else\n的逻辑，无需显式写出 else\n。\n反面教材 ❌：\npublic String getStatus(int code) {\nif (code == 0) {\nreturn \"Success\";\n} else {\n// 其他逻辑\nreturn \"Error: \" + getErrorMessage(code);\n}\n}\n虽然没错，但 else\n显得有些多余，未免画蛇添足。\n推荐写法 ✅：\npublic String getStatus(int code) {\nif (code == 0) {\nreturn \"Success\";\n}\n// 如果 code == 0，上面的 return 已经退出方法了\n// 能执行到这里，说明 code != 0，天然就是 else 的逻辑\nreturn \"Error: \" + getErrorMessage(code);\n}\n代码更简洁，减少了一层不必要的缩进。\n3. 简化布尔返回\n直接返回布尔表达式的结果，而不是使用 if-else\n返回 true\n或 false\n。\n反面教材 ❌：\npublic boolean isEligible(User user) {\nif (user.getAge() >= 18 && user.isActive()) {\nreturn true;\n} else {\nreturn false;\n}\n}\n点评：非常啰嗦。\n推荐写法 ✅：\npublic boolean isEligible(User user) {\nreturn user.getAge() >= 18 && user.isActive();\n}\n一行搞定，清晰明了。\n4. 减少不必要的临时变量\n如果一个变量仅仅是为了存储即将 return\n的值，可以考虑直接 return\n表达式的结果。\n反面教材 ❌：\npublic int calculateSum(int a, int b) {\nint sum = a + b;\nreturn sum;\n}\npublic String getUserGreeting(User user) {\nString greeting = \"Hello, \" + user.getName();\nreturn greeting;\n}\nsum\n和 greeting\n变量并非必需。\n推荐写法 ✅：\npublic int calculateSum(int a, int b) {\nreturn a + b;\n}\npublic String getUserGreeting(User user) {\n// 如果 user.getName() 调用成本高或需要复用，临时变量可能有意义\n// 但在这个简单场景下，直接返回更简洁\nreturn \"Hello, \" + user.getName();\n}\n更直接。\n但注意，如果表达式复杂或计算结果需要复用，还是考虑使用临时变量，可以提高可读性或效率，需要权衡。\n5. 巧用三元运算符\n对于简单的二选一返回逻辑，三元运算符 ?:\n是 if-else\n的简洁替代。\n反面教材 ❌：\npublic String getLevel(int score) {\nString level;\nif (score >= 60) {\nlevel = \"Pass\";\n} else {\nlevel = \"Fail\";\n}\nreturn level;\n}\n推荐写法 ✅：\npublic String getLevel(int score) {\nreturn score >= 60 ? \"Pass\" : \"Fail\";\n}\n一行代码，清晰表达了条件选择。\n但是千万注意不要滥用，过分嵌套的三元运算符会降低可读性。\n6. 返回空集合而非 null\n方法约定返回集合类型（List, Set, Map等）时，如果没有数据，应返回空集合而不是 null\n。\n这可以避免调用方不必要的 null\n检查。\n反面教材 ❌：\npublic List getUsers(String department) {\nList users = findUsersByDepartment(department);\nif (users.isEmpty()) { // 或者 users == null\nreturn null; // 调用方需要检查 null !\n}\nreturn users;\n}\n推荐写法 ✅：\nimport java.util.Collections;\nimport java.util.List;\npublic List getUsers(String department) {\nList users = findUsersByDepartment(department);\n// 假设 findUsersByDepartment 可能返回 null 或空 List\nif (users == null || users.isEmpty()) {\nreturn Collections.emptyList(); // 返回不可变的空列表\n}\n// 或者更好的是，确保 findUsersByDepartment 内部就返回空列表而不是 null\nreturn users;\n}\n// 调用方代码，无需担心 NullPointerException\nList userList = service.getUsers(\"IT\");\nfor (String user : userList) { // 直接遍历，安全\nSystem.out.println(user);\n}\n调用方代码更健壮、简洁，符合“防御性编程”的原则。\n7. 利用 Optional\n优雅处理可能缺失的值\n当方法可能返回一个值，也可能什么都不返回时，使用 Optional\n作为返回类型比返回 null\n更能明确表达这种可能性，并引导调用方正确处理。\n反面教材 ❌：\npublic User findUserById(String id) {\n// ... 查询逻辑 ...\nif (found) {\nreturn user;\n} else {\nreturn null; // 调用方必须检查 null\n}\n}\n// 调用方\nUser user = findUserById(\"123\");\nif (user != null) { // 繁琐的 null 检查\nSystem.out.println(user.getName());\n}\n推荐写法 ✅：\nimport java.util.Optional;\npublic Optional findUserById(String id) {\n// ... 查询逻辑 ...\nif (found) {\nreturn Optional.of(user);\n} else {\nreturn Optional.empty();\n}\n}\n// 调用方\nfindUserById(\"123\")\n.ifPresent(user -> System.out.println(user.getName())); // 清晰地处理存在的情况\n// 或者提供默认值\nString userName = findUserById(\"123\")\n.map(User::getName)\n.orElse(\"Unknown User\");\nOptional\n强制调用者思考值不存在的情况，并通过链式调用提供了更流畅的处理方式，减少空指针风险。\n但是Java的Optional\n非常蛋疼，如果使用时不加注意，本应返回Optional\n的方法，返回了null，反而会增加负担，因此团队的开发规范至关重要。\n8. 循环中的提前返回\n在循环中查找元素或满足某个条件时，一旦找到或满足，应立即 return\n，避免不必要的后续迭代。\n反面教材 ❌：\npublic Product findProductByName(List products, String name) {\nProduct foundProduct = null;\nfor (Product product : products) {\nif (product.getName().equals(name)) {\nfoundProduct = product;\nbreak; // 找到后跳出循环\n}\n}\n// 循环结束后再返回\nreturn foundProduct;\n}\n需要一个额外的 foundProduct\n变量，并且在循环外返回。\n浪费性能。\n推荐写法 ✅：\npublic Product findProductByName(List products, String name) {\nfor (Product product : products) {\nif (product.getName().equals(name)) {\nreturn product; // 一旦找到，立即返回\n}\n}\n// 循环正常结束，说明没找到\nreturn null; // 或者 Optional.empty()\n}\n逻辑更直接，代码更紧凑。\n9. 利用 switch\n表达式（Java 14+）\n现在Java的 switch\n表达式可以直接返回值，使得基于多分支选择的返回更加简洁。\n反面教材 ❌ (传统 switch\n语句):\npublic String getWeekdayType(DayOfWeek day) {\nString type;\nswitch (day) {\ncase MONDAY:\ncase TUESDAY:\ncase WEDNESDAY:\ncase THURSDAY:\ncase FRIDAY:\ntype = \"Workday\";\nbreak;\ncase SATURDAY:\ncase SUNDAY:\ntype = \"Weekend\";\nbreak;\ndefault:\nthrow new IllegalArgumentException(\"Invalid day: \" + day);\n}\nreturn type;\n}\n推荐写法 ✅ (使用 switch\n表达式):\npublic String getWeekdayType(DayOfWeek day) {\nreturn switch (day) {\ncase MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY -> \"Workday\";\ncase SATURDAY, SUNDAY -> \"Weekend\";\n// default 分支通常是必需的，除非覆盖了所有枚举常量\n// 如果逻辑确定上面的 case 已经覆盖所有情况，可以不写 default，\n// 但如果传入未覆盖的值会抛异常。\n// 或者明确处理:\n// default -> throw new IllegalArgumentException(\"Invalid day: \" + day);\n};\n}\n代码量显著减少，->\n语法更直观，且 switch\n表达式要求覆盖所有情况（或有 default\n），更安全。\n10. 返回更有意义的类型（枚举或自定义对象）\n避免使用魔法数字或含义模糊的字符串作为返回码，应返回定义清晰的枚举或包含状态和信息的自定义结果对象。\n反面教材 ❌：\npublic int processOrder(Order order) {\nif (order == null) return -1; // -1 代表失败\nif (!checkInventory(order)) return 1; // 1 代表库存不足\n// ... 处理 ...\nif (!paymentSuccess(order)) return 2; // 2 代表支付失败\nreturn 0; // 0 代表成功\n}\n// 调用方\nint resultCode = processOrder(myOrder);\nif (resultCode == 0) { ... }\nelse if (resultCode == 1) { ... } // 难以理解和维护\n推荐写法 ✅：\npublic enum OrderStatus { SUCCESS, FAILED_NULL_ORDER, FAILED_INVENTORY, FAILED_PAYMENT }\npublic OrderStatus processOrder(Order order) {\nif (order == null) return OrderStatus.FAILED_NULL_ORDER;\nif (!checkInventory(order)) return OrderStatus.FAILED_INVENTORY;\n// ... 处理 ...\nif (!paymentSuccess(order)) return OrderStatus.FAILED_PAYMENT;\nreturn OrderStatus.SUCCESS;\n}\n// 调用方\nOrderStatus status = processOrder(myOrder);\nif (status == OrderStatus.SUCCESS) { ... }\nelse if (status == OrderStatus.FAILED_INVENTORY) { ... } // 清晰易懂\n返回类型本身就携带了业务含义，代码自解释，更易于维护和扩展。\n11. 注意 finally\n块中的 return\n（陷阱！）\n尽量避免在 finally\n块中使用 return\n。\n它会覆盖 try\n或 catch\n块中的 return\n或抛出的异常，可能导致非预期的行为和难以追踪的 Bug。\n反面教材 ❌ (极不推荐):\npublic int trickyReturn() {\ntry {\nSystem.out.println(\"Trying...\");\n// 假设这里发生异常或正常返回 1\n// throw new RuntimeException(\"Oops!\");\nreturn 1;\n} catch (Exception e) {\nSystem.out.println(\"Caught exception\");\nreturn 2; // 试图在 catch 中返回 2\n} finally {\nSystem.out.println(\"Finally block\");\nreturn 3; // finally 中的 return 会覆盖前面的所有返回/异常！\n}\n// 这个方法最终会返回 3，即使 try 或 catch 中有 return 或抛出异常\n}\nfinally\n的主要目的是资源清理（如关闭流、释放锁），而不是返回值。\n在这里 return\n会让程序行为变得诡异。\n推荐写法 ✅：\npublic int cleanReturn() {\nint result = -1; // 默认值或错误码\nConnection conn = null;\ntry {\nconn = getConnection();\n// ... 使用 conn 操作 ...\nresult = 1; // 操作成功\nreturn result; // 在 try 中返回\n} catch (SQLException e) {\nSystem.err.println(\"Database error: \" + e.getMessage());\nresult = -2; // 数据库错误码\nreturn result; // 在 catch 中返回\n} finally {\n// 只做清理工作\nif (conn != null) {\ntry {\nconn.close();\nSystem.out.println(\"Connection closed.\");\n} catch (SQLException e) {\nSystem.err.println(\"Failed to close connection: \" + e.getMessage());\n}\n}\n// 不要在 finally 中 return\n}\n}\nfinally\n专注于它的本职工作——资源清理，让返回值逻辑在 try\n和 catch\n中清晰地处理。\n结尾\nreturn\n虽小，五脏俱全。\n一切的目的都是让代码更加优雅，逻辑更加清晰。\n这些并非什么高深的理论，更多的是在日常写代码时，对可读性、简洁性和健壮性的追求。\n希望你能写出诗一样的代码，从码农\n变成代码艺术家\n。\n当然，上面提到的点，有些可能在特定复杂场景下有争议（比如临时变量有时能提升可读性）。关键在于理解这些写法背后的思考：如何让代码更容易被他人（以及未来的自己）理解和维护？\n希望这些粗浅的经验能给大家带来一点启发。\n代码之道，与君共勉！",
        "summary": "本文介绍了11种关于return关键字的使用技巧，包括提前返回、避免return后的else块、简化布尔返回等，旨在提升代码的可读性和规范性。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "长跑8年，Node.js框架Koa v3.0终发布",
        "url": "https://juejin.cn/post/7497995257503236111",
        "source": "juejin",
        "hot": 1152,
        "time": "",
        "timestamp": 1745825836000,
        "extracted_time": "2025-04-28T07:37:16+00:00",
        "content": "大家好，我是农村程序员，独立开发者，行业观察员，前端之虎陈随易。\n- 关注公众号：\n陈随易\n，获取最新文章推送 (很多内容只在公众号发布\n) - 个人网站 1️⃣：chensuiyi.me\n- 个人网站 2️⃣：me.yicode.tech\n- 加入交流群，公众号或者个人网站联系我即可\n我会在这里分享关于 编程技术\n、独立开发\n、行业资讯\n，思考感悟\n等内容。\n所有文章都是古法手打，经过了深度思考和总结，不含 AI 添加剂，请放心食用，一起灵魂交流。\n如果本文能给你提供启发或帮助，欢迎动动小手指，一键三连 (点赞\n、评论\n、转发\n)，给我一些支持和鼓励，谢谢。\nNode.js 有两大家喻户晓的 Web 开发框架，一个是 express\n，另一个则是 koa\n。\n两者有个共同点，那就是简单到了极致，几乎没有多少学习成本，为 Node.js 的推广和传播立下了汗马功劳。\n随着技术的发展，越来越多的新框架涌现出来，提供了更为完善的生态和功能，这两位老将也逐渐廉颇老矣，尚能饭否。\n作为一个长期关注技术资讯的博主，曾一度以为 express v5.0\n和 koa v3.0\n不会问世，因为其中有些版本更新间隔长达 1-2年之久。\n不过最终呢，两者在2024年和2025年，都迎来了一个全新的大版本更新。\n从官方计划来看，koa v3.0\n的发布计划可以追溯到2017年，如今8年过去了，新的篇章已经开始起航，而8年的长跑，也终于落幕。\nOK，碎碎念就到这里，接下来一起看看，koa v3.0\n都更新了什么内容吧。\n最小支持 Node.js 版本为 v18\nNode.js v18（2022年4月发布）\n是一个比较特殊的版本，引入了原生的 Fetch API（实验性）\n，新增了 node:test（实验性）\n测试模块，并作为长期支持的稳定版本维护，是很多项目目前依旧保持的稳定版本。\n也在一定程度上，标志着 Node.js 发展更为激进的开端。\n移除 .redirect('back')\n，添加 .back(fallback_url)\n这也是2017年的提案，由于 v2 版本即将发布，这个提案直到 v3 版本才尘埃落定。\n不要在锚点引用中渲染重定向值\nassert.strictEqual(ctx.body, `Redirecting to ${url}.`);\n👇\nassert.strictEqual(ctx.body, `Redirecting to ${url}.`);\n简而言之就是，以前重定向 (redirect()\n)，会渲染一个 a\n标签，现在不会了。\nreq.origin\n返回值调整\n如果 header\n有 origin\n值，则直接返回该值，而不是当前的主机名 (hostname\n)。\n这个调整，给 CORS\n跨域问题提供了更准确的请求源识别，也进一步简化了 CORS\n中间件的实现。\n删除特殊的 ENOENT 支持\n在以前的版本中，Koa 对某些文件流 (如 fs.createReadStream\n) 的 ENOENT 错误进行了特殊处理。\nENOENT 代表文件不存在，默认情况下，Koa 会捕获这种错误并返回一个通用响应，而不需要开发者显式处理。\n本次更新移除了对 ENOENT 错误的特殊支持，要求开发者手动检查并处理流的错误。这是为了让流的错误处理逻辑更具一致性和可控性。\n更新前：\nctx.body = fs.createReadStream('non-existent-file.txt');\n更新后：\napp.use(async (ctx, next) => {\nawait next();\nif (ctx.body?.readable && typeof ctx.body?.pipe === 'function') {\nawait new Promise((resolve, reject) => {\nctx.body.on('readable', () => resolve());\nctx.body.on('error', (err) => reject(err)); // 必须处理错误\n});\n}\n});\n这是一个重大改动 (breaking change\n)，目的是让开发者对流的错误处理更加明确和可控。\n虽然移除了方便性，但增加了灵活性和一致性，符合更好的开发实践。\n支持自定义流\nimport archiver from 'archiver'\nconst archive = archiver('zip')\nconst stream = ...\narchive.append(stream, { name: 'archive.zip'})\nres.body = archive\n也即是说，可以用第三方流处理包来作为返回了。\n支持 WHATWG 响应体\nWHATWG 是什么？可以理解为 网络世界的规则制定者\n，定义了 HTML、DOM、Fetch API 等网络技术如何工作的规则。\n本次更新，表示 koa v3 已经可以使用与浏览器中相同的 Response\n对象格式。\n这样一来，Koa 就能与最新的 Web 标准保持一致，让开发者可以用相似的方式处理前端和后端的 HTTP 响应，简化了全栈开发体验。\n使用 asyncLocalStorage\n获取当前应用上下文\n示例：\nconst ctx = app.currentContext;\napp.currentContext\n是一个让你可以在任何地方 (不仅仅是中间件内部) 获取当前请求的上下文信息。\n想象你有一个全局的 魔法抽屉\n，无论你的代码在哪里执行，都可以拿到当前正在处理的请求信息。\n之前的问题：\n// Koa v2 方式\napp.use(async (ctx, next) => {\n// 只有在这里能访问 ctx\n// 如果调用其他函数，必须手动传递 ctx\nsomeFunction(ctx);\nawait next();\n});\nfunction someFunction(ctx) {\n// 必须通过参数获取 ctx\n}\n现在的优势：\n// Koa v3 新方式\napp.use(async (ctx, next) => {\n// 使用中间件\nawait next();\n});\n// 在任何其他文件或函数中\nfunction someUtility() {\nconst ctx = app.currentContext; // 直接获取当前请求上下文!\nconst userId = ctx.request.body.userId;\n// ...处理逻辑\n}\n使用场景：\n工具函数\n：不需要每次都传递 ctx 参数。日志记录\n：轻松在日志中包含当前请求信息。错误处理\n：在任何地方捕获错误时能获取请求详情。第三方库集成\n：让第三方库能感知当前请求。\nquery string\n被 URLSearchParams\n替代\n也是面向标准的一次更新，让 URL 的参数操作在浏览器端和服务器变得一致。\n感谢阅读，本文由编程记者 前端之虎陈随易\n撰稿，转载请保留顶部信息。",
        "summary": "Node.js框架Koa v3.0在8年后正式发布，主要更新包括支持Node.js v18、移除.redirect('back')、调整req.origin返回值、删除ENOENT错误特殊处理以及支持自定义流。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "四大产品升级，广汽昊铂HT/GT 2025款开启预售",
        "url": "https://www.ifanr.com/1622740",
        "source": "ifanr",
        "hot": 0,
        "time": "",
        "timestamp": 1746016797000,
        "desc": "2025年4月30日，2025款昊铂HT、昊铂GT正式预售，双车同步实现四大配置升级。此次推新，豪华再加码，为用户带来安全好开、舒适贴心的豪华出行体验。\n本次2025款车型均升级了HOD（Hand-Off Detection）电容感应方向盘，在使用智能驾驶辅助过程中，可实时监测驾驶员手部状态，及时进行提醒警示，增添了一道安全屏障；在设计上探索运动美学与驾控性能的有效融合，昊铂HT 2025款升级20英寸玄甲轮毂，新增扰流板，在丰富运动化设计元素的同时，进一步优化动力学性能，降低风阻和提升整车动态行驶稳定性；新升级的5G座舱能提升车机响应速度，让智联交互更灵敏，智能沟通无缝衔接。\n昊铂GT 2025款升级为19寸星动轮毂+标配碧青蓝性能卡钳，在强化颜值外观的同时运动性能张力十足，满足年轻用户对运动性能的审美追求；昊铂GT 2025款还针对710 Max版本车型升级VGR、FSD底盘智能技术，应对复杂道路场景优化车辆动态行驶灵活性，提升驾驭操控，让路途皆为坦途。\n广汽昊铂对于豪华品牌的高端化诠释，以「高价值」的技术加速产品推新，赋能豪华带来体验革新的同时，更以「高品价比」的产品策略让用户买得放心、坐得舒心、用得省心。广汽昊铂HT/GT 2024款同步推出限量一口价政策，昊铂HT 2024款限量置换一口价最低17.99万元起；昊铂GT 2024款限量置换一口价最低16.39万元起。\n广汽昊铂以一口价机制让用户感知到豪华消费的最高价值，更凭借着出众的产品水准，链接用户对于高端化产品的豪华价值认同。广汽昊铂HT/GT双车均斩获2025年第一季度中国汽车质量排行双榜，昊铂GT荣获中大型及大型纯电车型第一名，昊铂HT荣获中大型及大型纯电SUV第三名。",
        "content": "为您查询到 篇文章\n2025年4月30日，2025款昊铂HT、昊铂GT正式预售，双车同步实现四大配置升级。此次推新，豪华再加码，为用户带来安全好开、舒适贴心的豪华出行体验。\n本次2025款车型均升级了HOD（Hand-Off Detection）电容感应方向盘，在使用智能驾驶辅助过程中，可实时监测驾驶员手部状态，及时进行提醒警示，增添了一道安全屏障；在设计上探索运动美学与驾控性能的有效融合，昊铂HT 2025款升级20英寸玄甲轮毂，新增扰流板，在丰富运动化设计元素的同时，进一步优化动力学性能，降低风阻和提升整车动态行驶稳定性；新升级的5G座舱能提升车机响应速度，让智联交互更灵敏，智能沟通无缝衔接。\n昊铂GT 2025款升级为19寸星动轮毂+标配碧青蓝性能卡钳，在强化颜值外观的同时运动性能张力十足，满足年轻用户对运动性能的审美追求；昊铂GT 2025款还针对710 Max版本车型升级VGR、FSD底盘智能技术，应对复杂道路场景优化车辆动态行驶灵活性，提升驾驭操控，让路途皆为坦途。\n广汽昊铂对于豪华品牌的高端化诠释，以「高价值」的技术加速产品推新，赋能豪华带来体验革新的同时，更以「高品价比」的产品策略让用户买得放心、坐得舒心、用得省心。广汽昊铂HT/GT 2024款同步推出限量一口价政策，昊铂HT 2024款限量置换一口价最低17.99万元起；昊铂GT 2024款限量置换一口价最低16.39万元起。\n广汽昊铂以一口价机制让用户感知到豪华消费的最高价值，更凭借着出众的产品水准，链接用户对于高端化产品的豪华价值认同。广汽昊铂HT/GT双车均斩获2025年第一季度中国汽车质量排行双榜，昊铂GT荣获中大型及大型纯电车型第一名，昊铂HT荣获中大型及大型纯电SUV第三名。\n[展开]",
        "summary": "广汽昊铂HT/GT 2025款开启预售，实现四大配置升级，包括HOD电容感应方向盘、5G座舱、玄甲轮毂及VGR/FSD底盘技术等，提升安全、舒适与智能驾驶体验。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "快手成立可灵 AI 事业部",
        "url": "https://weibo.com/1642720480/5161195188784974",
        "source": "ifanr",
        "hot": 0,
        "time": "",
        "timestamp": 1746008515000,
        "desc": "快手成立可灵 AI 事业部，负责可灵、可图等系列大模型业务\n据晚点报道，快手在今日成立了可灵 AI 事业部。该事业部下设可灵 AI 产品部、运营部和技术部，负责可灵、可图等系列大模型业务，快手高级副总裁盖坤担任可灵 AI 事业部负责人，继续兼任社区科学线负责人。\n据悉，可灵与可图分别是快手自研的 ​……",
        "content": "Sina Visitor System",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "微信支付在新加坡开启刷掌支付",
        "url": "https://weibo.com/1642720480/5161191414176533",
        "source": "ifanr",
        "hot": 0,
        "time": "",
        "timestamp": 1746007911000,
        "desc": "微信支付今天官宣，微信刷掌开启首个海外点位 —— 新加坡。\n5 月 1 日起，到新加坡圣淘沙名胜世界就能刷掌支付，包含水上探险乐园及八大消费点位。而且用户在境外（非中国大陆地区）还能用小程序「PalmDa」管理刷掌权限。\n早于去年 12 月，在新加坡金融科技节上腾讯刷掌与 Visa 合作官宣出海，海外 ​……",
        "content": "Sina Visitor System",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "DeepSeek 发布新模型 DeepSeek-Prover-V2-671B",
        "url": "https://weibo.com/1642720480/5161186569487727",
        "source": "ifanr",
        "hot": 0,
        "time": "",
        "timestamp": 1746006703000,
        "desc": "刚刚，DeepSeek 在全球最大 AI 开源社区 Hugging Face 发布了一个名为 DeepSeek-Prover-V2-671B 的新模型。@APPSO\n根据目前公布的信息，DeepSeek-Prover-V2-671B 使用了更高效的 safetensors 文件格式，并支持多种计算精度（BF16、FP8、F32 等），方便模型更快、更省资源地训练和部署。\n从命名上看 ​……",
        "content": "Sina Visitor System",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "路虎揽胜 EV 完成冬季测试",
        "url": "https://weibo.com/1642720480/5161175752114656",
        "source": "ifanr",
        "hot": 0,
        "time": "",
        "timestamp": 1746003685000,
        "desc": "最近，路虎官方宣布了旗下新款的路虎揽胜 EV（ Range Rover E）即揽胜纯电版车型已经完成了发布前的第二轮冬季测试。这次冬季测试主要是为了验证新车的热管理系统，确保它在零度以下的极端温度中能够加热机舱并保持快速充电。\n在去年夏天，也曾经有外媒报道过，新的路虎纯电车型曾经在阿联酋的沙漠中 ​……",
        "content": "Sina Visitor System",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "苹果发布两条 Apple Watch 健康功能视频",
        "url": "https://weibo.com/1642720480/5161164900404084",
        "source": "ifanr",
        "hot": 0,
        "time": "",
        "timestamp": 1746001874000,
        "desc": "苹果最近发布了两条关于 Apple Watch 健康功能的 30 秒 TVC 视频，均是根据真实的中国 Apple Watch 用户的故事来进行拍摄。\n这两条 30 秒的 TVC 视频，分别聚焦于两位 Apple Watch 用户：刚刚退休的白红、即将上大学的李浩铭。\n年龄和背景都截然不同的他们，却有着一个共同点：都曾被 Apple Watch 在 ​……",
        "content": "Sina Visitor System",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "联想百应智能体接入千问 3 全面升级，重塑 IT 运维与AI办公体验",
        "url": "https://www.ifanr.com/1622659",
        "source": "ifanr",
        "hot": 0,
        "time": "",
        "timestamp": 1746000096000,
        "desc": "在企业智能化转型加速的当下，联想凭借强大的技术整合能力，携手通义千问模型 Qwen3（简称千问 3），深度升级百应智能体，在 IT 运维和 AI 办公领域实现重大突破，再次展现其在企业智能化服务领域的卓越实力。\n千问 3 作为国内首款混合推理模型，具备混合推理模式、支持 MCP、多语言等先进能力，这为联想百应智能体带来质的飞跃。\n在 IT 运维场景，千问 3 的强大推理与知识泛化能力，助力百应智能体本地推理模型升级。如今，百应智能体能够更精准地诊断问题、更智能地处理故障。值得一提的是，近期百应智能体还将推出离线智能桌面运维功能，即便处于复杂网络或离线环境，也能迅速定位异常并自动修复，全方位保障企业 IT 系统 7×24 小时稳定运行。此外，联想百应智能体 PC 端即将上线千问 3 本地模型一键部署功能，企业无需依赖外部网络，就能调用本地大模型，核心数据全程锁定在本地设备，从根本上确保数据安全，极大提升办公与运维的智能化水平。\n在 AI 办公场景，联想百应 Copilot 办公超级智能体与千问 3 深度融合，成效显著。通过重构 Word 长文档分析、多语言协作等核心能力，办公效率实现跨越式提升。千问 3 支持 119 种语言及方言的实时翻译，让百应 Copilot 在企业海外业务拓展、跨文化团队沟通、跨国会议语音转写与决议提炼等方面发挥关键作用。同时，创新引入的 “深度思考开关”，使用户可在轻量级快速交互与深度推理模式间自由切换，无论是简单的文本润色，还是深度的结构化报告生成，百应 Copilot 都能出色完成，结合企业知识库与检索增强生成（RAG）技术，实现精准问答与智慧决策，引领企业智能办公进入新时代。此次联想百应智能体与千问 3 的深度融合，为企业提供了高效、安全的智能化服务，有力推动企业在数字化浪潮中快速发展。",
        "content": "为您查询到 篇文章\n在企业智能化转型加速的当下，联想凭借强大的技术整合能力，携手通义千问模型 Qwen3（简称千问 3），深度升级百应智能体，在 IT 运维和 AI 办公领域实现重大突破，再次展现其在企业智能化服务领域的卓越实力。\n千问 3 作为国内首款混合推理模型，具备混合推理模式、支持 MCP、多语言等先进能力，这为联想百应智能体带来质的飞跃。\n在 IT 运维场景，千问 3 的强大推理与知识泛化能力，助力百应智能体本地推理模型升级。如今，百应智能体能够更精准地诊断问题、更智能地处理故障。值得一提的是，近期百应智能体还将推出离线智能桌面运维功能，即便处于复杂网络或离线环境，也能迅速定位异常并自动修复，全方位保障企业 IT 系统 7×24 小时稳定运行。此外，联想百应智能体 PC 端即将上线千问 3 本地模型一键部署功能，企业无需依赖外部网络，就能调用本地大模型，核心数据全程锁定在本地设备，从根本上确保数据安全，极大提升办公与运维的智能化水平。\n在 AI 办公场景，联想百应 Copilot 办公超级智能体与千问 3 深度融合，成效显著。通过重构 Word 长文档分析、多语言协作等核心能力，办公效率实现跨越式提升。千问 3 支持 119 种语言及方言的实时翻译，让百应 Copilot 在企业海外业务拓展、跨文化团队沟通、跨国会议语音转写与决议提炼等方面发挥关键作用。同时，创新引入的 “深度思考开关”，使用户可在轻量级快速交互与深度推理模式间自由切换，无论是简单的文本润色，还是深度的结构化报告生成，百应 Copilot 都能出色完成，结合企业知识库与检索增强生成（RAG）技术，实现精准问答与智慧决策，引领企业智能办公进入新时代。此次联想百应智能体与千问 3 的深度融合，为企业提供了高效、安全的智能化服务，有力推动企业在数字化浪潮中快速发展。\n[展开]",
        "summary": "联想百应智能体接入通义千问3模型，升级IT运维与AI办公体验，提升故障处理、数据安全及多语言协作能力，推动企业智能化转型。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "索尼 XPERIA 1 VII 预计5月发布",
        "url": "https://weibo.com/1642720480/5161141558842414",
        "source": "ifanr",
        "hot": 0,
        "time": "",
        "timestamp": 1745995839000,
        "desc": "索尼 XPERIA 1 VII 或将 5 月发布\n近期，媒体 sumahodigest 爆料了大量索尼 Xperia 1 VII 新机的外观信息，具体来看：\n新机将提供墨绿色和许久未见的紫色，后盖表面均采用磨砂处理；机身中框依然为直边设计，拥有前后切角处理；\n从公布的图片来看，新机依然拥有「徒手」拆卸的 SIM 卡槽与 3.5mm 耳 ​……",
        "content": "Sina Visitor System",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "魅族 Note 16 系列外观公布",
        "url": "https://weibo.com/1642720480/5161139046973633",
        "source": "ifanr",
        "hot": 0,
        "time": "",
        "timestamp": 1745995233000,
        "desc": "魅族 Note 16 系列外观公布，高管回应争议\n日前，星纪魅族正式公布了旗下 Note16 系列机型的外观信息。\n新机采用多边形切角环形相机模组，其中四个开孔位置对称排布；配色方面提供金红撞色和纯白两款配色。但在此消息公布后，不少网友纷纷表示魅族 Note16 系列「撞脸」华为 Mate XT 三折叠机型。\n随 ​……",
        "content": "Sina Visitor System",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "iPhone 17 部分机型完成测试",
        "url": "https://weibo.com/1642720480/5161133002458230",
        "source": "ifanr",
        "hot": 0,
        "time": "",
        "timestamp": 1745994025000,
        "desc": "消息称 iPhone 17 部分机型完成工程测试\n据 Digitimes 援引苹果供应链人士消息，苹果近期完成了 iPhone17 系列部分机型的工程验证测试（EVT）第一阶段，新机距离量产又更近了一步。\n据悉，工程验证测试是苹果产品测试中的一个重要阶段，后续还有设计验证测试（DVT）、生产验证测试（PVT），具体来看 ​……",
        "content": "Sina Visitor System",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "🎁[送码] Codenote - 结合备忘录和便笺的 Mac App，如果你有注释代码又舍不得删除，欢迎你来尝试一下。",
        "url": "https://www.v2ex.com/t/1129148",
        "source": "v2ex",
        "hot": 44,
        "time": "",
        "timestamp": 1745996359000,
        "desc": "![]( https://i.imgur.com/ah9qSMZ.png)\n![]( https://i.imgur.com/D4CEoYx.png)\n![]( https://i.imgur.com/OVvw83Y.png )\n![]( https://i.imgur.com/ZOyRjE8.png)\n**快速入口:**\n1. [视频介绍]( https://codenote.app)\n2. [App 下载]( https://apps.apple.com/cn/app/codenote/id6744996909)\n## 背景\n我是一名 Coder ，遇到问题，就要想办法解决问题。而除了工作中的挑战，还有很多私人问题需要面对——照顾好自己，也是生活中重要的一部分，毕竟，工作不该是生活的全部。\n从去年的 WWDC24 结束后，我开始在 Apple Developer 官方网站上学习 Swift 教程。但很快，三分钟热度过去了，没有合适的驱动力，让我一直徘徊到了这个月——Something is changed.\n在此前几年，我曾经学习过 Flutter ，并成功将两款 App 分别上线到 App Store 和 Google Play 。跨平台开发在追求开发速度上确实拥有天然优势。\n然而，Apple 自家平台的体验实在太优雅了。对于缺乏设计资源的开发者来说，依托平台原生设计去生长，反而更加自然、顺手。因此，\"掌握 Apple 原生开发\" 一直是我心中的一个执念。直到最近，这个心结终于被我解开了。\n## 言归正传\nSaveComment 是我在学习 SwiftUI 开发过程中萌发的一个想法。\n在学习过程中，我经常需要写大量注释、临时代码。慢慢地，这些“注释代码”堆积如山，充斥着我的 Demo 项目。虽然很多注释看似有用，让我舍不得清理，但随着数量不断增加，反而严重影响了我的学习效率。\n终于，我忍无可忍，决定顺便学习一下 macOS 应用开发，花了几小时实现了核心功能，又用几天时间打磨细节。最终，这个小工具逐渐成型，并从一个简单的保存注释的想法，进化成了一个轻量笔记本+便签工具。\n它有了一个正式的名字：**Codenote** （源自 Code+Note ，但不局限于 Code ）。\n现在，它已经正式上架 Mac App Store 🎉，\n还拥有了一个正儿八经的官网🌍: https://codenote.app 😄！\nMac App Store 地址: https://apps.apple.com/cn/app/codenote/id6744996909\n**目前算一个 MVP 版本，后续计划增加接入自定义 AI 模型等，欢迎大家来体验，来反馈。**\n## 功能\n#### 核心功能\n快捷键对选中内容 ✍️ 做笔记，或者剪切，也能像 🗒️ 便笺 一样 📌 钉在屏幕上。\n#### 笔记管理\n支持对笔记内容的高效整理与多维度分类：\n- ✅ **批量操作**：支持多选笔记，统一删除、移动或打标签\n- ✅ **文件夹管理**：创建文件夹组织笔记，结构清晰\n- ✅ **标签管理**：添加多个标签，便于搜索与聚合\n- ✅ **App 来源管理**：按来源应用（如 Safari 、Xcode 等）自动归类\n- ✅ **收藏功能**：一键收藏重要笔记，快速访问\n---\n#### 分类方式\n提供多种灵活的分类视角：\n- 📁 按文件夹组织\n- 🏷️ 按标签筛选\n- 💻 按 App 来源分类\n- ⭐ 收藏夹聚合常用笔记\n#### 语法高亮\n内建主流编程语言的语法高亮支持，适用于技术类笔记记录，如：\n- Nginx / Apache / Shell\n- JavaScript / TypeScript\n- Java / Python / Go / Rust\n- HTML / CSS / Markdown\n- SQL / Shell / JSON 等\n## 🎁送码福利\n限量 50 个 Mac App Store 兑换码（先到先得，剩下的发邮箱）：\n1. L6AAYMYWPWE9\n2. M6YNXAF47F6H\n3. LWL9YLEFT47A\n4. WK6HYXEN4MXK\n5. N3AXLL4LKF7K\n6. 4H6EEN73YYFK\n7. X6N4KNRLTKY6\n8. FJ376939KLNW\n9. T4LR677KKYTH\n10. PKJMKP79AX6X\n11. HLJKW6KMAMRJ\n12. MHH9TJH9KJPL\n13. MLE9NX9KX4EA\n14. TWFNF79KL4M7\n15. RNJH4FPJK69J\n16. 4YTRNT7AN7E7\n17. RYLT7J73WW46\n18. W3M3HEL3KRWW\n19. KYTLHM7WJEYX\n20. JRFRTP6XRA4P\n21. 9JRXHYM4F4RL\n22. 97EMYMT74N94\n23. H3NMWN7PM4EN\n24. PHETNPKHKK37\n25. N33HJAF9PJ64\n26. L369W77PMEM7\n27. E3J96RY4K6RL\n28. TA4L7WM96X7J\n29. WKPJXTENAPXK\n30. TEH47XWFPHW7\n31. **兑换了请回复一个数字，方便大家。**\n> 这是个起点，离完美还有距离。希望能收到大家宝贵的反馈。 ✨",
        "extracted_time": "2025-04-30T06:59:19+00:00",
        "content": "快速入口:\n我是一名 Coder ，遇到问题，就要想办法解决问题。而除了工作中的挑战，还有很多私人问题需要面对——照顾好自己，也是生活中重要的一部分，毕竟，工作不该是生活的全部。\n从去年的 WWDC24 结束后，我开始在 Apple Developer 官方网站上学习 Swift 教程。但很快，三分钟热度过去了，没有合适的驱动力，让我一直徘徊到了这个月——Something is changed.\n在此前几年，我曾经学习过 Flutter ，并成功将两款 App 分别上线到 App Store 和 Google Play 。跨平台开发在追求开发速度上确实拥有天然优势。\n然而，Apple 自家平台的体验实在太优雅了。对于缺乏设计资源的开发者来说，依托平台原生设计去生长，反而更加自然、顺手。因此，\"掌握 Apple 原生开发\" 一直是我心中的一个执念。直到最近，这个心结终于被我解开了。\nSaveComment 是我在学习 SwiftUI 开发过程中萌发的一个想法。\n在学习过程中，我经常需要写大量注释、临时代码。慢慢地，这些“注释代码”堆积如山，充斥着我的 Demo 项目。虽然很多注释看似有用，让我舍不得清理，但随着数量不断增加，反而严重影响了我的学习效率。\n终于，我忍无可忍，决定顺便学习一下 macOS 应用开发，花了几小时实现了核心功能，又用几天时间打磨细节。最终，这个小工具逐渐成型，并从一个简单的保存注释的想法，进化成了一个轻量笔记本+便签工具。\n它有了一个正式的名字：Codenote （源自 Code+Note ，但不局限于 Code ）。\n现在，它已经正式上架 Mac App Store 🎉，\n还拥有了一个正儿八经的官网🌍: https://codenote.app 😄！\nMac App Store 地址: https://apps.apple.com/cn/app/codenote/id6744996909\n目前算一个 MVP 版本，后续计划增加接入自定义 AI 模型等，欢迎大家来体验，来反馈。\n快捷键对选中内容 ✍️ 做笔记，或者剪切，也能像 🗒️ 便笺 一样 📌 钉在屏幕上。\n支持对笔记内容的高效整理与多维度分类：\n提供多种灵活的分类视角：\n内建主流编程语言的语法高亮支持，适用于技术类笔记记录，如：\n限量 50 个 Mac App Store 兑换码（先到先得，剩下的发邮箱）：\n这是个起点，离完美还有距离。希望能收到大家宝贵的反馈。 ✨\n1\nkorvin 22 小时 40 分钟前\n|\n2\nlockheart 22 小时 40 分钟前\n23. H3NMWN7PM4EN 已用，感谢开发者\n|\n3\nsnycv 22 小时 38 分钟前\n20. JRFRTP6XRA4P 已用，感谢\n|\n4\nzle12688 22 小时 37 分钟前\n30.TEH47XWFPHW7\n|\n5\nzle12688 22 小时 37 分钟前\n感谢\n|\n6\nsaimax 22 小时 37 分钟前\n2. M6YNXAF47F6H 已用 谢谢\n|\n7\nRollup 22 小时 37 分钟前\nTWFNF79KL4M7 已使用，感谢\n|\n8\ntuot 22 小时 25 分钟前\nWK6HYXEN4MXK 已使用，谢谢\n|\n9\neamdfs 22 小时 20 分钟前\nE3J96RY4K6RL 已使用，谢谢\n|\n10\nsun522198558 22 小时 15 分钟前\nTA4L7WM96X7J 已用谢谢\n|\n11\nidlerlestat 22 小时 14 分钟前\nKYTLHM7WJEYX 已用\n|\n12\nevan9527 22 小时 12 分钟前\n16. 4YTRNT7AN7E7 感谢\n|\n13\nLaurus 21 小时 49 分钟前\n|\n14\nreturn1992 21 小时 48 分钟前\ncmV0dXJuMTk5MkAxNjMuY29t ，谢谢，请邮箱发个\n|\n15\nLaurus 21 小时 46 分钟前\n[email protected] ，谢谢，请邮箱发个。30 个兑换码我一个个试过了，都被用过了。\n|\n16\nn0nnull 21 小时 45 分钟前\nFJ376939KLNW 已用，谢谢分享\n|\n17\nLituby 21 小时 41 分钟前 via Android\n大佬来晚了，求个码，感谢🙏\nbGl0dWJ5QG91dGxvb2suY29t |\n18\ntsin1618 21 小时 39 分钟前\ndnBzZXJpY0BvdXRsb29rLmNvbQ==，求个码，谢谢\n|\n19\nCheckM8 21 小时 35 分钟前 via iPhone\n|\n20\nfollowad 21 小时 29 分钟前 via iPhone\n大佬 俺来啦 求个码噻。私密马赛。[email protected]\n|\n21\narron2022 21 小时 25 分钟前\n[email protected] OP 好人，来年生八个娃，感谢\n|\n22\nsmilehe 21 小时 21 分钟前\n大佬，[email protected] 感谢。\n|\n23\nShum1n 21 小时 12 分钟前\nNTQwODQyOTMwQHFxLmNvbQ== 求个码 感谢 OP\n|\n24\nURgoy 21 小时 8 分钟前 via iPhone\nenp6bG14YUBnbWFpbC5jb20=，蹲一个，谢谢\n|\n25\nfengci 21 小时 1 分钟前\nNzY5MjA1MjdAcXEuY29t 蹲\n|\n26\nTomorrowxxy 20 小时 58 分钟前\nICAwMzgwODA4QGdtYWlsLmNvbSAgIA== 感谢 OP\n|\n27\nFakerLeung 20 小时 58 分钟前\nMzc1MDgyNjc3QHFxLmNvbQ==\n蹲个码，谢谢楼主 |\n28\nwyjson 20 小时 53 分钟前 via Android\n來晚了，蹲個碼謝謝樓主。[email protected]\n|\n29\nnianyou 20 小时 53 分钟前\naXJ1Ym9tYkBxcS5jb20= 谢谢楼主\n|\n30\nimBossa 20 小时 46 分钟前\n感谢，aW1ib3NzYUBvdXRsb29rLmNvbQ==\n|\n31\naiyo101 20 小时 41 分钟前\nOTA0MTIwMjc4QHFxLmNvbQ==\n蹲，谢谢楼主 |\n32\nHeanes 19 小时 18 分钟前\naGVhbmVzQDE2My5jb20= 谢谢楼主\n|\n33\nDaniel0829 19 小时 5 分钟前\n冒昧求个码。感谢。（ base 64 ） dGVjaGRhbmllbEBkdWNrLmNvbQ==\n|\n34\nlangdalanghonghu 18 小时 48 分钟前\nbGFuZ2RhbGFuZ2hvbmdodXNodWlmb3JtYWNAZ21haWwuY29t 求个码谢谢楼主\n|\n35\nXhofe 18 小时 40 分钟前\neGhvZmVAcXEuY29t\n蹲，谢谢楼主 |\n36\njianny 18 小时 39 分钟前\n码全部兑换完了，求一个码，我的邮箱：amlhbm55QGxpdmUuY29t 谢谢大佬！\n|\n37\nmiaoxiaomayi 18 小时 26 分钟前\n@Laurus 我也是每个都试了一遍\n|\n38\nskvi 18 小时 22 分钟前 via Android\n📬\nay1ub3RpZnlAb3V0bG9vay5jb20= 希望还有 |\n39\nlilyaki 18 小时 4 分钟前\nMTU2MTYzODU5QHFxLmNvbQ== 谢谢大佬\n|\n40\nSuremotoo 15 小时 51 分钟前\n蹲，感谢开发者！\nc3VyZW1vdG9vQGdtYWlsLmNvbQ== |\n41\nBssn 15 小时 40 分钟前\nb2trb251bGxAZ21haWwuY29t\n感谢开发者，很有趣的 app ，感觉在学习一门新语言时尤其有用哈哈 |\n42\nhuyasi 11 小时 22 分钟前 via iPhone\n[email protected] 求一个谢谢🙏\n|\n43\nNeroKim 9 小时 45 分钟前\n来晚了，求一个码 谢谢\nbmVyb0BuZXJvLm1l |\n44\nychen997 7 小时 6 分钟前\n来晚了，但是很有用，可否求一个码，谢谢啦\neWluYW4uZW1haWxAZ21haWwuY29t |\n45\nAJDX3906 54 分钟前 via iPhone\nYWpkeDM5MDZAMTYzLmNvbQ==\n看了 app 描述，想体验一下，蹲个码 |\n46\nhexiaowu1993 54 分钟前\n来晚了，蹲一个码，感谢 op\nNDQ2ODg3MTA5QHFxLmNvbQ== |",
        "summary": "Codenote 是一款结合备忘录和便笺功能的 Mac 应用，旨在帮助开发者高效管理注释代码和笔记。该应用已上架 Mac App Store，并计划未来接入自定义 AI 模型。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "劳动节为什么不翻译为劳工节或者工人节",
        "url": "https://www.v2ex.com/t/1129260",
        "source": "v2ex",
        "hot": 35,
        "time": "",
        "timestamp": "",
        "desc": "说劳动节，好像这个节是为了劳动，或者为了歌颂劳动似的，“劳动最光荣”\n其实英文是 International Workers' Day, 或者 Labour Day ，意思是工人、劳工的节日，是为了**保障劳动者（工人）权益**的节日\n这个节日的起源，是当时的工人为了争取 8 小时工作制而进行罢工，可见**是为了减少劳动，而非歌颂劳动，并非“劳动最光荣”**\n总结如下：\nLabour Day 的起源可以总结如下：\n- **起源背景**\n19 世纪中后期，随着资本主义的发展，工人阶级普遍遭受超长工时和恶劣劳动条件的剥削。工人们为争取八小时工作制和改善生活条件，陆续发起罢工和抗议[3][4]。\n- **澳大利亚的首次行动**\n1856 年 4 月 21 日，澳大利亚墨尔本的石匠和建筑工人举行大规模停工，要求实施八小时工作制，这一行动成为后续国际工人运动的先声[1][5][7]。\n- **美国芝加哥大罢工**\n1886 年 5 月 1 日，美国芝加哥等城市约 35 万工人举行大罢工，要求八小时工作制。期间发生了著名的“干草市场事件”（ Haymarket Affair ），工人与警方冲突，造成多人伤亡。这次运动虽然遭到镇压，但极大地推动了全球工人运动的发展[1][2][3][4][5][9]。\n- **国际劳动节的确立**\n为纪念美国工人的斗争，1889 年 7 月，恩格斯领导下的第二国际在巴黎召开代表大会，决定将每年的 5 月 1 日定为国际劳动节（ May Day ），号召全球工人为争取合法权益和八小时工作制而团结斗争[1][3][4][5]。\n- **节日影响与传播**\n1890 年 5 月 1 日，欧美多国工人首次集体庆祝这一节日。此后，五一劳动节逐渐成为全球 80 多个国家法定的节日，象征工人阶级团结、争取权益和社会进步[3][4]。\n简要总结：\nLabour Day 起源于 19 世纪工人为争取八小时工作制而发起的罢工运动，尤其是 1886 年美国芝加哥的大罢工。1889 年，第二国际将 5 月 1 日定为国际劳动节，以纪念工人运动和争取权益的斗争精神。此节日如今已成为全球劳动者的共同节日[1][3][4][5]。\n来源\n[1] 国际劳动节- 维基百科，自由的百科全书 https://zh.wikipedia.org/zh-hans/%E5%9B%BD%E9%99%85%E5%8A%B3%E5%8A%A8%E8%8A%82\n[2] 五一国际劳动节起源 - 项城市人民政府 https://xiangcheng.gov.cn/sitesources/xcs/page_pc/xwdt/ssxw/articleA1FAF1E27CF14A9EA301668D58F39535.html\n[3] 五一国际劳动节_百度百科 https://baike.baidu.com/item/%E4%BA%94%E4%B8%80%E5%9B%BD%E9%99%85%E5%8A%B3%E5%8A%A8%E8%8A%82/810559\n[4] 国际劳动节由来 http://paper.ce.cn/pad/content/202404/28/content_293674.html\n[5] 五一国际劳动节的起源是什么？（罗莎·卢森堡，1894 ） https://www.marxists.org/chinese/rosa-luxemburg/mia-chinese-rosa-1894.htm\n[6] 党史故事|五一国际劳动节是怎样被引入到中国的？ - 共产党员网 https://www.12371.cn/2021/04/16/VIDE1618554904389481.shtml\n[7] 劳动节- 维基百科，自由的百科全书 https://zh.wikipedia.org/zh-hans/%E5%8A%B3%E5%8A%A8%E8%8A%82\n[8] 新中国的第一个“五一”国际劳动节 http://cpc.people.com.cn/n1/2024/0425/c443712-40223444.html\n[9] [PDF] 國際勞動節由來及意義 https://www.mol.gov.tw/media/tkrfbokv/%E6%B4%BB%E5%8B%95%E8%A8%8A%E6%81%AF.pdf?mediaDL=true",
        "content": "| 注册会员 | 746,495 |\n| 主题 | 1,129,292 |\n| 回复 | 16,207,047 |\n| 求问 2025 年技术栈选择， RN 还是 flutter\n1 程序员 • Asuler • 15 分钟前 • 最后回复来自 tootfsg\n|\n26 |\n| 朋友买卢浮宫门票被钓鱼网站骗 信息安全 • zerozz • 25 分钟前 • 最后回复来自 totoro52 | 77 |\n| 最近自建一个 nas 装了飞牛，使用域名解析 ipv6， 只能局域可以访问， 外网访问不了，怎么回事，折腾半天不行，求教。 NAS • pey69 • 32 分钟前 • 最后回复来自 Liqiniu | 4 |\n| 老婆明天生日，想去春熙路做手工[手动狗头] 程序员 • csfreshman • 1 小时 7 分钟前 • 最后回复来自 lloovve | 7 |\n| 求教：使用 iSCSI 共享能否解决 SMB/NFS 的权限冲突问题 NAS • Ploter • 2 小时 34 分钟前 • 最后回复来自 webcape233 | 8 |\n| perplexity 的 deep research 模式的 AI 幻觉（hallucination）很严重，动不动就伪造古文，自编数据更是司空见惯，各位有没有同价位的幻觉率少点的 Deep Research 推荐？ 程序员 • qqqfreeboycn • 2 小时 56 分钟前 |\n| 每天解锁 Jemini ai 的一种玩法 5/1：素描转实体图 程序员 • antaeus • 3 小时 21 分钟前 |\n| 多进制数的乘法时间复杂度 O(n)? 程序员 • qwertyegg • 1 小时 22 分钟前 • 最后回复来自 KeShih | 2 |\n| 有没有研究图形化 AI 模型的大牛。预测轮盘落点。我有海量数据 程序员 • ydt0728 • 2 小时 9 分钟前 • 最后回复来自 newtype0092 | 23 |\n| 腾讯云欠费 2 元删数据没有讨论的吗 云计算 • lichdkimba • 1 小时 31 分钟前 • 最后回复来自 stark123 | 171 |\n| 直接用 v0.dev 写的界面与真实的后端接口通讯可以吗? 程序员 • jiaoguan1688 • 33 分钟前 • 最后回复来自 kneo | 4 |\n| 月兔编程语言支持国产芯片开发，对标 C？ 程序员 • Hooooooey • 3 小时 2 分钟前 • 最后回复来自 muooOOO | 7 |\n| 高频金融系统如何防止突然断电导致的数据丢失？ 程序员 • latifrons • 2 小时 29 分钟前 • 最后回复来自 PhpBB | 95 |\n| 接了一个小程序的单子，客户很多图片怎么放比较好呢？\n1 程序员 • ccctttwww • 22 分钟前 • 最后回复来自 pytth\n|\n30 |\n| 大厂的同事们，你们是怎么定位线上故障的？\n1 程序员 • 5261 • 13 小时 16 分钟前 • 最后回复来自 kid1412621\n|\n100 |\n| Hacker News 中文 RSS 订阅 RSS • s4fea0a8321 • 3 小时 43 分钟前 • 最后回复来自 set | 3 |\n| tg 上运维/sre/devops 相关的交流群 DevOps • hellolinuxer • 9 小时 47 分钟前 • 最后回复来自 lizzzy | 1 |\n| 字节的 AI 智能体 Trae 用起来怎么样 程序员 • kellysally • 2 小时 18 分钟前 • 最后回复来自 Aspx | 14 |\n| [Golang/k8s] 内存分析中 pprof 与 runtime 包的 HeapInuse 的 GAP 在哪里呢？ Go 编程语言 • Charlie17Li • 15 小时 43 分钟前 • 最后回复来自 feedcode | 1 |\n| 浅浅体验了一下 vivo x200 ultra，不太满意 Android • Awes0me • 5 小时 19 分钟前 • 最后回复来自 southwolf | 20 |\n| 那个大模型编码能力最好？\n1 程序员 • silenceboychen • 16 小时 29 分钟前 • 最后回复来自 sickoo\n|\n99 |\n| Cursor 帮我写了个 pdf 编辑器 程序员 • daBig • 2 小时 49 分钟前 • 最后回复来自 Syiize | 3 |\n| 微信公众号新消息立刻转发到群里如何实现，有人有点子或者软件吗？ 程序员 • john2023 • 2 小时 51 分钟前 • 最后回复来自 mybro | 26 |\n| 哪一家 AI 对会话隐私保护的最好？ 程序员 • haolitcs • 2 小时 4 分钟前 • 最后回复来自 flyqie | 2 |\n| Python 项目代码升级咋搞？ Python • jackOff • 17 小时 21 分钟前 • 最后回复来自 bingfengfeifei | 7 |\n| 中国建设银行顺利无损收取谷歌广告联盟 Google Adsense 电汇 程序员 • handsometong • 15 小时 4 分钟前 • 最后回复来自 handsometong | 4 |\n| 在线之家 在公司就可以访问 家里的网就访问不了，请问是什么原因呢？ 程序员 • doujiao • 2 小时 46 分钟前 • 最后回复来自 keshi | 1 |\n| emby 服务远程访问的问题 NAS • guoguobaba • 13 小时 12 分钟前 • 最后回复来自 kid1412621 | 27 |\n| 你们的 cursor 界面卡吗?win 版本的 程序员 • jiaoguan1688 • 20 小时 5 分钟前 • 最后回复来自 HomeZane | 2 |\n| 这几天折腾 PVE AIO 有点上头了 NAS • 0x663 • 17 分钟前 • 最后回复来自 anonymity | 48 |\n| 打包 mac 应用进行分发一定需要进行苹果开发者认证并付费吗？ iDev • silenceboychen • 22 小时 38 分钟前 • 最后回复来自 hwdq0012 | 17 |\n| nodejs 后端，怎么比较好的生成接口文档？(排除 nest.js) Node.js • wuxilaoshiren • 12 小时 49 分钟前 • 最后回复来自 kid1412621 | 26 |\n| 请教下，有没有实现基于笔记本的 win11 系统自动完成不同的 PM 操作 Windows • tyy123 • 23 小时 38 分钟前 • 最后回复来自 ntedshen | 6 |\n| 腾讯新开源的 Kuikly，但是我不太敢用，害怕又是一个 kpi 产物 程序员 • hhhhohhhh • 5 小时 39 分钟前 • 最后回复来自 bunnyblueair | 36 |\n| 两个人的数据开发团队,被要求从零开始治理企业数据 MySQL • IIIIZAYOI • 3 小时 6 分钟前 • 最后回复来自 iv8d | 20 |\n| 谁有开源的 react antd 5 的表单设计器求分享 程序员 • zsvc • 23 小时 22 分钟前 |\n| 再也不用记 k8s 的命令了 Kubernetes • justyy • 9 小时 47 分钟前 |\n| NAS 硬盘选多大的？有没有可能混用希捷西数？ NAS • dcsuibian • 2 小时 21 分钟前 • 最后回复来自 Autonomous | 36 |\n| 有做过基于 webrtc 技术的多人视频会议系统的吗 PHP • tangknox1 • 14 小时 48 分钟前 • 最后回复来自 tangknox1 | 16 |\n| 救救我~~， k8s 的 containerd 的镜像加速还有那些办法可以用呀 Kubernetes • 052678 • 18 小时 17 分钟前 • 最后回复来自 mengyx | 21 |\n| jdk 发行版大家生产环境和开发环境都用的是哪一家呢？\n1 Java • zx9481 • 23 小时 43 分钟前 • 最后回复来自 guanyujia5444\n|\n54 |\n| GitHub 开源项目提 PR，求推荐！ 程序员 • gulao • 22 小时 16 分钟前 • 最后回复来自 guanzhangzhang | 16 |\n| WEB 版本的操作系统好用么？ 程序员 • zsvc • 1 天前 • 最后回复来自 qinqiuxu | 19 |\n| 安卓有类似熊猫吃短信的短信拦截工具吗 Android • balddonkey1 • 13 小时 26 分钟前 • 最后回复来自 flynaj | 21 |\n| 有没有学习 opencl 和 cuda 编程的教程和学习的地方啊#web3#区块链 程序员 • akadanjuan101 • 23 小时 11 分钟前 • 最后回复来自 bytecc | 5 |\n| 如何记住 debug 的快捷键 程序员 • movq • 1 天前 • 最后回复来自 newaccount | 21 |\n| Deepseek 发布新模型 程序员 • johnsmith2077 • 18 小时 28 分钟前 • 最后回复来自 coolfan | 1 |\n| Android 的 Application 类中持有静态 SP 为什么会导致空指针\n2 Android • SmaliYu • 21 小时 5 分钟前 • 最后回复来自 phcbest\n|\n11 |\n| 有没一种可以将 http/socks 代理转 http 协议的东西？ Web Dev • ztjal • 21 小时 15 分钟前 • 最后回复来自 yc8332 | 37 |\n| 前端开发 | 微信 前端开发 Chrome Vue.js 浏览器 React CSS Firefox Flutter Edge Angular Electron Web Dev Next.js Vite Nuxt.js Ionic |\n| 编程语言 | Python Java PHP Go 编程语言 JavaScript Node.js C++ Rust Swift HTML .NET C# Ruby on Rails TypeScript Ruby Kotlin Lua |\n| 后端架构 | 云计算 服务器 DNS MySQL NGINX Docker 数据库 Kubernetes Ubuntu Amazon Web Services Django Redis MongoDB DevOps Cloudflare Elasticsearch Flask Tornado API Timescale |\n| iOS | iDev iCode iMarketing iAd |",
        "summary": "新闻内容为一个论坛的帖子列表，涉及技术讨论、编程问题、AI应用、NAS配置、云计算、编程语言、Android设备体验等话题。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Bartender 这个价格认真的吗，这么贵？",
        "url": "https://www.v2ex.com/t/1129193",
        "source": "v2ex",
        "hot": 28,
        "time": "",
        "timestamp": 1746006306000,
        "desc": "https://i.imgur.com/3dn8MXI.png",
        "extracted_time": "2025-04-30T09:45:06+00:00",
        "content": "1\ncrayhuang 20 小时 0 分钟前\n这是日元吧？\n|\n2\nNsLib 19 小时 58 分钟前\n这工具被偷偷收购了, 不建议再用了\n|\n3\ndzdh 19 小时 56 分钟前\n现在用开源免费的 ice\n|\n7\ncoolcoffee 19 小时 39 分钟前\n同楼上，我现在在用的开源 ice 基本复刻了 Bartender 。Barbee 我有购买没达到我的预期。\n|\n8\nmikaelson 19 小时 30 分钟前\n@dzdh #3 https://github.com/jordanbaird/Ice 是这个吗\n|\n9\nmiaomiao888 17 小时 46 分钟前\n@yuyuf https://html.zone/ip/query/?ip=185.200.125.201 不同 IP 库有不同结果\n|\n10\nobjectxiang 16 小时 7 分钟前\n@coolcoffee 好像听到 V 友在说 Barbee 需要再改改，本子和笔已经准备好了。\n|\n12\ncoolcoffee 15 小时 51 分钟前\n@objectxiang\n我记得 Barbee 里面的 Hidden Section 区域，如果显示出来的时候想要点击某个应用程序，那么这个程序会被移动到 Visible Section ，而且 Hidden Section 再次隐藏的时候不会把刚刚那个程序给继续隐藏。 |\n13\ndddd1919 15 小时 45 分钟前\nhidden bar ，也还行吧够用\n|\n14\ndilidilid 15 小时 37 分钟前 1\n苹果这刘海屏都 4 年了，图标遮挡从第一天开始抱怨就很多，硬是不给一个官方的解决方案实在是牛逼\n|\n15\nRoccoShi 15 小时 34 分钟前\nice 好用的\n|\n16\ngpt5 15 小时 32 分钟前\nBarbee 还可以\n|\n19\nduxiansen 15 小时 19 分钟前\nice +1, Barbee 之前下载试过好几次，bug 好多\n|\n20\nobjectxiang 15 小时 12 分钟前\n@coolcoffee #12 谢谢您，如果是这个问题的话，应该现在版本没有问题了。下次如果您想换也可以试试最新的 TestFlight 版本的 Barbee： https://testflight.apple.com/join/HPKNaKKv\n|\n21\nGoalonez 15 小时 1 分钟前\nBarbee 其他都挺好的，就是鼠标指针似乎经常会被影响。具体有点忘了是闪还是抖动来着，这个很影响日常操作。\nice 也有些问题，但没有特别影响使用的问题。 还是推荐 ice 。 |\n22\nobjectxiang 14 小时 48 分钟前\n@Goalonez 原来大家在意的是这个问题🤣，下次一定改。\n|\n24\nGoalonez 12 小时 40 分钟前\n@objectxiang #22 这个问题能修复的话，Barbee 肯定是比 ice 更好的选择。而且 ice 似乎已经好几个月没更新了。\n|\n26\nNsLib 5 小时 8 分钟前\n@yuyuf 说起来其实你可以换个用菜单栏的思路, 我的工作流优化以后, 也就调音量、Wifi 、切换耳机会用到菜单栏 (其实这个也能优化掉), 而且我甚至还用 iStat Menus 看监控. 把关键的几个图标拖到最右边, 其他的图标爱咋显示咋显示, 无所谓\n|\n27\ndilidilid 2 小时 58 分钟前\n@NsLib 问题不在这里，问题在于被遮挡之后根本没法把“关键的几个图标”拖出来，除非你恰好外接了一块屏幕。很多图标是打开软件之后才会冒出来的，这意味着你是没法控制图标“出生”在哪里的\n|\n28\ndarer 2 小时 46 分钟前\n@objectxiang barbee 还有一个问题是经常自动的点到左上角的苹果图标 不知道是不是已知问题 有没有修\n|\n29\nduolaamengv2 56 分钟前\n改用 Ice 了，一摸一样\n|",
        "summary": "用户在讨论 Bartender 和其替代品如 Ice 和 Barbee 的使用体验，包括价格、功能、稳定性及界面问题。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "接了一个小程序的单子，客户很多图片怎么放比较好呢？",
        "url": "https://www.v2ex.com/t/1129194",
        "source": "v2ex",
        "hot": 28,
        "time": "",
        "timestamp": 1746006394000,
        "desc": "小程序需求非常简单，只是展示商品的一些功能，没有后台，只有大概 100-200 张图片，访问量会非常的少，怎么放比较好呢",
        "extracted_time": "2025-04-30T09:46:34+00:00",
        "content": "1\nyidinghe 19 小时 50 分钟前 via Android\n直接放同域名的后台网站就可以了。\n|\n2\nwebszy 19 小时 50 分钟前\n看大小，图片太大了放 cdn ，都是小图片就放本地\n|\n3\nlepig 19 小时 49 分钟前\n一次性买卖就找个免费图床，交付完拉到\n需要后期维护可以用 OSS ，也可以自己买个服务器搭建。 OSS 可能会被盗刷，谨慎一点 |\n4\nawolf 19 小时 45 分钟前\nCDN 吧\n|\n6\nmake115 19 小时 30 分钟前\n压缩放后台\n|\n10\n695975931 19 小时 16 分钟前\n小程序的云开发也有对象存储，可以放那里，不过收费，图片不多收费也还好\n|\n11\nyinmin 19 小时 14 分钟前 via iPhone\n买个阿里云的 200M 峰值的轻量服务器跑 nginx 网站。原因：价格便宜（对于公司来讲）、峰值 200Mbps 下载快、不会出现意外费用，将来还可以扩展安装些别的。\n|\n14\nmoefishtang 18 小时 55 分钟前\n阿里云 EMAS\n还有个野路子：用知乎的公共图床（在文章页面上传照片就行，能拿到图片链接，知乎没开防盗链） |\n15\nccctttwww OP @moefishtang 野路子怕翻车，甚至想过用公司的 cdn ，但想稳点还是算了\n|\n17\nIvanLi127 18 小时 3 分钟前\n你这项目没运维费用吗？一般折中方案不就是丢到对象存储里嘛\n|\n18\nRomic 17 小时 55 分钟前\n放在你 nas 上面，客户如果不想付钱直接给图片内容偷天换日\n|\n20\njingrui 16 小时 35 分钟前\n说个正规军做法，腾讯云开通 cos ，按量付费的，几毛钱 1 个 G ，访问少还是很便宜的；访问多，cos 开通 cdn 。\n|\n21\nwogogoing 16 小时 20 分钟前 via iPhone\nop 试试我的星光图床吧 👉 https://stardots.io\n|\n22\nstabc 16 小时 18 分钟前\n几十 m 的话。很多云存储的免费配额都足够了。或者你让客户自己花钱申请。跟他解释清楚。做事要负责。\n|\n23\nHuberyPang 16 小时 16 分钟前\n图片转为 webp 格式，一个图能压缩到十几 kb\n|\n24\nyahon 16 小时 13 分钟前\n图片压缩，小程序分包然后试试能不能放下。不行就放 CDN 。\n|\n25\npasson 16 小时 13 分钟前\n都打包到小程序内吧\n|\n26\npasson 16 小时 12 分钟前\n不对，小程序大小有限制\n|\n27\nkamal 12 小时 4 分钟前\n不管用什么 CDN ，千万不要用云开发保存图片。费用贵很多。\n|\n28\nPEax 4 小时 43 分钟前\ntinypng.com 可以先压缩下\n|",
        "summary": "用户在开发小程序时遇到图片存储问题，多位网友给出了不同建议，包括使用CDN、对象存储、云开发、图床等方案，并讨论了成本、安全性及图片压缩等问题。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "谷歌的 NotebookLM 能生成中文播客了",
        "url": "http://www.ruanyifeng.com/blog/2025/05/notebooklm.html",
        "source": "阮一峰的网络日志",
        "hot": "",
        "time": "2025-05-01 04:26:24",
        "timestamp": 1746044784000,
        "published": "2025-05-01 04:26:24",
        "content": "两天前，谷歌发了一个公告。\n它旗下的 AI 笔记产品 NotebookLM，现在支持50种语言生成播客了（原来只支持英文）。\n我一定要分享这个消息，终于能生成中文播客了。这是我一直想要的功能，相信也是很多朋友想要的。\n我演示一下，大家听听效果，会惊到你的。\n首先，访问它的官网，点开右上角的设置，选择\"Output Language\"（输出语言）。\n切换到\"中文（简体）\"。\n然后，在首页新建一个笔记本。一般来说，一个学习主题，对应一个笔记本。\n作为演示，我新建了一个\"中国小说\"的笔记本。进入后，在 Source（原始材料）标签页上传了鲁迅的《阿Q正传》。\n注意，上传的文件格式目前只限于 PDF、TXT 和 Markdown。\n另外，经过我测试，如果是图片扫描的 PDF 文件，它会自动进行文字识别。\n接着，切换到 Studio（工作室）标签页，点击 Generate（生成）按钮，它就开始生成播客。\n几分钟以后，播客就生成了，里面是一男一女在谈论你上传的资料。\nruanyf · 阿Q正傳\n大家听听看，是不是很像那些精心准备的真人播客。\nNotebookLM 不仅可以上传文本材料，还可以针对网站和 Youtube 视频，生成播客。\n我随便找了一个 Youtube 的英文视频，内容是国产旗舰手机的摄影能力比较。\n下面是生成的播客。\nruanyf · Vivo X200 Ultra 相机评测\n我听了以后，觉得都不必看视频了。而且，中文播客比英文视频，更容易抓住重点。\n总之，有了中文播客以后，任何枯燥的学习资料，都能变成平易近人的播客节目。走路、休息、锻炼、开车的时候都能听，学习时间和途径都变多了。\n需要注意的是，免费账户一天只能生成三个播客，更多需要付费。\n除了播客，NotebookLM 的 AI 笔记功能，也非常好用。\n你可以上传自己的学习材料，也可以用它搜索某个主题的学习材料。\n下面是我用它搜索 PostgreSQL 数据库的学习材料。\n指定学习材料以后，你可以跟这些材料聊天。\n它还会自动生成各种笔记：学习指导、内容摘要、常见问题、时间线等等。\n以上就是 NotebookLM 的基本用法。\n我的评价是，NotebookLM 是一款革命性的笔记工具，属于少数几个真正有重大用处的 AI 产品。\n它会改变做笔记的方式和学习方式，每个学习者都应该知道有这样一个工具。\n它属于谷歌的产品，似乎还没有竞品，希望国内的厂商能够做出替代品。\n（完）\n文档信息\n版权声明：自由转载-非商用-非衍生-保持署名（创意共享3.0许可证）\n发表日期： 2025年5月 1日",
        "desc": "两天前，谷歌发了一个公告。...",
        "summary": "谷歌的NotebookLM现在支持50种语言生成播客，包括中文。用户可以通过上传文本、网站或YouTube视频生成类似真人主持的播客内容。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "因经济动荡 LWN 考虑涨价",
        "url": "https://www.solidot.org/story?sid=81193",
        "source": "Solidot",
        "hot": "",
        "time": "2025-04-30 16:05:40",
        "timestamp": 1746000340000,
        "published": "2025-04-30 16:05:40",
        "content": "今年一季度美国经济下滑了 0.3%，几年前欣欣向荣的美国经济正面临不确定性。历史悠久的自由软件和开源新闻网站 LWN 报告它也受到当下政治和经济动荡的影响。LWN 注意到从 3 月初起，新订阅量和续订量都出现了明显下滑。这与美国发起的贸易战以及由此导致的经济衰退相一致。订阅量减少目前尚未对 LWN 构成生存威胁，也没有影响到作者的薪酬，但这一情况令人担忧。为应对挑战 LWN 开始勒紧裤腰带过日子。如果情况恶化，它可能不得不提高订阅价格。LWN 是一家美国公司，但很大一部分订阅来自国外。如果针对美国公司的抵制情绪加剧，它不太可能不受影响。",
        "desc": "今年一季度美国经济下滑了 0.3%，几年前欣欣向荣的美国经济正面临不确定性。历史悠久的自由软件和开源新闻网站 LWN 报告它也受到当下政治和经济动荡的影响。LWN 注意到从 3 月初起，新订阅量和续订量都出现了明显下滑。这与美国发起的贸易战以及由此导致的经济衰退相一致。订阅量减少目前尚未对 LWN 构成生存威胁，也没有影响到作者的薪酬，但这一情况令人担忧。为应对挑战 LWN 开始勒紧裤腰带过日子。如果情况恶化，它可能不得不提高订阅价格。LWN 是一家美国公司，但很大一部分订阅来自国外。如果针对美国公司的抵制情绪加剧，它不太可能不受影响。",
        "summary": "由于美国经济下滑和贸易战影响，LWN网站面临订阅量下降的问题，考虑可能提高订阅价格以应对经济压力。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Google 称政府更频繁的使用 0day",
        "url": "https://www.solidot.org/story?sid=81191",
        "source": "Solidot",
        "hot": "",
        "time": "2025-04-30 15:37:17",
        "timestamp": 1745998637000,
        "published": "2025-04-30 15:37:17",
        "content": "Google Threat Intelligence Group (GTIG)报告，2024 年检测到 75 个 0day，低于 2023 年的 98 个。其中 Windows 最多从 16 个增加到 22 个，Safari 和 iOS 的 0day 从 2023 年的 11 个和 9 个分别降至 3 个和 2 个。Android 7 个和 2023 年持平，Chrome 也是 7 个。Firefox 一个，俄罗斯黑客组织 CIGAR 利用 CVE-2024-9680 针对 Firefox 和 Tor 浏览器窃取用户数据。Google 表示成功追踪了 75 个 0day 中的 34 个，大部分攻击来自政府支持的组织，主要是窃取情报而不是出于经济动机，其中包括中国和朝鲜。",
        "desc": "Google Threat Intelligence Group (GTIG)报告，2024 年检测到 75 个 0day，低于 2023 年的 98 个。其中 Windows 最多从 16 个增加到 22 个，Safari 和 iOS 的 0day 从 2023 年的 11 个和 9 个分别降至 3 个和 2 个。Android 7 个和 2023 年持平，Chrome 也是 7 个。Firefox 一个，俄罗斯黑客组织 CIGAR 利用 CVE-2024-9680 针对 Firefox 和 Tor 浏览器窃取用户数据。Google 表示成功追踪了 75 个 0day 中的 34 个，大部分攻击来自政府支持的组织，主要是窃取情报而不是出于经济动机，其中包括中国和朝鲜。",
        "summary": "Google 报告称 2024 年检测到 75 个 0day 漏洞，其中大部分由政府支持的组织利用，用于窃取情报。Windows 和 Android 漏洞数量有所增加，而 Safari 和 iOS 明显减少。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Mercury: Commercial-scale diffusion language model",
        "url": "https://www.inceptionlabs.ai/introducing-mercury",
        "source": "Hacker News",
        "hot": "",
        "time": "2025-04-30 21:51:10",
        "timestamp": 1746021070000,
        "published": "2025-04-30 21:51:10",
        "content": "Comments",
        "summary": "新闻标题提到Mercury是一个商业规模的扩散语言模型。新闻内容仅包含一个链接，未提供进一步信息。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Apple violated antitrust ruling, judge finds",
        "url": "https://www.wsj.com/tech/apple-violated-antitrust-ruling-federal-judge-finds-66b85957",
        "source": "Hacker News",
        "hot": "",
        "time": "2025-05-01 00:03:55",
        "timestamp": 1746029035000,
        "published": "2025-05-01 00:03:55",
        "content": "Comments",
        "summary": "A judge has ruled that Apple violated an antitrust ruling.",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Pwning the Ladybird Browser",
        "url": "https://jessie.cafe/posts/pwning-ladybirds-libjs/",
        "source": "Hacker News",
        "hot": "",
        "time": "2025-04-30 23:59:09",
        "timestamp": 1746028749000,
        "published": "2025-04-30 23:59:09",
        "content": "Comments",
        "summary": "新闻标题为'Pwning the Ladybird Browser'，内容链接至Y Combinator的评论页面，未提供具体信息。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Espressif's ESP32-C5 Is Now in Mass Production",
        "url": "https://www.espressif.com/en/news/ESP32-C5_Mass_Production",
        "source": "Hacker News",
        "hot": "",
        "time": "2025-04-30 22:15:21",
        "timestamp": 1746022521000,
        "published": "2025-04-30 22:15:21",
        "content": "Comments",
        "summary": "Espressif的ESP32-C5芯片现已开始批量生产。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Linux Kernel Exploitation: Attack of the Vsock",
        "url": "https://hoefler.dev/articles/vsock.html",
        "source": "Hacker News",
        "hot": "",
        "time": "2025-04-30 19:03:04",
        "timestamp": 1746010984000,
        "published": "2025-04-30 19:03:04",
        "content": "Comments",
        "summary": "新闻标题提到了Linux内核利用和Vsock攻击，内容链接指向了相关评论。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Zhaoxin's KX-7000",
        "url": "https://chipsandcheese.com/p/zhaoxins-kx-7000",
        "source": "Hacker News",
        "hot": "",
        "time": "2025-04-30 20:23:33",
        "timestamp": 1746015813000,
        "published": "2025-04-30 20:23:33",
        "content": "Comments",
        "summary": "新闻标题为'Zhaoxin's KX-7000'，新闻内容仅包含一个链接，未提供具体信息。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Show HN: Convert Large CSV/XLSX to JSON or XML in Browser",
        "url": "https://csvforge.com",
        "source": "Hacker News",
        "hot": "",
        "time": "2025-05-01 01:31:19",
        "timestamp": 1746034279000,
        "published": "2025-05-01 01:31:19",
        "content": "Comments",
        "summary": "该新闻介绍了一个在浏览器中将大型CSV或XLSX文件转换为JSON或XML的工具。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Reversible computing with mechanical links and pivots",
        "url": "https://tennysontbardwell.com/blog/2025/04/30/mechanical-computing/index.html",
        "source": "Hacker News",
        "hot": "",
        "time": "2025-04-30 17:35:08",
        "timestamp": 1746005708000,
        "published": "2025-04-30 17:35:08",
        "content": "Comments",
        "summary": "新闻标题提到使用机械连接和枢轴实现可逆计算，但新闻内容仅包含一个链接，未提供具体信息。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "GroMo (YC W21) Is Hiring",
        "url": "https://www.ycombinator.com/companies/gromo/jobs/aP4JS9K-product-tech-business-ai-enthusiasts",
        "source": "Hacker News",
        "hot": "",
        "time": "2025-05-01 01:01:02",
        "timestamp": 1746032462000,
        "published": "2025-05-01 01:01:02",
        "content": "Comments",
        "summary": "GroMo (YC W21) Is Hiring",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "NotebookLM Audio Overviews are now available in over 50 languages",
        "url": "https://blog.google/technology/google-labs/notebooklm-audio-overviews-50-languages/",
        "source": "Hacker News",
        "hot": "",
        "time": "2025-04-30 17:28:38",
        "timestamp": 1746005318000,
        "published": "2025-04-30 17:28:38",
        "content": "Comments",
        "summary": "NotebookLM Audio Overviews are now available in over 50 languages.",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "I Found Malware in a BeamNG Mod",
        "url": "https://lemonyte.com/blog/beamng-malware",
        "source": "Hacker News",
        "hot": "",
        "time": "2025-04-30 19:17:28",
        "timestamp": 1746011848000,
        "published": "2025-04-30 19:17:28",
        "content": "Comments",
        "summary": "新闻标题提到在BeamNG模组中发现了恶意软件。新闻内容仅包含评论链接，未提供更多细节。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Show HN: Create your own finetuned AI model using Google Sheets",
        "url": "https://promptrepo.com/finetune/",
        "source": "Hacker News",
        "hot": "",
        "time": "2025-04-30 15:53:36",
        "timestamp": 1745999616000,
        "published": "2025-04-30 15:53:36",
        "content": "Comments",
        "summary": "该新闻介绍了一个通过Google Sheets创建自定义微调AI模型的方法。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Future of OSU Open Source Lab in Jeopardy",
        "url": "https://osuosl.org/blog/osl-future/",
        "source": "Hacker News",
        "hot": "",
        "time": "2025-04-30 18:51:52",
        "timestamp": 1746010312000,
        "published": "2025-04-30 18:51:52",
        "content": "Comments",
        "summary": "新闻标题提到OSU Open Source Lab的未来面临威胁，但新闻内容仅包含一个链接，未提供更多具体信息。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Milwaukee police considering trading mugshots for facial recognition tech",
        "url": "https://www.jsonline.com/story/news/crime/2025/04/25/milwaukee-police-considering-trading-mugshots-for-facial-recognition-tech/83084223007/",
        "source": "Hacker News",
        "hot": "",
        "time": "2025-05-01 03:05:25",
        "timestamp": 1746039925000,
        "published": "2025-05-01 03:05:25",
        "content": "Comments",
        "summary": "Milwaukee police are considering using facial recognition technology in exchange for mugshots.",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Phi-4 Reasoning Models",
        "url": "https://azure.microsoft.com/en-us/blog/one-year-of-phi-small-language-models-making-big-leaps-in-ai/",
        "source": "Hacker News",
        "hot": "",
        "time": "2025-05-01 01:02:41",
        "timestamp": 1746032561000,
        "published": "2025-05-01 01:02:41",
        "content": "Comments",
        "summary": "新闻标题为'Phi-4 Reasoning Models'，新闻内容仅包含一个链接至评论页面。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "DeepSeek-Prover-V2",
        "url": "https://github.com/deepseek-ai/DeepSeek-Prover-V2",
        "source": "Hacker News",
        "hot": "",
        "time": "2025-04-30 16:23:28",
        "timestamp": 1746001408000,
        "published": "2025-04-30 16:23:28",
        "content": "Comments",
        "summary": "新闻标题为'DeepSeek-Prover-V2'，新闻内容仅包含一个链接至Y Combinator的评论页面，未提供更多具体信息。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "一个月 78 块的 AI 日历，治好了我的「万事开头难」",
        "url": "http://www.geekpark.net/news/348924",
        "source": "极客公园",
        "hot": "",
        "time": "2025-05-01 01:24:57",
        "timestamp": 1746033897000,
        "published": "2025-05-01 01:24:57",
        "content": "作者 | Li Yuan\n编辑 | 郑玄\n你有没有一件事，因为做起来太麻烦，拖到一直都不想开始？\n好吧，笔者承认，我有这个问题。这也是笔者自从拥有智能手机以来，一直在不断尝试各种日程管理和 To-do List 应用的原因。\n不过笔者很快就发现，对于一个擅长规划的人而言，似乎只用一个日历，也已经能很好地规划自己的工作了。而对于一个本来就讨厌规划的人而言，添加任务，添加截止日期，添加子任务，添加截止日期，分配优先级，本身就是一项令人头疼到不想开始的事情。\n于是，我和日程软件的关系，最后变得很像一对怨偶——只有任务变得又紧急又多又重要的时候，我才会鼓起勇气，把一件一件任务登记到软件里，设置好截止日期和提醒时间。而只要能够稍得喘息，我就永远想不起来打开这个软件。\n而如果一件事情虽然重要，比如我知道我想学习拳击，但是这件事并不十分紧急，对我来说又很麻烦——又要去买装备又要去对比课程，哪个 To-do List 也很难帮我开启这一任务。\n作为一个日程管理 app 的资深用户，笔者本来已经对这个「老怨偶」不再抱有太多期望了。大多数 To-do List 的软件，功能都大同小异，区别无非是 UI 和使用上的繁琐程度。\n不过，最近，机缘巧合之下，笔者发现了一款 AI-native 的日程管理软件，让我突然眼前一亮。\n日程管理领域，早已有一整套成熟完整的理论体系，无论是「重要 vs 紧急」四象限理论、番茄工作法、还是 GTD 理论，都早在上世纪就已经被提出。而这款软件，却在这样一个「历史悠久、创新稀少」的领域中，依然借助 AI 做出了突破，甚至意外地，在我的日常生活里真正起到了点作用。\nAI-native 的日程软件长什么样？\n笔者是在小红书最开始发现了这款软件。\n名叫 Splitti，这款由国外独立开发者设计的日程管理软件，最先在 ADHD 社群中有了小范围的传播——ADHD 人群注意力不集中，因此对于日程管理软件本身的需求，也相对比较旺盛。\n而这款 app，主打的是能够使用 AI，帮助 ADHD 人群，更快地启动任务和安排生活。\n一打开这个 app，我就感受到了这个软件的与众不同之处。\n作为日程软件的老用户，笔者已经对日程软件的界面十分熟悉——一般不是一个日历，就是一个任务添加界面。\n而打开 Splitti，则很不一样——你被要求写一段自我介绍，让 AI 更好地了解你。\n不明所以，笔者填写了几个关键信息：「Li Yuan、女、科技作者、INTP」，并填写了一个规划痛点「养猫，猫会打扰我的工作。」\n接下来，出乎笔者的意料，app 马上根据笔者输入的内容，生成了一段非常长的对笔者个人的情况分析，包括「注意她可能喜欢深度专注，应该在交流中增加智识性内容。」等等。并马上提出了三个追问问题，包括「在做科技作者的过程中，你遇到的最大挑战是什么？」\n这种体验确实是在 AI 时代之前难以想象的。软件并不像之前的日程软件一样，提供的是一个标准化的工具体验，而更像一个真正的私人教练，在接触中，会选择先了解你的情况。\n而在获得笔者的私人情况后，Splitti 开始建议笔者增加一条新任务。\n任务可以直接用自然语言，甚至语音输入，直接输入关于这条任务，我的所有思考就可以了。\n接下来，AI 则根据它对我，和对人物的理解，直接将这个任务分成了多个子任务。\n除了分解任务之外，笔者还惊喜地发现，AI 已经为我的每个任务，规划了一个大概能完成的时间，并给他们自动设置了截止日期。\n每一个子任务，如果过于抽象，还可以点击，再次进行任务分解。比如「找到拳击课程」可以进一步拆解为「在网上调研」，「在线下调研」，「阅读评论」，「给场馆打电话」，「列出不同场馆的对比」。\n在任务被拆解到足够细之后，即使是启动困难的人，似乎也有了可以开始的动力。而 Splitti 正是用 AI 为用户垫好了这关键的一步。\n甚至在深度使用中，笔者发现， 这样的任务拆解，甚至是根据个人使用定制化的——在笔者添加了一个写作任务之后， AI 进行任务拆解时，会单独拆解出一条任务：请寻找一个合适的工作环境，尽量免受猫咪打扰。\n使用越多，把自己的需求和困惑向 AI 讲解地越明确，AI 就会生成一个越完美的私人定制规划。\n笔者还惊喜地发现，AI 能做的还不仅如此。\nAI 还能为我的任务生成经典的「重要 vs 紧急」四象限图。在得知我是一个科技作者后，AI 自动把我列出的「撰写一个机器人方向稿件」列入了重要且紧急的象限中，而把寻找拳击场馆列入了不那么重要且不紧急的象限中，并在下面给出了自己的原因。\n在添加多条任务后，AI 还可以根据添加的任务，直接帮你规划出日程安排，重要紧急事项靠前，而不那么紧急的事项靠后。甚至还加入了一些不完全符合中国水土的考量——AI 把工作事项都尽量安排在了每天晚上五点之前，五点之后安排了健身和娱乐。\n甚至除了传统的日程软件的功能之外，Splitti 还会提供对于添加任务的分析——事业方向的任务过多了，也需要多安排一些朋友聚会；当日的情绪疏导——用户可以选择不同的 AI 导师，从幽默风趣型的，到正念冥想型的；还可以收到针对用户定制化的通知——Yuan，你想要力量的话，就应该赶紧来挑拳击设备了！\n笔者第一次感觉到 AI-Native 的应用的魅力。\n相比于传统 To-do List 软件，用户所需要付出的努力非常少，只需要用「人话」把自己想做的事，想长期实现的目标简单说一遍，而获得的体验，却是完全翻倍的。\n相比于传统更像「电子化日历」的应用，Splitti 更像是一个能听懂人话、但比人类更强的助手——它不会遗漏细节，也不会被复杂的规划问题搞得头疼。\n对人来说，添加一项新任务，往往意味着整个日程都需要重新调整：要重新评估每项任务的重要性和紧急性，考虑购物是否安排在促销日，健身是否避开生理期，最后才能决定新任务的最佳插入点。\n但对 AI 而言，这一切只需一秒，整个日程就能被即时、自动、合理地重新安排。\nAI-Native App 的一种新思路：不同档位 AI 进行不同定价\nSplitti 的另一个有趣之处，是它尝试了一种完全 AI-Native 的定价方式。\n通常情况下，To-do List App 有自己的一套定价方式。\n以 2013–2014 年就已推出的知名应用滴答清单为例，目前采用「免费+付费解锁高级功能」的模式：免费用户可以使用基础的日历视图，并创建有限数量的清单和任务；而成为高级会员后，才能解锁如持续提醒、时间段设置、高级数据统计、更大的任务和清单容量等功能。\n这样的定价策略，反映了传统的日程软件的电子工具属性——免费用户只能使用不那么好用的工具，而付费用户，则可以获得更强大的工具。\n而 Splitti 在这点上，设计理念是完全不同的。\n虽然 Splitti 的不同付费档位也存在一定的功能差异，但它的核心定价逻辑，并不在于「能用多少功能」，而在于「用的是哪种 AI」。\n免费用户几乎可以使用与付费用户相同的功能，但调用的是被称为「简单 AI 」的基础模型。中档付费用户则可以获得「更智能的 AI」，而最高档位的用户，使用的则是 Splitti 提供的「最先进的 AI」。\n在功能层面，最高档付费用户获得的也并不是更多的工具选项，而是更深度的 AI 交互权限——他们可以更频繁地与 AI 沟通，提出更复杂的请求，享受更个性化、更智能的任务规划体验。\n对 Splitti 来说，贵的不是功能多，而是你可以「更多地跟更聪明的大脑对话」。\n作为一个小众 app，这样的定价方式是不是能够获得接受还不明确，不过笔者在美区的 app 评论下，找到了一个有趣的评价：\n「我用了二十年的手机，这是我人生中第一次留下应用评论。我之所以写这条评论，是因为我觉得这个 App 对像我这样的人来说简直是救星。我有决策瘫痪、注意力缺陷障碍（ADHD），总是对生活感到极度压力大、难以招架。过去，我曾是个高效能人士，但自从有了孩子，加上每天被各种紧急事务压得喘不过气来，我的生活节奏彻底被打乱了。过去两年我几乎是在痛苦中熬过来的。\n我曾考虑过请一位生活教练，希望有人能帮助我找回动力、重新接触我热爱的事情，同时也帮我理清思路、保持条理。然而，当我得知报价在 6000 到 7000 美元之间时，我意识到这条路对我来说并不可行。\n我知道自己非常需要那种「有个人真正关心我、会问我怎么了、会追问细节、会提出前进建议」的帮助。所以我开始寻找带有 AI 辅助的任务管理工具，尝试了大概四款，最终选择了这一个。\n它真的非常棒，我目前还没有用完所有功能，但已经印象深刻。当然，它还有一些 bug 和小问题需要完善，毕竟这款应用还比较新。但我真的很认可他们的思路，也希望借由这条评论表达我的感谢，并为他们的成长和改进贡献一份力量。\n谢谢你们！」\n当用户真的能够将 app 与 life coach（生活教练）这样的服务开始对比的时候，或许 Splitti 已经成功了一半了。\nAI 时代的软件开发——或许从 Day One 就可以跨国\n相信读者或许注意到了，在本文的配图中，Splitti 的软件中，有时文字是中文，而有时文字是英文。\n这或许也是下一个时代的 AI 应用中，非常有趣的一点。\n在上一个时代中，如果想做出非常好的应用出海，翻译和本地化是非常重要的一点。而对于新时代的 AI 应用而言，却不一定完全如此。\n笔者在第一次使用 Splitti 的时候，使用的是 Splitti 的英文版本软件 。然而从一开始，笔者输入的个人简介，就是全中文输入。而在 AI 时代，这并没有任何影响。\n软件背后的 AI，认识每一种语言，虽然前端使用了英文提示，但无论你输入的是哪种小众的语言，并不会影响 AI 的核心功能，AI 仍然能我把任务进行成功分解，进行规划。\n对于应用出海而言，现在或许是前所未有的好时机。\n不过同时，用 AI 开发应用，也仍然存在许多不稳定性。\nSplitti 的评论中，也有不少评论都在批评软件的 bug。\n这与软件本身由两位独立开发者开发有关。作为一项准日程工具，Splitti 在功能上极其全面。不仅具有 AI 分解任务，AI 规划日程，AI 陪伴提醒这样的创新功能，还具备了比如「重要 vs 紧急」四象限、番茄钟、任务分析、白噪音冥想等一系列传统日程软件可能要付费获得，或者不会全面实现的功能。显然两位独立开发者的野心过于庞大，导致软件仍有不少 bug 影响使用。\n而同时，部分原因也仍然根植于 AI 应用开发无法绕开的 AI 本身的局限性中。\n如前面所提到，AI 本身虽然能读懂中文，有时候 AI 会选择用英文帮我分解任务，有时 AI 会选择用中文帮我分解任务，这完全无法预料。\n而在一些评论中，还有用户提到，有时 AI 设置的截止时间不对，用户手动调整时间的时候，AI 会忽略用户调整的时间，按照自己生成的截止时间规划日程。\n经过精调后，这些问题并非不可解决，不过对于新时代的 AI 开发者而言，要不断面临 AI 带来的未知性，将是一项永久的功课。\nAI 应用从卖生成能力走向卖推理能力\n在 Splitti 身上，笔者也看见了 AI 应用的未来。\n过去我们所熟悉的 AI，多是依赖其生成能力：生成对话，提供情绪价值；或者用来进行文字总结、润色，提升一定程度的生产力。但这些应用的核心，仍然是「生成内容」。\n而随着 OpenAI 的 o 系列、DeepSeek R1 等推理模型的逐步成型，AI 的「智力」实现了真正意义上的飞跃。我们终于可以开始依赖 AI，去完成那些过去对人类来说既繁琐又困难的任务——需要进行多个维度的考量最后做出判断的任务。\nSplitti 的特别并不在于它重新定义了日程工具的呈现方式，而在于它将任务分解、长期规划、日程安排——这些对人类来说难度较高的工作，交由 AI 处理。\n它不是在用户规划之后，用更漂亮的方式「重写」内容，而是从根本上，使用了 AI 的「大脑」来代替人类进行逻辑思考和规划。\n表面上，Splitti 似乎只是优化了交互方式——用户可以用自然语言来安排日程，使用体验更舒适；但实质上，它真正改变的是交付的内容：用户需要做的越来越少，而 AI 能承担的越来越多。\n这样的变化，正在各个行业发生。\n比如在 极客公园的采访 中，猿辅导的硬件负责人提到：在推理模型出现之前，AI 主要被用来解题和扩充题库，依赖的仍是生成能力。而现在，小猿 AI 会将用户的数据直接交给 AI，由它来判断用户不理解的知识点，并安排接下来的学习任务——这正是推理能力的体现。\n旅游行业也有类似趋势。生成旅行规划在 2023 年就已成为 AI 应用的重点方向之一。但当时的产品更多是重新包装网络信息，充其量告诉用户某地有哪些景点、评分如何。而进入推理时代，我们有望看到 AI 真正「理解人类」，为用户制定出合理而个性化的行程规划。\nAI 时代就是如此。看似没有太多变化，但实际已经走过沧海桑田。前一年 AI 能力尚不足以完成的，今年或许就可以了。\n我们曾一度觉得 AI 像是个「情商高、但做事不太靠谱」的搭子——擅长聊天、擅长安慰，却难以真正承担任务。\n而从今年开始，随着推理模型的成熟，这种印象或许将被颠覆：AI 的面孔开始更像一个智商高、逻辑缜密、执行力强的勤勉高管，能独立完成任务，也能做出判断和规划。\n*头图来源 ：AI 生成\n本文为极客公园原创文章，转载请联系极客君微信 geekparkGO",
        "desc": "作者 | Li Yuan编辑 | 郑玄你有没有一件事，因为做起来太麻烦，拖到一直都不想开始？好吧，笔者承认，我有这个问题。这也是笔者自从拥有智能手机以来，一直在不断尝试各种日程管理和 To-do List 应用的原因。不过笔者很快就发现，对于一个擅长规划的人而言，似乎只用一个日历，也已经能很好地规划自己的工作了。而对于一个本来就讨厌规划的人而言，添加任务，添加截止日期，添加子任务，添加截止日期，分配优先级，本身就是一项令人头疼到不想开始的事情。于是，我和日程软件的关系，最后变得很像一对怨偶——只有任务变得又紧急又多又重要的时候，我才会鼓起勇气，把一件一件任务登记到软件里，设置好截止日期和提醒时间。而只要能够稍得喘息，我就永远想不起来打开这个软件。而如果一件事情虽然重要，比如我知道我想学习拳击，但是这件事并不十分紧急，对我来说又很麻烦——又要去买装备又要去对比课程，哪个 To-do List 也很难帮我开启这一任务。作为一个日程管理 app 的资深用户，笔者本来已经对这个「老怨偶」不再抱有太多期望了。大多数 To-do List 的软件，功能都大同小异，区别无非是 UI 和使用上的繁琐程度。不过，最近，机缘巧合之下，笔者发现了一款 AI-native 的日程管理软件，让我突然眼前一亮。日程管理领域，早已有一整套成熟完整的理论体系，无论是「重要 vs 紧急」四象限理论、番茄工作法、还是 GTD 理论，都早在上世纪就已经被提出。而这款软件，却在这样一个「历史悠久、创新稀少」的领域中，依然借助 AI 做出了突破，甚至意外地，在我的日常生活里真正起到了点作用。AI-native 的日程软件长什么样？笔者是在小红书最开始发现了这款软件。名叫 Splitti，这款由国外独立开发者设计的日程管理软件，最先在 ADHD 社群中有了小范围的传播——ADHD 人群注意力不集中，因此对于日程管理软件本身的需求，也相对比较旺盛。而这款 app，主打的是能够使用 AI，帮助 ADHD 人群，更快地启动任务和安排生活。一打开这个 app，我就感受到了这个软件的与众不同之处。作为日程软件的老用户，笔者已经对日程软件的界面十分熟悉——一般不是一个日历，就是一个任务添加界面。而打开 Splitti，则很不一样——你被要求写一段自我介绍，让 AI 更好地了解你。不明所以，笔者填写了几个关键信息：「Li Yuan、女、科技作者、INTP」，并填写了一个规划痛点「养猫，猫会打扰我的工作。」接下来，出乎笔者的意料，app 马上根据笔者输入的内容，生成了一段非常长的对笔者个人的情况分析，包括「注意她可能喜欢深度专注，应该在交流中增加智识性内容。」等等。并马上提出了三个追问问题，包括「在做科技作者的过程中，你遇到的最大挑战是什么？」这种体验确实是在 AI 时代之前难以想象的。软件并不像之前的日程软件一样，提供的是一个标准化的工具体验，而更像一个真正的私人教练，在接触中，会选择先了解你的情况。而在获得笔者的私人情况后，Splitti 开始建议笔者增加一条新任务。任务可以直接用自然语言，甚至语音输入，直接输入关于这条任务，我的所有思考就可以了。接下来，AI 则根据它对我，和对人物的理解，直接将这个任务分成了多个子任务。除了分解任务之外，笔者还惊喜地发现，AI 已经为我的每个任务，规划了一个大概能完成的时间，并给他们自动设置了截止日期。每一个子任务，如果过于抽象，还可以点击，再次进行任务分解。比如「找到拳击课程」可以进一步拆解为「在网上调研」，「在线下调研」，「阅读评论」，「给场馆打电话」，「列出不同场馆的对比」。在任务被拆解到足够细之后，即使是启动困难的人，似乎也有了可以开始的动力。而 Splitti 正是用 AI 为用户垫好了这关键的一步。甚至在深度使用中，笔者发现，这样的任务拆解，甚至是根据个人使用定制化的——在笔者添加了一个写作任务之后， AI 进行任务拆解时，会单独拆解出一条任务：请寻找一个合适的工作环境，尽量免受猫咪打扰。使用越多，把自己的需求和困惑向 AI 讲解地越明确，AI 就会生成一个越完美的私人定制规划。笔者还惊喜地发现，AI 能做的还不仅如此。AI 还能为我的任务生成经典的「重要 vs 紧急」四象限图。在得知我是一个科技作者后，AI 自动把我列出的「撰写一个机器人方向稿件」列入了重要且紧急的象限中，而把寻找拳击场馆列入了不那么重要且不紧急的象限中，并在下面给出了自己的原因。在添加多条任务后，AI 还可以根据添加的任务，直接帮你规划出日程安排，重要紧急事项靠前，而不那么紧急的事项靠后。甚至还加入了一些不完全符合中国水土的考量——AI 把工作事项都尽量安排在了每天晚上五点之前，五点之后安排了健身和娱乐。甚至除了传统的日程软件的功能之外，Splitti 还会提供对于添加任务的分析——事业方向的任务过多了，也需要多安排一些朋友聚会；当日的情绪疏导——用户可以选择不同的 AI 导师，从幽默风趣型的，到正念冥想型的；还可以收到针对用户定制化的通知——Yuan，你想要力量的话，就应该赶紧来挑拳击设备了！笔者第一次感觉到 AI-Native 的应用的魅力。相比于传统 To-do List 软件，用户所需要付出的努力非常少，只需要用「人话」把自己想做的事，想长期实现的目标简单说一遍，而获得的体验，却是完全翻倍的。相比于传统更像「电子化日历」的应用，Splitti 更像是一个能听懂人话、但比人类更强的助手——它不会遗漏细节，也不会被复杂的规划问题搞得头疼。对人来说，添加一项新任务，往往意味着整个日程都需要重新调整：要重新评估每项任务的重要性和紧急性，考虑购物是否安排在促销日，健身是否避开生理期，最后才能决定新任务的最佳插入点。但对 AI 而言，这一切只需一秒，整个日程就能被即时、自动、合理地重新安排。AI-Native App 的一种新思路：不同档位 AI 进行不同定价Splitti 的另一个有趣之处，是它尝试了一种完全 AI-Native 的定价方式。通常情况下，To-do List App 有自己的一套定价方式。以 2013–2014 年就已推出的知名应用滴答清单为例，目前采用「免费+付费解锁高级功能」的模式：免费用户可以使用基础的日历视图，并创建有限数量的清单和任务；而成为高级会员后，才能解锁如持续提醒、时间段设置、高级数据统计、更大的任务和清单容量等功能。这样的定价策略，反映了传统的日程软件的电子工具属性——免费用户只能使用不那么好用的工具，而付费用户，则可以获得更强大的工具。而 Splitti 在这点上，设计理念是完全不同的。虽然 Splitti 的不同付费档位也存在一定的功能差异，但它的核心定价逻辑，并不在于「能用多少功能」，而在于「用的是哪种 AI」。免费用户几乎可以使用与付费用户相同的功能，但调用的是被称为「简单 AI 」的基础模型。中档付费用户则可以获得「更智能的 AI」，而最高档位的用户，使用的则是 Splitti 提供的「最先进的 AI」。在功能层面，最高档付费用户获得的也并不是更多的工具选项，而是更深度的 AI 交互权限——他们可以更频繁地与 AI 沟通，提出更复杂的请求，享受更个性化、更智能的任务规划体验。对 Splitti 来说，贵的不是功能多，而是你可以「更多地跟更聪明的大脑对话」。作为一个小众 app，这样的定价方式是不是能够获得接受还不明确，不过笔者在美区的 app 评论下，找到了一个有趣的评价：「我用了二十年的手机，这是我人生中第一次留下应用评论。我之所以写这条评论，是因为我觉得这个 App 对像我这样的人来说简直是救星。我有决策瘫痪、注意力缺陷障碍（ADHD），总是对生活感到极度压力大、难以招架。过去，我曾是个高效能人士，但自从有了孩子，加上每天被各种紧急事务压得喘不过气来，我的生活节奏彻底被打乱了。过去两年我几乎是在痛苦中熬过来的。我曾考虑过请一位生活教练，希望有人能帮助我找回动力、重新接触我热爱的事情，同时也帮我理清思路、保持条理。然而，当我得知报价在 6000 到 7000 美元之间时，我意识到这条路对我来说并不可行。我知道自己非常需要那种「有个人真正关心我、会问我怎么了、会追问细节、会提出前进建议」的帮助。所以我开始寻找带有 AI 辅助的任务管理工具，尝试了大概四款，最终选择了这一个。它真的非常棒，我目前还没有用完所有功能，但已经印象深刻。当然，它还有一些 bug 和小问题需要完善，毕竟这款应用还比较新。但我真的很认可他们的思路，也希望借由这条评论表达我的感谢，并为他们的成长和改进贡献一份力量。谢谢你们！」当用户真的能够将 app 与 life coach（生活教练）这样的服务开始对比的时候，或许 Splitti 已经成功了一半了。AI 时代的软件开发——或许从 Day One 就可以跨国相信读者或许注意到了，在本文的配图中，Splitti 的软件中，有时文字是中文，而有时文字是英文。这或许也是下一个时代的 AI 应用中，非常有趣的一点。在上一个时代中，如果想做出非常好的应用出海，翻译和本地化是非常重要的一点。而对于新时代的 AI 应用而言，却不一定完全如此。笔者在第一次使用 Splitti 的时候，使用的是 Splitti 的英文版本软件。然而从一开始，笔者输入的个人简介，就是全中文输入。而在 AI 时代，这并没有任何影响。软件背后的 AI，认识每一种语言，虽然前端使用了英文提示，但无论你输入的是哪种小众的语言，并不会影响 AI 的核心功能，AI 仍然能我把任务进行成功分解，进行规划。对于应用出海而言，现在或许是前所未有的好时机。不过同时，用 AI 开发应用，也仍然存在许多不稳定性。Splitti 的评论中，也有不少评论都在批评软件的 bug。这与软件本身由两位独立开发者开发有关。作为一项准日程工具，Splitti 在功能上极其全面。不仅具有 AI 分解任务，AI 规划日程，AI 陪伴提醒这样的创新功能，还具备了比如「重要 vs 紧急」四象限、番茄钟、任务分析、白噪音冥想等一系列传统日程软件可能要付费获得，或者不会全面实现的功能。显然两位独立开发者的野心过于庞大，导致软件仍有不少 bug 影响使用。而同时，部分原因也仍然根植于 AI 应用开发无法绕开的 AI 本身的局限性中。如前面所提到，AI 本身虽然能读懂中文，有时候 AI 会选择用英文帮我分解任务，有时 AI 会选择用中文帮我分解任务，这完全无法预料。而在一些评论中，还有用户提到，有时 AI 设置的截止时间不对，用户手动调整时间的时候，AI 会忽略用户调整的时间，按照自己生成的截止时间规划日程。经过精调后，这些问题并非不可解决，不过对于新时代的 AI 开发者而言，要不断面临 AI 带来的未知性，将是一项永久的功课。AI 应用从卖生成能力走向卖推理能力在 Splitti 身上，笔者也看见了 AI 应用的未来。过去我们所熟悉的 AI，多是依赖其生成能力：生成对话，提供情绪价值；或者用来进行文字总结、润色，提升一定程度的生产力。但这些应用的核心，仍然是「生成内容」。而随着 OpenAI 的 o 系列、DeepSeek R1 等推理模型的逐步成型，AI 的「智力」实现了真正意义上的飞跃。我们终于可以开始依赖 AI，去完成那些过去对人类来说既繁琐又困难的任务——需要进行多个维度的考量最后做出判断的任务。Splitti 的特别并不在于它重新定义了日程工具的呈现方式，而在于它将任务分解、长期规划、日程安排——这些对人类来说难度较高的工作，交由 AI 处理。它不是在用户规划之后，用更漂亮的方式「重写」内容，而是从根本上，使用了 AI 的「大脑」来代替人类进行逻辑思考和规划。表面上，Splitti 似乎只是优化了交互方式——用户可以用自然语言来安排日程，使用体验更舒适；但实质上，它真正改变的是交付的内容：用户需要做的越来越少，而 AI 能承担的越来越多。这样的变化，正在各个行业发生。比如在极客公园的采访中，猿辅导的硬件负责人提到：在推理模型出现之前，AI 主要被用来解题和扩充题库，依赖的仍是生成能力。而现在，小猿 AI 会将用户的数据直接交给 AI，由它来判断用户不理解的知识点，并安排接下来的学习任务——这正是推理能力的体现。旅游行业也有类似趋势。生成旅行规划在 2023 年就已成为 AI 应用的重点方向之一。但当时的产品更多是重新包装网络信息，充其量告诉用户某地有哪些景点、评分如何。而进入推理时代，我们有望看到 AI 真正「理解人类」，为用户制定出合理而个性化的行程规划。AI 时代就是如此。看似没有太多变化，但实际已经走过沧海桑田。前一年 AI 能力尚不足以完成的，今年或许就可以了。我们曾一度觉得 AI 像是个「情商高、但做事不太靠谱」的搭子——擅长聊天、擅长安慰，却难以真正承担任务。而从今年开始，随着推理模型的成熟，这种印象或许将被颠覆：AI 的面孔开始更像一个智商高、逻辑缜密、执行力强的勤勉高管，能独立完成任务，也能做出判断和规划。*头图来源 ：AI 生成本文为极客公园原创文章，转载请联系极客君微信 geekparkGO",
        "summary": "文章介绍了一款名为Splitti的AI日程管理软件，该软件通过AI技术帮助用户更高效地管理任务和日程，尤其对ADHD人群有帮助。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "DeepSeek 发布 Prover-V2 模型；小米首个推理大模型开源；饿了么宣布超百亿补贴加入外卖战局",
        "url": "http://www.geekpark.net/news/348950",
        "source": "极客公园",
        "hot": "",
        "time": "2025-05-01 01:09:56",
        "timestamp": 1746032996000,
        "published": "2025-05-01 01:09:56",
        "content": "DeepSeek 发布 Prover-V2 模型，参数量达 6710 亿\n4 月 30 日消息，DeepSeek 于 AI 开源社区 Hugging Face 上发布了一个名为 DeepSeek-Prover-V2-671B 的新模型。\n据悉，DeepSeek-Prover-V2-671B 使用了更高效的 safetensors 文件格式，并支持多种计算精度，方便模型更快、更省资源地训练和部署，参数达 6710 亿，或为去年发布的 Prover-V1.5 数学模型升级版本。在模型架构上，该模型使用了 DeepSeek-V3 架构，采用 MoE（混合专家）模式，具有 61 层 Transformer 层，7168 维隐藏层。同时支持超长上下文，最大位置嵌入达 16.38 万，使其能处理复杂的数学证明，并且采用了 FP8 量化，可通过量化技术减小模型大小，提高推理效率。（来源：新浪科技）\n小米开源「Xiaomi MiMo」大模型：为推理而生，以 7B 参数超越 OpenAI o1-mini\n4 月 30 日消息，小米大模型团队通过「Xiaomi MiMo」公众号宣布，小米开源首个「为推理而生」的大模型 Xiaomi MiMo，联动预训练到后训练，全面提升推理能力。据介绍，MiMo 是来自全新成立不久的「小米大模型 Core 团队」的初步尝试。\n在数学推理（AIME 24-25）和代码竞赛（LiveCodeBench v5）公开测评集上，MiMo 仅用 7B 的参数规模，超越了 OpenAI 的闭源推理模型 o1-mini 和阿里 Qwen 更大规模的开源推理模型 QwQ-32B-Preview。\n官方表示，MiMo 推理能力的提升，由预训练和后训练阶段中数据和算法等多层面的创新联合驱动，包括：\n预训练：核心是让模型见过更多推理模式\n数据：着重挖掘富推理语料，并合成约 200B tokens 推理数据。\n训练：进行了三阶段训练，逐步提升训练难度，总训练 25T tokens。\n后训练：核心是高效稳定的强化学习算法和框架\n算法：提出 Test Difficulty Driven Reward 来缓解困难算法问题中的奖励稀疏问题，并引入 Easy Data Re-Sampling 策略，以稳定 RL 训练。\n框架：设计了 Seamless Rollout 系统，使得 RL 训练加速 2.29 倍，验证加速 1.96 倍。（来源：IT 之家）\n可生成 AI 播客：谷歌 NotebookLM 音频概览功能新增 76 种语言支持，包含中文\n4 月 30 日消息，谷歌宣布其基于人工智能的笔记和研究助手工具 NotebookLM 的「音频概览（Audio Overviews）」功能新增 76 种语言支持。该功能于去年推出，旨在通过人工智能虚拟主持人根据用户上传到 NotebookLM 的文档（如课程阅读材料或法律摘要）生成播客，帮助用户以另一种方式理解和消化文档中的信息。\n谷歌表示，此前「音频概览」功能仅支持用户账户所设置的首选语言。如今，公司新增了「输出语言」选项，用户可以自由选择生成「音频概览」的语言。谷歌强调，用户可以随时更改语言设置，这样就能根据需要轻松创建多语言内容或学习材料。\n谷歌在一篇博客文章中举例说明了这一功能的实用性：「例如，一位准备关于亚马逊雨林课程的教师可以与学生共享多种语言的资源，比如葡萄牙语纪录片、西班牙语研究报告和英语学习报告。学生们可以将这些资料上传到 NotebookLM，并在他们偏好的语言中生成关键要点的音频概览。」（来源：IT 之家）\nMeta 公布 2025 财年第 1 财季财报：营收 423.14 美元，同比增长 16%\n5 月 1 日消息，Meta 公司4 月 30 日发布博文，公布了 2025 财年第 1 财季（截至 3 月 31 日）的财报业绩，营收达到 423.14 亿美元，同比增长 16%；净利润 166.44 亿美元，同比增长 35%。\nMeta 在 2025 财年第 1 财季交出了一份亮眼的成绩单。总营收达到 423.14 亿美元（IT 之家注：现汇率约合 3078.03 亿元人民币），较去年同期的 364.55 亿美元增长 16%，若按固定汇率计算，增长率更是高达 19%。\n净利润从去年的 123.69 亿美元跃升至 166.44 亿美元（现汇率约合 1210.73 亿元人民币），增幅达 35%；每股摊薄收益（EPS）从 4.71 美元提升至 6.43 美元，增长 37%；运营利润为 175.55 亿美元，同比增长 27%，运营利润率从 38% 提升至 41%。\nMeta 旗下应用家族（Family of Apps）的日活跃用户（DAP）平均达 34.3 亿，同比增长 6%；广告曝光量（Ad Impressions）同比增长 5%，每条广告平均价格上涨 10%，推动广告收入达到 413.92 亿美元，占总营收的绝大部分。\nMeta AI 的月活跃用户接近 10 亿，显示其在人工智能领域的快速布局。此外，公司现金流表现强劲，经营活动现金流为 240.26 亿美元，自由现金流为 103.34 亿美元，现金及有价证券总额达 702.3 亿美元。（来源：IT 之家）\n微软第三季度营收 700.7 亿美元，高于市场预期\n微软第三季度营收 700.7 亿美元，预估 684.8 亿美元；第三季度每股收益 3.46 美元；第三季度智能云业务营收 268 亿美元，预估 259.9 亿美元；第三财季云营收 424 亿美元，分析师预期 422.2 亿美元；第三财季 Azure 增长对人工智能（AI）业务贡献 16 个百分点，分析师预期公司 15.6 个百分点。美股盘后涨超 6%。（来源：新浪科技）\n苹果加速印度布局，塔塔 / 富士康新工厂被曝组装生产 iPhone 16e 等机型\n4 月 30 日消息，路透社 4 月 29 日发布博文，报道称苹果公司在印度南部的两家新工厂已启动生产。其中一家由塔塔电子（Tata Electronics）运营的工厂已开始生产老款 iPhone，而另一家由富士康（Foxconn）建设的工厂将在 5 月启动发货。\nIT 之家援引博文介绍，位于印度南部泰米尔纳德邦霍苏尔（Hosur）的塔塔电子新工厂已于近日投产，首批生产线专注于生产老款 iPhone 型号。\n而富士康在卡纳塔克邦班加罗尔投资 26 亿美元建设的新工厂，也将在数日内启动首条生产线。\n据悉，该工厂每小时可生产 300 至 500 台 iPhone，首批产品包括 iPhone 16 和 16e 型号。消息人士透露，该富士康工厂预计在 2027 年 12 月全面建成，届时将创造约 5 万个就业机会。（来源：IT 之家）\n消息称宁德时代拟下月在港上市，或成四年来最大规模新股发行\n4 月 30 日消息，据路透社援引两位知情人士消息称，电池制造巨头宁德时代计划于下月启动在香港的上市程序，预计将成为该市四年来规模最大的股票发行。\n消息人士称，此次交易的建簿过程——即邀请投资者对股权发行进行投标的过程，预计将于 5 月 12 日起始的一周开始。此前另有知情人士透露，此次发行可能筹集至少 50 亿美元（IT 之家注：现汇率约合 363.71 亿元人民币）。\n宁德时代未立即回应置评请求。\n其中一位消息人士补充说，宁德时代建簿的规模和时间可能会发生变化。\n报道称，宁德时代此次登陆港股将成为近 4 年香港规模最大的一次上市。2021 年，快手通过首次公开募股筹集了 62 亿美元（现汇率约合 451 亿元人民币）。\n宁德时代此前在一份监管文件中表示，筹集的部分资金将用于在匈牙利建设一座价值 73 亿欧元（现汇率约合 604.72 亿元人民币）的电池工厂。（来源：IT 之家）\n饿了么宣布超百亿补贴加入外卖战局\n外卖战场的热度再度加码。4 月 30 日，饿了么宣布进一步加大平台补贴力度，即日起开启平台「饿补超百亿」大促。针对补贴，饿了么表示不打竞争口水仗，「只发真福利」。目前，饿了么 App 已上线「超百亿」口令词入口。（来源：富途牛牛）\n英伟达新工具开放使用，可根据 3D 场景创建 AI 图像，配置要求 RTX 4080\n4 月 30 日消息，英伟达推出了一款新工具，允许开发者首先在 3D 中创建图像，然后生成 AI 图像。\n这个工具名为 Nvidia AI Blueprint for 3D-guided generative AI，4 月 30 日起即可下载，适用于配备 RTX 4080 GPU 或更高型号的计算机，它通过将 Blender 的 3D 建模软件与 Black Forest Lab 的 FLUX.1 图像生成器连接起来工作。\n用户可以使用 Blender 中的 3D 对象（如建筑物、植物、动物和车辆）绘制场景，然后将其用作创建 2D 图像的参考。用户可以手动调整观看位置或某些对象应放置的位置，与仅使用文本描述相比，这种方法在生成 2D 图像时可以提供更多细节控制。\n例如，如果你脑海中有一个非常具体的城市图像——建筑物的形状和高度，显示的树木或汽车数量，甚至你观看的角度，此时就可以使用该工具在 Blender 中手动创建一个大概的样子。（来源：IT 之家）\n消息称 Meta 第三代雷朋联名智能眼镜将于 10 月发售，配单色显示屏及手环控制器\n据彭博社报道，Meta 旗下第三代 Ray-Ban 雷朋联名智能眼镜将于今年 10 月发售，目前 Meta 已安排部分员工在周末加班，加班加点研发这款设备。\n该眼镜相比前两代最大的特色就是配备了一块单色（预计为绿色）显示面板，同时带有可以佩戴在手腕上的「手环」风格控制器，定价在 1000 至 1400 美元（IT 之家注：现汇率约合 7274 至 10184 元人民币）之间。\n据悉，第三代雷朋联名智能眼镜将内置相机、照片、地图等应用，同时还支持快速查看来自手机应用的通知。该眼镜内置安卓系统，但无法安装第三方 App，同时眼镜的各项功能将「严重依赖手机」。 Meta「内部人士」透露，第三代雷朋联名智能眼镜拍照质量将「媲美 iPhone 13」。（来源：IT 之家）\n荣耀手表全新系列官宣，两款新品将至\n在4 月 30 日下午的荣耀 MagicBook Pro 16 2025 新品发布会上，荣耀预告了荣耀手表全新系列。\n从预告海报可以看到，荣耀手表全新系列将包含两款产品，一款是硬朗风格，另一款是圆润风格。\n外观方面，新品提供棕色和黑色两款配色，手表屏幕覆盖蓝宝石玻璃，表壳则采用钛合金材质，这款新品的续航时间据称可以达到 15 天。\n功能上，新品支持自由潜水等 100 多种运动模式，支持快速健康扫描、健康早晨报告以及全天健康追踪等。（来源：IT 之家）\n纽约地铁探索引入 AI 技术：提前预警异常行为，预防犯罪发生\n美国纽约大都会运输署（MTA）表示，其正在探索使用人工智能系统对该市地铁站台上的犯罪和危险行为进行「预测性预防」。\nMTA 首席安全官迈克尔・肯珀（Michael Kemper）表示，该机构正在「研究并试点使用人工智能等技术，以感知地铁站台上可能出现的麻烦或不当行为」。他在周一的 MTA 安全委员会会议上解释说：「如果有人行为异常、失去理智，这可能会触发警报，从而促使安保人员或警方采取行动。」他强调，警方可能会「在事情发生前」就做出反应。\n肯珀补充道：「人工智能是未来。」他提到，MTA 目前正在与科技公司合作，研究「什么样的技术可以在地铁系统中发挥作用」。不过，他并未透露 MTA 正在与哪些公司合作，人工智能将如何实施，以及人工智能摄像头将被期望检测到的具体行为类型。（来源：IT 之家）",
        "desc": "DeepSeek 发布 Prover-V2 模型，参数量达 6710 亿4 月 30 日消息，DeepSeek 于 AI 开源社区 Hugging Face 上发布了一个名为 DeepSeek-Prover-V2-671B 的新模型。据悉，DeepSeek-Prover-V2-671B 使用了更高效的 safetensors 文件格式，并支持多种计算精度，方便模型更快、更省资源地训练和部署，参数达 6710 亿，或为去年发布的 Prover-V1.5 数学模型升级版本。在模型架构上，该模型使用了 DeepSeek-V3 架构，采用 MoE（混合专家）模式，具有 61 层 Transformer 层，7168 维隐藏层。同时支持超长上下文，最大位置嵌入达 16.38 万，使其能处理复杂的数学证明，并且采用了 FP8 量化，可通过量化技术减小模型大小，提高推理效率。（来源：新浪科技）小米开源「Xiaomi MiMo」大模型：为推理而生，以 7B 参数超越 OpenAI o1-mini4 月 30 日消息，小米大模型团队通过「Xiaomi MiMo」公众号宣布，小米开源首个「为推理而生」的大模型 Xiaomi MiMo，联动预训练到后训练，全面提升推理能力。据介绍，MiMo 是来自全新成立不久的「小米大模型 Core 团队」的初步尝试。在数学推理（AIME 24-25）和代码竞赛（LiveCodeBench v5）公开测评集上，MiMo 仅用 7B 的参数规模，超越了 OpenAI 的闭源推理模型 o1-mini 和阿里 Qwen 更大规模的开源推理模型 QwQ-32B-Preview。官方表示，MiMo 推理能力的提升，由预训练和后训练阶段中数据和算法等多层面的创新联合驱动，包括：预训练：核心是让模型见过更多推理模式数据：着重挖掘富推理语料，并合成约 200B tokens 推理数据。训练：进行了三阶段训练，逐步提升训练难度，总训练 25T tokens。后训练：核心是高效稳定的强化学习算法和框架算法：提出 Test Difficulty Driven Reward 来缓解困难算法问题中的奖励稀疏问题，并引入 Easy Data Re-Sampling 策略，以稳定 RL 训练。框架：设计了 Seamless Rollout 系统，使得 RL 训练加速 2.29 倍，验证加速 1.96 倍。（来源：IT 之家）可生成 AI 播客：谷歌 NotebookLM 音频概览功能新增 76 种语言支持，包含中文4 月 30 日消息，谷歌宣布其基于人工智能的笔记和研究助手工具 NotebookLM 的「音频概览（Audio Overviews）」功能新增 76 种语言支持。该功能于去年推出，旨在通过人工智能虚拟主持人根据用户上传到 NotebookLM 的文档（如课程阅读材料或法律摘要）生成播客，帮助用户以另一种方式理解和消化文档中的信息。谷歌表示，此前「音频概览」功能仅支持用户账户所设置的首选语言。如今，公司新增了「输出语言」选项，用户可以自由选择生成「音频概览」的语言。谷歌强调，用户可以随时更改语言设置，这样就能根据需要轻松创建多语言内容或学习材料。谷歌在一篇博客文章中举例说明了这一功能的实用性：「例如，一位准备关于亚马逊雨林课程的教师可以与学生共享多种语言的资源，比如葡萄牙语纪录片、西班牙语研究报告和英语学习报告。学生们可以将这些资料上传到 NotebookLM，并在他们偏好的语言中生成关键要点的音频概览。」（来源：IT 之家）Meta 公布 2025 财年第 1 财季财报：营收 423.14 美元，同比增长 16%5 月 1 日消息，Meta 公司4 月 30 日发布博文，公布了 2025 财年第 1 财季（截至 3 月 31 日）的财报业绩，营收达到 423.14 亿美元，同比增长 16%；净利润 166.44 亿美元，同比增长 35%。Meta 在 2025 财年第 1 财季交出了一份亮眼的成绩单。总营收达到 423.14 亿美元（IT 之家注：现汇率约合 3078.03 亿元人民币），较去年同期的 364.55 亿美元增长 16%，若按固定汇率计算，增长率更是高达 19%。净利润从去年的 123.69 亿美元跃升至 166.44 亿美元（现汇率约合 1210.73 亿元人民币），增幅达 35%；每股摊薄收益（EPS）从 4.71 美元提升至 6.43 美元，增长 37%；运营利润为 175.55 亿美元，同比增长 27%，运营利润率从 38% 提升至 41%。Meta 旗下应用家族（Family of Apps）的日活跃用户（DAP）平均达 34.3 亿，同比增长 6%；广告曝光量（Ad Impressions）同比增长 5%，每条广告平均价格上涨 10%，推动广告收入达到 413.92 亿美元，占总营收的绝大部分。Meta AI 的月活跃用户接近 10 亿，显示其在人工智能领域的快速布局。此外，公司现金流表现强劲，经营活动现金流为 240.26 亿美元，自由现金流为 103.34 亿美元，现金及有价证券总额达 702.3 亿美元。（来源：IT 之家）微软第三季度营收 700.7 亿美元，高于市场预期微软第三季度营收 700.7 亿美元，预估 684.8 亿美元；第三季度每股收益 3.46 美元；第三季度智能云业务营收 268 亿美元，预估 259.9 亿美元；第三财季云营收 424 亿美元，分析师预期 422.2 亿美元；第三财季 Azure 增长对人工智能（AI）业务贡献 16 个百分点，分析师预期公司 15.6 个百分点。美股盘后涨超 6%。（来源：新浪科技）苹果加速印度布局，塔塔 / 富士康新工厂被曝组装生产 iPhone 16e 等机型4 月 30 日消息，路透社 4 月 29 日发布博文，报道称苹果公司在印度南部的两家新工厂已启动生产。其中一家由塔塔电子（Tata Electronics）运营的工厂已开始生产老款 iPhone，而另一家由富士康（Foxconn）建设的工厂将在 5 月启动发货。IT 之家援引博文介绍，位于印度南部泰米尔纳德邦霍苏尔（Hosur）的塔塔电子新工厂已于近日投产，首批生产线专注于生产老款 iPhone 型号。而富士康在卡纳塔克邦班加罗尔投资 26 亿美元建设的新工厂，也将在数日内启动首条生产线。据悉，该工厂每小时可生产 300 至 500 台 iPhone，首批产品包括 iPhone 16 和 16e 型号。消息人士透露，该富士康工厂预计在 2027 年 12 月全面建成，届时将创造约 5 万个就业机会。（来源：IT 之家）消息称宁德时代拟下月在港上市，或成四年来最大规模新股发行4 月 30 日消息，据路透社援引两位知情人士消息称，电池制造巨头宁德时代计划于下月启动在香港的上市程序，预计将成为该市四年来规模最大的股票发行。消息人士称，此次交易的建簿过程——即邀请投资者对股权发行进行投标的过程，预计将于 5 月 12 日起始的一周开始。此前另有知情人士透露，此次发行可能筹集至少 50 亿美元（IT 之家注：现汇率约合 363.71 亿元人民币）。宁德时代未立即回应置评请求。其中一位消息人士补充说，宁德时代建簿的规模和时间可能会发生变化。报道称，宁德时代此次登陆港股将成为近 4 年香港规模最大的一次上市。2021 年，快手通过首次公开募股筹集了 62 亿美元（现汇率约合 451 亿元人民币）。宁德时代此前在一份监管文件中表示，筹集的部分资金将用于在匈牙利建设一座价值 73 亿欧元（现汇率约合 604.72 亿元人民币）的电池工厂。（来源：IT 之家）饿了么宣布超百亿补贴加入外卖战局外卖战场的热度再度加码。4 月 30 日，饿了么宣布进一步加大平台补贴力度，即日起开启平台「饿补超百亿」大促。针对补贴，饿了么表示不打竞争口水仗，「只发真福利」。目前，饿了么 App 已上线「超百亿」口令词入口。（来源：富途牛牛）英伟达新工具开放使用，可根据 3D 场景创建 AI 图像，配置要求 RTX 40804 月 30 日消息，英伟达推出了一款新工具，允许开发者首先在 3D 中创建图像，然后生成 AI 图像。这个工具名为 Nvidia AI Blueprint for 3D-guided generative AI，4 月 30 日起即可下载，适用于配备 RTX 4080 GPU 或更高型号的计算机，它通过将 Blender 的 3D 建模软件与 Black Forest Lab 的 FLUX.1 图像生成器连接起来工作。用户可以使用 Blender 中的 3D 对象（如建筑物、植物、动物和车辆）绘制场景，然后将其用作创建 2D 图像的参考。用户可以手动调整观看位置或某些对象应放置的位置，与仅使用文本描述相比，这种方法在生成 2D 图像时可以提供更多细节控制。例如，如果你脑海中有一个非常具体的城市图像——建筑物的形状和高度，显示的树木或汽车数量，甚至你观看的角度，此时就可以使用该工具在 Blender 中手动创建一个大概的样子。（来源：IT 之家）消息称 Meta 第三代雷朋联名智能眼镜将于 10 月发售，配单色显示屏及手环控制器据彭博社报道，Meta 旗下第三代 Ray-Ban 雷朋联名智能眼镜将于今年 10 月发售，目前 Meta 已安排部分员工在周末加班，加班加点研发这款设备。该眼镜相比前两代最大的特色就是配备了一块单色（预计为绿色）显示面板，同时带有可以佩戴在手腕上的「手环」风格控制器，定价在 1000 至 1400 美元（IT 之家注：现汇率约合 7274 至 10184 元人民币）之间。据悉，第三代雷朋联名智能眼镜将内置相机、照片、地图等应用，同时还支持快速查看来自手机应用的通知。该眼镜内置安卓系统，但无法安装第三方 App，同时眼镜的各项功能将「严重依赖手机」。 Meta「内部人士」透露，第三代雷朋联名智能眼镜拍照质量将「媲美 iPhone 13」。（来源：IT 之家）荣耀手表全新系列官宣，两款新品将至在4 月 30 日下午的荣耀 MagicBook Pro 16 2025 新品发布会上，荣耀预告了荣耀手表全新系列。从预告海报可以看到，荣耀手表全新系列将包含两款产品，一款是硬朗风格，另一款是圆润风格。外观方面，新品提供棕色和黑色两款配色，手表屏幕覆盖蓝宝石玻璃，表壳则采用钛合金材质，这款新品的续航时间据称可以达到 15 天。功能上，新品支持自由潜水等 100 多种运动模式，支持快速健康扫描、健康早晨报告以及全天健康追踪等。（来源：IT 之家）纽约地铁探索引入 AI 技术：提前预警异常行为，预防犯罪发生美国纽约大都会运输署（MTA）表示，其正在探索使用人工智能系统对该市地铁站台上的犯罪和危险行为进行「预测性预防」。MTA 首席安全官迈克尔・肯珀（Michael Kemper）表示，该机构正在「研究并试点使用人工智能等技术，以感知地铁站台上可能出现的麻烦或不当行为」。他在周一的 MTA 安全委员会会议上解释说：「如果有人行为异常、失去理智，这可能会触发警报，从而促使安保人员或警方采取行动。」他强调，警方可能会「在事情发生前」就做出反应。肯珀补充道：「人工智能是未来。」他提到，MTA 目前正在与科技公司合作，研究「什么样的技术可以在地铁系统中发挥作用」。不过，他并未透露 MTA 正在与哪些公司合作，人工智能将如何实施，以及人工智能摄像头将被期望检测到的具体行为类型。（来源：IT 之家）",
        "summary": "DeepSeek发布参数达6710亿的Prover-V2模型，小米开源首个推理大模型Xiaomi MiMo，饿了么宣布超百亿补贴加入外卖战局。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "发布 Qwen3，阿里云拉开新一轮开源模型竞赛的序幕",
        "url": "http://www.geekpark.net/news/348949",
        "source": "极客公园",
        "hot": "",
        "time": "2025-04-30 15:40:40",
        "timestamp": 1745998840000,
        "published": "2025-04-30 15:40:40",
        "content": "2025 年已经过去 1/3，如果用关键词来概括 AI 领域的发展你会想到什么？这是我想到的：开源、创新加速加速加速。\n2 月是「DeepSeek」的，R1 以所有人意想不到的方式，让全球执牛耳的 AI 开发者、创业者、投资人把目光锁定在「DeepSeek」「中国」「开源」上。\n4 月是「开源模型」的，发令枪是 Meta 喊的。被 DeepSeek 盖过风头后，2025 年 2 月 19 日，坐不住的 Meta 率先官宣——首个生成式 AI 开发者大会 LlamaCon 将于当地 4 月 29 日（北京时间 4 月 30 日）举行，颇有重新夺回「AI 开源界老大」江湖地位的意欲。\n但 AI 领域的产品发布节奏就是很微妙，什么时候发布似乎取决于对手的动作，作为一种心照不宣的默契，Meta 一声枪响让 4 月底成为开源模型的主场。\n整个 4 月甚至更早，AI 开发者们都在各大社交平台「蹲」开源领域「三大头牌」的新发布：DeepSeek-R2、Qwen3 以及 Llama4。Llama4 由于本月初的发布低于预期，似乎少了一些热度。\n目前看起来，4 月底最受关注的还是中国队，R2 呼之欲出，Qwen3 终于来了。\n4 月 29 日凌晨 5 点，阿里巴巴开源新一代通义千问模型 Qwen3，参数量仅为 DeepSeek-R1 的 1/3，成本大幅下降，性能全面超越 R1、OpenAI-o1 等全球顶尖模型，登顶全球最强开源模型。X 平台的开发者网友甚至把今天定义为「Happy Qwen3 Day」，不仅因为 Qwen3 全面超越 R1，更因为 Qwen3 家族的多尺寸、内置 MCP 支持、支持混合推理等实用性的功能点。\n官方技术报告进一步给出了 Qwen3 的几大亮点：\n「探索智能上限」再突破：通过扩大预训练和强化学习的规模，实现了更高层次的智能；\n国内首个「混合推理模型」：无缝集成了思考模式与非思考模式，为用户提供了灵活控制思考预算的能力；\n增强了 Agent 能力：正从专注于训练模型的时代过渡到以训练 Agent 为中心的时代。\n对于 Qwen3，个人用户现在就可以在「通义」APP 或 chat.qwen.ai 网页直接体验，夸克也即将全线接入 Qwen3。开发者和企业则可以免费在魔搭社区、HuggingFace 等平台下载模型并商用，或通过阿里云百炼调用 Qwen3 的 API 服务。\n憋了这么久的 Qwen3 到底怎么样？又代表哪些模型发展的趋势？\n01 Qwen3，登顶全球最强开源模型\nQwen3 包含 2 个 MoE 和 6 个密集模型，阿里云开源了两个 MoE 模型的权重，六个 Dense 模型也已开源，包括 Qwen3-32B、Qwen3-14B、Qwen3-8B、Qwen3-4B、Qwen3-1.7B 和 Qwen3-0.6B，均在 Apache 2.0 许可下开源。\n其中，旗舰型号 Qwen3-235B-A22B 参数量仅为 DeepSeek-R1 的 1/3，成本大幅下降，性能全面超越 R1、OpenAI-o1 等全球顶尖模型，登顶全球最强开源模型。\n此外，据阿里云官方介绍，Qwen3 是国内首个「混合推理模型」。「快思考」与「慢思考」集成进同一个模型，对简单需求可低算力「秒回」答案，对复杂问题可多步骤「深度思考」，大大节省算力消耗。\nQwen3 在推理、指令遵循、工具调用、多语言能力等方面均大幅增强，创下所有国产模型及全球开源模型的性能新高：在奥数水平的 AIME25 测评中，Qwen3 斩获 81.5 分，刷新开源纪录；在考察代码能力的 LiveCodeBench 评测中，Qwen3 突破 70 分大关，表现甚至超过 Grok3；在评估模型人类偏好对齐的 ArenaHard 测评中，Qwen3 以 95.6 分超越 OpenAI-o1 及 DeepSeek-R1。\n性能大幅提升的同时，Qwen3 的部署成本还大幅下降，仅需 4 张 H20 即可部署千问 3 满血版，显存占用仅为性能相近模型的三分之一。\nQwen3 性能｜图片来源：阿里云\n此外，小型 MoE 模型 Qwen3-30B-A3B 的激活参数数量是 QwQ-32B 的 10%，表现更胜一筹，甚至像 Qwen3-4B 这样的小模型也能匹敌 Qwen2.5-72B-Instruct 的性能。\n据介绍，Qwen3-235B-A22B 是一个拥有 2350 多亿总参数和 220 多亿激活参数的大模型；Qwen3-30B-A3B 则是一个拥有约 300 亿总参数和 30 亿激活参数的小型 MoE 模型。\n得益于在预训练、大规模强化学习和推理模式整合方面取得的显著进展，Qwen3 主打「思考更深、行动更快」，更好地构建 AI 应用。Qwen3 预训练数据量达 36T，并在后训练阶段多轮强化学习，将非思考模式无缝整合到思考模型中。\n值得注意的是，这次 Qwen3 的发布，主打混合推理，但是需要思考的长度最短也是 1024tokens，否则如果问题所需要的推理预算用不满 1024tokens，根本感受不到可以调节精度的混合推理模型的好。也就无法发挥用 Qwen3 不同程度的思考，灵活满足 AI 应用和不同场景对性能和成本的多样需求。\n截图来源：X\n02 大模型全面转向「混合推理模型」和「Agent」\n在 Qwen3 发布的前一天，X 平台已有「行业人士」——日本的大模型厂商 SakanaAI 的一位工程师敏锐地捕捉到了 Qwen3 的重点。当天，在 AI 领域最重要的学术会议之一 ICLR 2025 的一个工作坊上，阿里云通义实验室通义千问负责人林俊旸透露了 Qwen 的下一步方向：推理模型和非推理模型的统一，以及面向 agent 的大模型。\n这正是今天发布的 Qwen3 最大的两个特点，同时也是大模型厂商们正在集体发生的转向。\n2025 年 2 月 25 日，Anthropic 发布了最新的旗舰模型 Claude 3.7 Sonnet，同时也称作是市场上首个混合推理模型。这意味着 Claude 3.7 Sonnet 能够生成即时的响应（快思考），也可以进行延展的、逐步的思考（慢思考）。API 用户还可以细粒度地控制模型的思考时长；当给定更长的思考时间，理论上会有更高质量的答案。\nAnthropic 表示，混合推理模型的架构代表下一代前沿模型，可以让模型像人类用同一个大脑一样，既能快速反应又能深度思考，这既能为用户创造更无缝的体验，也能让用户通过 API 使用 Claude 3.7 Sonnet 时，可以控制思考的预算。比如：可以告诉 Claude 最多思考 N 个 token，N 的取值可以达到其输出限制的 128K token，从而在回答质量与速度（及成本）之间进行权衡。\n「混合推理架构」也得到了 OpenAI 的青睐。Sam Altman 在更早的时间看到，当前的模型和产品供应已经变得非常复杂，希望 AI 能「开箱即用」、简化产品供应，「我们和你一样讨厌模型选择器，想要回归神奇的统一智能，之后，我们的一个重要目标是通过创建能够使用我们所有工具、知道何时需要长时间思考或不需要的系统，统一 o 系列模型和 GPT 系列模型，整体上能广泛适用于各种任务。」\n就像在 DeepSeek-R1 里一样，点选「深度思考」背后调用的是推理模型 R1 做的长推理，不选则调用的是基座模型 V3 即时生成的答案。现在，模型厂商把「思考的颗粒度」这个选择权更灵活、广泛地交给用户来控制推理预算。\n在 Qwen3 中，可以滑动「思考预算」的按钮，来控制思考的最大长度，从而匹配合适的推理质量和成本。\n在思考模式下，Qwen3 模型会逐步推理，经过深思熟虑后给出最终答案，适合需要深入思考的复杂问题。在非思考模式下，模型提供快速、近乎即时的响应，适用于那些对速度要求高于深度的简单问题。这种灵活性使用户能够根据具体任务控制模型进行「思考」的程度。这两种模式的结合大大增强了模型实现稳定且高效的「思考预算」控制能力，在成本效益和推理质量之间实现更优的平衡。\n另一个模型厂商的转向则是 Agent。随着 Manus 验证了 Claude 3.5 Sonnet 达到了通用 agent 的一些能力，加上模型调用工具、实现 agent 能力的统一协议——MCP 在越来越大的范围内被拥抱，下一代模型要面向 agent、面向实际场景来优化。\n就 Qwen3 来说，正在迈向以训练 Agent 为中心的阶段，当前 Qwen3 优化了 Agent 和 代码能力，同时也加强了对 MCP 的支持。据称，Qwen3 原生支持 MCP 协议，并具备强大的工具调用（function calling）能力，结合封装了工具调用模板和工具调用解析器的 Qwen-Agent 框架，将大大降低编码复杂性，实现高效的手机及电脑 Agent 操作等任务。\n在该示例中，Qwen3 思考并自主调用工具到 Github 数开源模型获得的 star，继续思考并调用绘图工具制作图片，并调用工具保存。｜视频来源：阿里云\n03 开源模型新一轮竞赛开启\nQwen3 的发布，意味着开源模型领域新一轮「三国杀」已然开始。\n事实上，随着 DeepSeek 的横空出世，加上 OpenAI、字节等大厂调整对开源的态度，开源已然成为大模型赛道的大势所趋。而 Llama、Qwen 和 DeepSeek，正是目前开源领域最有竞争力的玩家。\nHugging Face 联合创始人、CEO Clement Delangue 发推暗示 DeepSeek 即将带来新发布。｜截图来源：X\n而此前 OpenAI 和 DeepSeek 的成功已经证明，互联网时代的生态、用户和产品壁垒，今天在 AI 时代并没有互联网时代那样牢不可摧，模型能力才是基础大模型公司的核心竞争力。而 Llama、Qwen 和 DeepSeek 的胜者，有可能在下一个发布周期到来前（至少在 OpenAI 的开源模型发布前），成为整个 AI 行业的引领者。\n虽然新一代模型能力的强弱，还要等待 Llama 和 DeepSeek 的发布，但值得关注的是，这三家开源模型厂商的生态策略亦有差异，这点从模型的侧重点就能看出端倪。\nDeepSeek 和 Meta 的侧重点也有不同，但一个共同点都是不太重视 ToB，至少是在服务生态的建设上并不成功。而这点也是 Qwen 和其背后的阿里云最重视的部分。\n极客公园曾在此前的文章里写过，脱胎于阿里云 Qwen，是最有以开源模型技术领先性、广泛全面开源的策略，追求生态建设的架势。阿里的 AI 战略里除了追求 AGI，也同样重视 AI 基础设施建设，以及更上层的与阿里的电商、钉钉、夸克等 AI 应用的结合。\n此前，阿里云智能集团资深副总裁、公共云事业部总裁刘伟光表示，「阿里云是全世界唯一一家积极研发基础大模型并全方位开源、全方位贡献的云计算厂商。」\n而 Qwen 模型下载量和衍生模型数量这两个衡量的生态的指标也同样领先。根据阿里云官方的最新数据，阿里通义已开源 200 余个模型，全球下载量超 3 亿次，千问衍生模型数超 10 万个，已经超越 Llama 位居全球开源模型的第一。\n而新模型选择在进一步优化推理成本、混合推理和 Agent 上发力，显然 Qwen 瞄准的是开发者和 B 端用户的部署需求。这也将成为 Qwen 与 DeepSeek、Llama、OpenAI 等竞争对手最大的不同，也是阿里能否赢得 AI 时代的一张船票的关键所在。",
        "desc": "2025 年已经过去 1/3，如果用关键词来概括 AI 领域的发展你会想到什么？这是我想到的：开源、创新加速加速加速。2 月是「DeepSeek」的，R1 以所有人意想不到的方式，让全球执牛耳的 AI 开发者、创业者、投资人把目光锁定在「DeepSeek」「中国」「开源」上。4 月是「开源模型」的，发令枪是 Meta 喊的。被 DeepSeek 盖过风头后，2025 年 2 月 19 日，坐不住的 Meta 率先官宣——首个生成式 AI 开发者大会 LlamaCon 将于当地 4 月 29 日（北京时间 4 月 30 日）举行，颇有重新夺回「AI 开源界老大」江湖地位的意欲。但 AI 领域的产品发布节奏就是很微妙，什么时候发布似乎取决于对手的动作，作为一种心照不宣的默契，Meta 一声枪响让 4 月底成为开源模型的主场。整个 4 月甚至更早，AI 开发者们都在各大社交平台「蹲」开源领域「三大头牌」的新发布：DeepSeek-R2、Qwen3 以及 Llama4。Llama4 由于本月初的发布低于预期，似乎少了一些热度。目前看起来，4 月底最受关注的还是中国队，R2 呼之欲出，Qwen3 终于来了。4 月 29 日凌晨 5 点，阿里巴巴开源新一代通义千问模型 Qwen3，参数量仅为 DeepSeek-R1 的 1/3，成本大幅下降，性能全面超越 R1、OpenAI-o1 等全球顶尖模型，登顶全球最强开源模型。X 平台的开发者网友甚至把今天定义为「Happy Qwen3 Day」，不仅因为 Qwen3 全面超越 R1，更因为 Qwen3 家族的多尺寸、内置 MCP 支持、支持混合推理等实用性的功能点。官方技术报告进一步给出了 Qwen3 的几大亮点：「探索智能上限」再突破：通过扩大预训练和强化学习的规模，实现了更高层次的智能；国内首个「混合推理模型」：无缝集成了思考模式与非思考模式，为用户提供了灵活控制思考预算的能力；增强了 Agent 能力：正从专注于训练模型的时代过渡到以训练 Agent 为中心的时代。对于 Qwen3，个人用户现在就可以在「通义」APP 或 chat.qwen.ai 网页直接体验，夸克也即将全线接入 Qwen3。开发者和企业则可以免费在魔搭社区、HuggingFace 等平台下载模型并商用，或通过阿里云百炼调用 Qwen3 的 API 服务。憋了这么久的 Qwen3 到底怎么样？又代表哪些模型发展的趋势？01Qwen3，登顶全球最强开源模型Qwen3 包含 2 个 MoE 和 6 个密集模型，阿里云开源了两个 MoE 模型的权重，六个 Dense 模型也已开源，包括 Qwen3-32B、Qwen3-14B、Qwen3-8B、Qwen3-4B、Qwen3-1.7B 和 Qwen3-0.6B，均在 Apache 2.0 许可下开源。其中，旗舰型号 Qwen3-235B-A22B 参数量仅为 DeepSeek-R1 的 1/3，成本大幅下降，性能全面超越 R1、OpenAI-o1 等全球顶尖模型，登顶全球最强开源模型。此外，据阿里云官方介绍，Qwen3 是国内首个「混合推理模型」。「快思考」与「慢思考」集成进同一个模型，对简单需求可低算力「秒回」答案，对复杂问题可多步骤「深度思考」，大大节省算力消耗。Qwen3 在推理、指令遵循、工具调用、多语言能力等方面均大幅增强，创下所有国产模型及全球开源模型的性能新高：在奥数水平的 AIME25 测评中，Qwen3 斩获 81.5 分，刷新开源纪录；在考察代码能力的 LiveCodeBench 评测中，Qwen3 突破 70 分大关，表现甚至超过 Grok3；在评估模型人类偏好对齐的 ArenaHard 测评中，Qwen3 以 95.6 分超越 OpenAI-o1 及 DeepSeek-R1。性能大幅提升的同时，Qwen3 的部署成本还大幅下降，仅需 4 张 H20 即可部署千问 3 满血版，显存占用仅为性能相近模型的三分之一。Qwen3 性能｜图片来源：阿里云此外，小型 MoE 模型 Qwen3-30B-A3B 的激活参数数量是 QwQ-32B 的 10%，表现更胜一筹，甚至像 Qwen3-4B 这样的小模型也能匹敌 Qwen2.5-72B-Instruct 的性能。据介绍，Qwen3-235B-A22B 是一个拥有 2350 多亿总参数和 220 多亿激活参数的大模型；Qwen3-30B-A3B 则是一个拥有约 300 亿总参数和 30 亿激活参数的小型 MoE 模型。得益于在预训练、大规模强化学习和推理模式整合方面取得的显著进展，Qwen3 主打「思考更深、行动更快」，更好地构建 AI 应用。Qwen3 预训练数据量达 36T，并在后训练阶段多轮强化学习，将非思考模式无缝整合到思考模型中。值得注意的是，这次 Qwen3 的发布，主打混合推理，但是需要思考的长度最短也是 1024tokens，否则如果问题所需要的推理预算用不满 1024tokens，根本感受不到可以调节精度的混合推理模型的好。也就无法发挥用 Qwen3 不同程度的思考，灵活满足 AI 应用和不同场景对性能和成本的多样需求。截图来源：X02大模型全面转向「混合推理模型」和「Agent」在 Qwen3 发布的前一天，X 平台已有「行业人士」——日本的大模型厂商 SakanaAI 的一位工程师敏锐地捕捉到了 Qwen3 的重点。当天，在 AI 领域最重要的学术会议之一 ICLR 2025 的一个工作坊上，阿里云通义实验室通义千问负责人林俊旸透露了 Qwen 的下一步方向：推理模型和非推理模型的统一，以及面向 agent 的大模型。这正是今天发布的 Qwen3 最大的两个特点，同时也是大模型厂商们正在集体发生的转向。2025 年 2 月 25 日，Anthropic 发布了最新的旗舰模型 Claude 3.7 Sonnet，同时也称作是市场上首个混合推理模型。这意味着 Claude 3.7 Sonnet 能够生成即时的响应（快思考），也可以进行延展的、逐步的思考（慢思考）。API 用户还可以细粒度地控制模型的思考时长；当给定更长的思考时间，理论上会有更高质量的答案。Anthropic 表示，混合推理模型的架构代表下一代前沿模型，可以让模型像人类用同一个大脑一样，既能快速反应又能深度思考，这既能为用户创造更无缝的体验，也能让用户通过 API 使用 Claude 3.7 Sonnet 时，可以控制思考的预算。比如：可以告诉 Claude 最多思考 N 个 token，N 的取值可以达到其输出限制的 128K token，从而在回答质量与速度（及成本）之间进行权衡。「混合推理架构」也得到了 OpenAI 的青睐。Sam Altman 在更早的时间看到，当前的模型和产品供应已经变得非常复杂，希望 AI 能「开箱即用」、简化产品供应，「我们和你一样讨厌模型选择器，想要回归神奇的统一智能，之后，我们的一个重要目标是通过创建能够使用我们所有工具、知道何时需要长时间思考或不需要的系统，统一 o 系列模型和 GPT 系列模型，整体上能广泛适用于各种任务。」就像在 DeepSeek-R1 里一样，点选「深度思考」背后调用的是推理模型 R1 做的长推理，不选则调用的是基座模型 V3 即时生成的答案。现在，模型厂商把「思考的颗粒度」这个选择权更灵活、广泛地交给用户来控制推理预算。在 Qwen3 中，可以滑动「思考预算」的按钮，来控制思考的最大长度，从而匹配合适的推理质量和成本。在思考模式下，Qwen3 模型会逐步推理，经过深思熟虑后给出最终答案，适合需要深入思考的复杂问题。在非思考模式下，模型提供快速、近乎即时的响应，适用于那些对速度要求高于深度的简单问题。这种灵活性使用户能够根据具体任务控制模型进行「思考」的程度。这两种模式的结合大大增强了模型实现稳定且高效的「思考预算」控制能力，在成本效益和推理质量之间实现更优的平衡。另一个模型厂商的转向则是 Agent。随着 Manus 验证了 Claude 3.5 Sonnet 达到了通用 agent 的一些能力，加上模型调用工具、实现 agent 能力的统一协议——MCP 在越来越大的范围内被拥抱，下一代模型要面向 agent、面向实际场景来优化。就 Qwen3 来说，正在迈向以训练 Agent 为中心的阶段，当前 Qwen3 优化了 Agent 和 代码能力，同时也加强了对 MCP 的支持。据称，Qwen3 原生支持 MCP 协议，并具备强大的工具调用（function calling）能力，结合封装了工具调用模板和工具调用解析器的 Qwen-Agent 框架，将大大降低编码复杂性，实现高效的手机及电脑 Agent 操作等任务。在该示例中，Qwen3 思考并自主调用工具到 Github 数开源模型获得的 star，继续思考并调用绘图工具制作图片，并调用工具保存。｜视频来源：阿里云03开源模型新一轮竞赛开启Qwen3 的发布，意味着开源模型领域新一轮「三国杀」已然开始。事实上，随着 DeepSeek 的横空出世，加上 OpenAI、字节等大厂调整对开源的态度，开源已然成为大模型赛道的大势所趋。而 Llama、Qwen 和 DeepSeek，正是目前开源领域最有竞争力的玩家。Hugging Face 联合创始人、CEO Clement Delangue 发推暗示 DeepSeek 即将带来新发布。｜截图来源：X而此前 OpenAI 和 DeepSeek 的成功已经证明，互联网时代的生态、用户和产品壁垒，今天在 AI 时代并没有互联网时代那样牢不可摧，模型能力才是基础大模型公司的核心竞争力。而 Llama、Qwen 和 DeepSeek 的胜者，有可能在下一个发布周期到来前（至少在 OpenAI 的开源模型发布前），成为整个 AI 行业的引领者。虽然新一代模型能力的强弱，还要等待 Llama 和 DeepSeek 的发布，但值得关注的是，这三家开源模型厂商的生态策略亦有差异，这点从模型的侧重点就能看出端倪。DeepSeek 和 Meta 的侧重点也有不同，但一个共同点都是不太重视 ToB，至少是在服务生态的建设上并不成功。而这点也是 Qwen 和其背后的阿里云最重视的部分。极客公园曾在此前的文章里写过，脱胎于阿里云 Qwen，是最有以开源模型技术领先性、广泛全面开源的策略，追求生态建设的架势。阿里的 AI 战略里除了追求 AGI，也同样重视 AI 基础设施建设，以及更上层的与阿里的电商、钉钉、夸克等 AI 应用的结合。此前，阿里云智能集团资深副总裁、公共云事业部总裁刘伟光表示，「阿里云是全世界唯一一家积极研发基础大模型并全方位开源、全方位贡献的云计算厂商。」而 Qwen 模型下载量和衍生模型数量这两个衡量的生态的指标也同样领先。根据阿里云官方的最新数据，阿里通义已开源 200 余个模型，全球下载量超 3 亿次，千问衍生模型数超 10 万个，已经超越 Llama 位居全球开源模型的第一。而新模型选择在进一步优化推理成本、混合推理和 Agent 上发力，显然 Qwen 瞄准的是开发者和 B 端用户的部署需求。这也将成为 Qwen 与 DeepSeek、Llama、OpenAI 等竞争对手最大的不同，也是阿里能否赢得 AI 时代的一张船票的关键所在。",
        "summary": "阿里云发布新一代开源模型Qwen3，性能超越多个全球顶尖模型，成为当前最强开源模型，并引入混合推理等创新功能。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "藏师傅做了 DeepSeek-Prover-V2 一图流帮你了解这个模型 网页生成这东西太方便了，把PDF扔进去直接就出来了",
        "url": "https://x.com/op7418/status/1917784643459506380",
        "source": "Twitter-歸藏",
        "hot": "",
        "time": "2025-05-01 03:34:24",
        "timestamp": 1746041664000,
        "published": "2025-05-01 03:34:24",
        "content": "藏师傅做了 DeepSeek-Prover-V2 一图流帮你了解这个模型\n网页生成这东西太方便了，把PDF扔进去直接就出来了\n歸藏(guizang.ai): Deepseek 放出了 DeepSeek-Prover-V2 的详细论文\n详细总结分析一下：\nProver-V2 是一个专为 Lean 4 形式化定理证明设计的开源大型语言模型。\n其核心目标是利用强化学习进行子目标分解，从而提升形式化数学推理能力。\n🌟核心方法与创新：\n1️⃣递归定理证明流水线 (Recursive Theorem Proving",
        "desc": "藏师傅做了 DeepSeek-Prover-V2 一图流帮你了解这个模型网页生成这东西太方便了，把PDF扔进去直接就出来了歸藏(guizang.ai): Deepseek 放出了 DeepSeek-Prover-V2 的详细论文详细总结分析一下：Prover-V2 是一个专为 Lean 4 形式化定理证明设计的开源大型语言模型。其核心目标是利用强化学习进行子目标分解，从而提升形式化数学推理能力。🌟核心方法与创新：1️⃣递归定理证明流水线 (Recursive Theorem Proving",
        "summary": "藏师傅介绍了DeepSeek-Prover-V2模型，该模型专为Lean 4形式化定理证明设计，利用强化学习提升数学推理能力，支持通过PDF生成内容。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "OpenRouter 部署了 DeepSeek-Prover-V2-671B 现在可以免费体验，需要测试的朋友们可以开冲了",
        "url": "https://x.com/op7418/status/1917611179255673142",
        "source": "Twitter-歸藏",
        "hot": "",
        "time": "2025-04-30 16:05:07",
        "timestamp": 1746000307000,
        "published": "2025-04-30 16:05:07",
        "content": "OpenRouter 部署了 DeepSeek-Prover-V2-671B\n现在可以免费体验，需要测试的朋友们可以开冲了\nOpenRouter: 🐳 New: DeepSeek Prover v2, also available for free\nIt's a 671B parameter model. Not much is known about it yet, but it's likely an upgrade from DeepSeek-Prover-V1.5, which leveraged \"Proof Assistant Feedback for Reinforcement Learning.\"\nTry it out and let us know what you",
        "desc": "OpenRouter 部署了 DeepSeek-Prover-V2-671B现在可以免费体验，需要测试的朋友们可以开冲了OpenRouter: 🐳 New: DeepSeek Prover v2, also available for freeIt's a 671B parameter model. Not much is known about it yet, but it's likely an upgrade from DeepSeek-Prover-V1.5, which leveraged \"Proof Assistant Feedback for Reinforcement Learning.\"Try it out and let us know what you",
        "summary": "OpenRouter 部署了 DeepSeek-Prover-V2-671B 模型，现在可以免费体验。该模型参数量达671B，可能是 DeepSeek-Prover-V1.5 的升级版，使用了强化学习技术。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "RT yang fei: 像素化 + 分段点亮 + 模拟LCD视觉效果和俄式掌机，有种反未来复古感😍，大家不妨尝试一下(参数在评论) @dotey",
        "url": "https://x.com/dotey/status/1917757873590854003",
        "source": "Twitter-宝玉",
        "hot": "",
        "time": "2025-05-01 01:34:40",
        "timestamp": 1746034480000,
        "published": "2025-05-01 01:34:40",
        "content": "RT yang fei\n像素化 + 分段点亮 + 模拟LCD视觉效果和俄式掌机，有种反未来复古感😍，大家不妨尝试一下(参数在评论) @dotey",
        "desc": "RT yang fei像素化 + 分段点亮 + 模拟LCD视觉效果和俄式掌机，有种反未来复古感😍，大家不妨尝试一下(参数在评论) @dotey",
        "summary": "新闻内容提到通过像素化、分段点亮和模拟LCD视觉效果，结合俄式掌机风格，呈现出一种复古的视觉体验，并邀请读者尝试。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "RT virushuo: epic赢了在加州对苹果的官司，细节很有趣。上次法院判决允许外链引导支付之后，Philip Schiller建议按照法院要求执行。但是CFO建议搞花招增加难度...",
        "url": "https://x.com/dotey/status/1917746831724839315",
        "source": "Twitter-宝玉",
        "hot": "",
        "time": "2025-05-01 00:50:20",
        "timestamp": 1746031820000,
        "published": "2025-05-01 00:50:20",
        "content": "RT virushuo\nepic赢了在加州对苹果的官司，细节很有趣。上次法院判决允许外链引导支付之后，Philip Schiller建议按照法院要求执行。但是CFO建议搞花招增加难度，Cook采用了这个建议，最终被认为是藐视法庭。想起苹果ai团队建议采购GPU，被CFO否决，最后ai全面落后。公司到CFO影响业务的状态，大概是不会有创新了。\n9to5Mac: Apple’s consequential App Store setback comes on the eve of a key event https://9to5mac.com/2025/04/30/apples-consequential-app-store-setback-comes-on-the-eve-of-a-key-event/ by @apollozac",
        "desc": "RT virushuoepic赢了在加州对苹果的官司，细节很有趣。上次法院判决允许外链引导支付之后，Philip Schiller建议按照法院要求执行。但是CFO建议搞花招增加难度，Cook采用了这个建议，最终被认为是藐视法庭。想起苹果ai团队建议采购GPU，被CFO否决，最后ai全面落后。公司到CFO影响业务的状态，大概是不会有创新了。9to5Mac: Apple’s consequential App Store setback comes on the eve of a key event https://9to5mac.com/2025/04/30/apples-consequential-app-store-setback-comes-on-the-eve-of-a-key-event/ by @apollozac",
        "summary": "Epic在加州对苹果的官司中获胜，法院允许外链引导支付。苹果高管曾建议规避执行，导致被认定藐视法庭。新闻还提到苹果CFO对AI团队采购GPU的否决影响了AI发展。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "用 AI 画乐高搭建的城市 注： - 可以用 AI 参考提示词示例帮你生成更多 - 本图用 sora 生成 提示词1: 创建一幅充满细节且色彩鲜艳的乐高风格西安钟楼广场场景。...",
        "url": "https://x.com/dotey/status/1917713810346872902",
        "source": "Twitter-宝玉",
        "hot": "",
        "time": "2025-04-30 22:52:56",
        "timestamp": 1746024776000,
        "published": "2025-04-30 22:52:56",
        "content": "用 AI 画乐高搭建的城市\n注：\n- 可以用 AI 参考提示词示例帮你生成更多\n- 本图用 sora 生成\n提示词1:\n创建一幅充满细节且色彩鲜艳的乐高风格西安钟楼广场场景。钟楼以典雅的传统中式乐高建筑呈现，顶部覆以金色和墨绿色乐高瓦片，周围环绕着繁忙的圆形街道，上面有众多造型逼真的乐高小汽车、公交车和自行车。街道两旁密集排列着以乐高搭建的商铺和商场，招牌色彩明亮，汉字标识清晰可见。乐高小人们正在街头行走、拍照、购物或休息聊天，充满活力。背景以晴朗的乐高蓝天、少量漂浮的乐高云朵和远处淡雅的乐高秦岭山脉烘托，整体呈现出欢乐且富有历史感的氛围。\n提示词2:\n创建一幅高度精细且色彩鲜艳的乐高版上海外滩景象。前景呈现经典的外滩历史建筑群，用乐高砖块精致还原西式与新古典主义风格的建筑立面，包括钟楼、穹顶、柱廊等细节。乐高小人们正在沿江漫步、拍照、观光，街道两旁停靠着经典样式的乐高汽车。背景是壮观的黄浦江，以蓝色半透明乐高砖拼接，江面上有乐高渡轮和游览船。对岸的浦东陆家嘴高楼林立，包括东方明珠塔、上海中心、金茂大厦和环球金融中心，这些超现代乐高摩天大楼色彩丰富、造型逼真。天空为乐高明亮蓝色，点缀少量白色乐高积木云朵，整体呈现充满活力与现代感的视觉效果。\n提示词3:\n以真实乐高积木精心搭建的西安小吃街场景，采用逼真的等距视角拍摄，凸显微缩景深效果。街道两旁密集排列着各种美食摊位与店铺，招牌上写着“羊肉泡馍”、“肉夹馍”、“凉皮”等经典小吃名称，鲜艳明亮，富有生活气息。街景中乐高小人动作生动逼真：摊主在热情招呼顾客，食客手持美食边走边吃，乐高车辆如送货的三轮车穿行其中。前景的摊位和美食细节清晰锐利，背景的摊位和人群逐渐虚化，强化真实而微观的视觉体验。柔和的自然光线营造出塑料材质细腻的反光与柔和阴影，小的刮擦痕迹和指纹增加触觉真实感。整体以电影感的构图捕捉街头烟火气的微缩乐高场景。\n提示词4:\n打造一幅充满传统韵味的上海豫园老街乐高场景。画面中心是以黑色与红色乐高砖精心搭建的传统中式乐高建筑，如湖心亭和九曲桥，屋檐与屋脊线条清晰优美。桥下湖水以透明浅蓝色乐高积木拼砌，乐高小人正沿桥观赏或拍照。周围的老街以红色和棕色乐高砖铺就，两旁排列着细致逼真的传统店铺，售卖乐高版的糖画、汤包、小笼包和特色纪念品。街道上方悬挂着红色与黄色的乐高灯笼，乐高游客与居民络绎不绝，表现热闹繁华的景象。背景配以明朗的乐高蓝天与柔和的阳光，整体画面温暖而富有人情味。",
        "desc": "用 AI 画乐高搭建的城市注：- 可以用 AI 参考提示词示例帮你生成更多- 本图用 sora 生成提示词1:创建一幅充满细节且色彩鲜艳的乐高风格西安钟楼广场场景。钟楼以典雅的传统中式乐高建筑呈现，顶部覆以金色和墨绿色乐高瓦片，周围环绕着繁忙的圆形街道，上面有众多造型逼真的乐高小汽车、公交车和自行车。街道两旁密集排列着以乐高搭建的商铺和商场，招牌色彩明亮，汉字标识清晰可见。乐高小人们正在街头行走、拍照、购物或休息聊天，充满活力。背景以晴朗的乐高蓝天、少量漂浮的乐高云朵和远处淡雅的乐高秦岭山脉烘托，整体呈现出欢乐且富有历史感的氛围。提示词2:创建一幅高度精细且色彩鲜艳的乐高版上海外滩景象。前景呈现经典的外滩历史建筑群，用乐高砖块精致还原西式与新古典主义风格的建筑立面，包括钟楼、穹顶、柱廊等细节。乐高小人们正在沿江漫步、拍照、观光，街道两旁停靠着经典样式的乐高汽车。背景是壮观的黄浦江，以蓝色半透明乐高砖拼接，江面上有乐高渡轮和游览船。对岸的浦东陆家嘴高楼林立，包括东方明珠塔、上海中心、金茂大厦和环球金融中心，这些超现代乐高摩天大楼色彩丰富、造型逼真。天空为乐高明亮蓝色，点缀少量白色乐高积木云朵，整体呈现充满活力与现代感的视觉效果。提示词3:以真实乐高积木精心搭建的西安小吃街场景，采用逼真的等距视角拍摄，凸显微缩景深效果。街道两旁密集排列着各种美食摊位与店铺，招牌上写着“羊肉泡馍”、“肉夹馍”、“凉皮”等经典小吃名称，鲜艳明亮，富有生活气息。街景中乐高小人动作生动逼真：摊主在热情招呼顾客，食客手持美食边走边吃，乐高车辆如送货的三轮车穿行其中。前景的摊位和美食细节清晰锐利，背景的摊位和人群逐渐虚化，强化真实而微观的视觉体验。柔和的自然光线营造出塑料材质细腻的反光与柔和阴影，小的刮擦痕迹和指纹增加触觉真实感。整体以电影感的构图捕捉街头烟火气的微缩乐高场景。提示词4:打造一幅充满传统韵味的上海豫园老街乐高场景。画面中心是以黑色与红色乐高砖精心搭建的传统中式乐高建筑，如湖心亭和九曲桥，屋檐与屋脊线条清晰优美。桥下湖水以透明浅蓝色乐高积木拼砌，乐高小人正沿桥观赏或拍照。周围的老街以红色和棕色乐高砖铺就，两旁排列着细致逼真的传统店铺，售卖乐高版的糖画、汤包、小笼包和特色纪念品。街道上方悬挂着红色与黄色的乐高灯笼，乐高游客与居民络绎不绝，表现热闹繁华的景象。背景配以明朗的乐高蓝天与柔和的阳光，整体画面温暖而富有人情味。",
        "summary": "新闻介绍了使用AI工具Sora生成乐高风格的城市场景，包括西安钟楼广场、上海外滩、西安小吃街和上海豫园老街等，展示了AI在创意设计和视觉呈现中的应用。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "RT 马东锡 NLP 🇸🇪: 「DeepSeek, Reasoning」论文 DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal...",
        "url": "https://x.com/dotey/status/1917675204932780069",
        "source": "Twitter-宝玉",
        "hot": "",
        "time": "2025-04-30 19:38:52",
        "timestamp": 1746013132000,
        "published": "2025-04-30 19:38:52",
        "content": "RT 马东锡 NLP 🇸🇪\n「DeepSeek, Reasoning」论文\nDeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal Decomposition\n用\"sorry\"做占位符，sorry，除了硬核，无法可说。\nDeepSeek这篇在reasoning的追求上，到了一个让普通老百姓不能理解的程度。\nDeepSeek 的一系列推理模型，已经用test time scaling的方法，证明它有做奥赛数学题的reasoning能力。\n但这不够，这篇论文不要已经work的非正式性自然语言推理过程，一定要formal theorem proving，要用数学正式表达的形式化推理，。怎么评价呢，“挺卷的反正就” 。\n方法上，DeepSeek把“非正式分解 + 递归求解 + 强化学习”整合为一条pipeline：\n- DeepSeek-V3 先用自然语言写出解题思路，同时把每一步翻译成 Lean 子目标（以 sorry 结尾）。\n- 一个 7B 参数的 prover 模型递归地填补这些 sorry，得到完整 Lean 证明。\n- 拼接后的“CoT + 正式证明”作为冷启动数据，再用 RL 微调，显式奖励\"证明结构与分解保持一致\"。\n看完论文，一头雾水，为啥用sorry做占字符？\n问了一下专门做数学研究的朋友，才知道，微软的Lean是专门用来做交互式地构造严谨证明，sorry就是Lean的本身对数学推导的占字符。😱\n读完其他优秀的论文，我总会感叹exciting，amazing。\n这篇只有，无法可说，sorry....",
        "desc": "RT 马东锡 NLP 🇸🇪「DeepSeek, Reasoning」论文DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal Decomposition用\"sorry\"做占位符，sorry，除了硬核，无法可说。DeepSeek这篇在reasoning的追求上，到了一个让普通老百姓不能理解的程度。DeepSeek 的一系列推理模型，已经用test time scaling的方法，证明它有做奥赛数学题的reasoning能力。但这不够，这篇论文不要已经work的非正式性自然语言推理过程，一定要formal theorem proving，要用数学正式表达的形式化推理，。怎么评价呢，“挺卷的反正就” 。方法上，DeepSeek把“非正式分解 + 递归求解 + 强化学习”整合为一条pipeline：- DeepSeek-V3 先用自然语言写出解题思路，同时把每一步翻译成 Lean 子目标（以 sorry 结尾）。- 一个 7B 参数的 prover 模型递归地填补这些 sorry，得到完整 Lean 证明。- 拼接后的“CoT + 正式证明”作为冷启动数据，再用 RL 微调，显式奖励\"证明结构与分解保持一致\"。看完论文，一头雾水，为啥用sorry做占字符？问了一下专门做数学研究的朋友，才知道，微软的Lean是专门用来做交互式地构造严谨证明，sorry就是Lean的本身对数学推导的占字符。😱读完其他优秀的论文，我总会感叹exciting，amazing。这篇只有，无法可说，sorry....",
        "summary": "DeepSeek-Prover-V2论文提出了一种结合自然语言推理、子目标分解和强化学习的方法，用于提升形式化数学推理能力，使用Lean语言进行证明构建。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "睡不着继续翻了翻 Reddit, 博主 matteogeniaccio 使用推测性解码能让 Qwen3-32B 的速度提升2倍, 感兴趣的同学可以照着他的命令试试 -c 32768 -md Qwen_Qwen3-0.6...",
        "url": "https://x.com/karminski3/status/1917809170235208066",
        "source": "Twitter-karminski-牙医",
        "hot": "",
        "time": "2025-05-01 05:11:52",
        "timestamp": 1746047512000,
        "published": "2025-05-01 05:11:52",
        "content": "睡不着继续翻了翻 Reddit, 博主 matteogeniaccio 使用推测性解码能让 Qwen3-32B 的速度提升2倍, 感兴趣的同学可以照着他的命令试试\n-c 32768 -md Qwen_Qwen3-0.6B-Q6_K.gguf -ngld 99 -cd 8192 -devd CUDA0 -fa -ctk q8_0 -ctv q8_0\n原帖地址：http://www.reddit.com/r/LocalLLaMA/comments/1kbg2rl/waiting_for_qwen3_32b_coder_speculative_decoding/",
        "desc": "睡不着继续翻了翻 Reddit, 博主 matteogeniaccio 使用推测性解码能让 Qwen3-32B 的速度提升2倍, 感兴趣的同学可以照着他的命令试试-c 32768 -md Qwen_Qwen3-0.6B-Q6_K.gguf -ngld 99 -cd 8192 -devd CUDA0 -fa -ctk q8_0 -ctv q8_0原帖地址：http://www.reddit.com/r/LocalLLaMA/comments/1kbg2rl/waiting_for_qwen3_32b_coder_speculative_decoding/",
        "summary": "Reddit博主matteogeniaccio分享了使用推测性解码技术使Qwen3-32B模型速度提升两倍的方法，并提供了相关命令参数。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "极限测试！Qwen3 写代码+画画！究竟是不是开源最强模型？ 本次不但有大家喜闻乐见的 KCORES-LLM-Arena 测试，而且还增加了新测试集 morden-art 供大家预览！另外...",
        "url": "https://x.com/karminski3/status/1917785603976094000",
        "source": "Twitter-karminski-牙医",
        "hot": "",
        "time": "2025-05-01 03:38:13",
        "timestamp": 1746041893000,
        "published": "2025-05-01 03:38:13",
        "content": "极限测试！Qwen3 写代码+画画！究竟是不是开源最强模型？\n本次不但有大家喜闻乐见的 KCORES-LLM-Arena 测试，而且还增加了新测试集 morden-art 供大家预览！另外本次还包括了 Qwen3 的幻觉和文本召回率测试解读~\n给大家做到一个视频全面了解 Qwen3 性能!\nhttps://youtu.be/kph_c6LovQA",
        "desc": "极限测试！Qwen3 写代码+画画！究竟是不是开源最强模型？本次不但有大家喜闻乐见的 KCORES-LLM-Arena 测试，而且还增加了新测试集 morden-art 供大家预览！另外本次还包括了 Qwen3 的幻觉和文本召回率测试解读~给大家做到一个视频全面了解 Qwen3 性能!https://youtu.be/kph_c6LovQA",
        "summary": "新闻介绍了Qwen3模型在代码编写和绘画方面的性能测试，包括KCORES-LLM-Arena和morden-art测试集，并提供视频展示其表现。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Qwen3 测试视频来啦！👏 本次不但有大家喜闻乐见的 KCORES-LLM-Arena 测试，而且还增加了新测试集 morden-art 供大家预览！另外本次还包括了 Qwen3 的幻觉和文...",
        "url": "https://x.com/karminski3/status/1917779143032463751",
        "source": "Twitter-karminski-牙医",
        "hot": "",
        "time": "2025-05-01 03:12:32",
        "timestamp": 1746040352000,
        "published": "2025-05-01 03:12:32",
        "content": "Qwen3 测试视频来啦！👏\n本次不但有大家喜闻乐见的 KCORES-LLM-Arena 测试，而且还增加了新测试集 morden-art 供大家预览！另外本次还包括了 Qwen3 的幻觉和文本召回率测试解读~\n给大家做到一个视频全面了解 Qwen3 性能!\n( 好了，我终于可以去睡了, 祝各位假期愉快! )\n#大模型竞技场 #Qwen3 #qwen",
        "desc": "Qwen3 测试视频来啦！👏本次不但有大家喜闻乐见的 KCORES-LLM-Arena 测试，而且还增加了新测试集 morden-art 供大家预览！另外本次还包括了 Qwen3 的幻觉和文本召回率测试解读~给大家做到一个视频全面了解 Qwen3 性能!( 好了，我终于可以去睡了, 祝各位假期愉快! )#大模型竞技场 #Qwen3 #qwen",
        "summary": "Qwen3 发布测试视频，包含 KCORES-LLM-Arena 和新测试集 morden-art 的测试内容，并对幻觉和文本召回率进行了分析，全面展示 Qwen3 的性能。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "来看看昨天发布的 DeepSeek-Prover-V2-671B 有哪些新鲜内容： 先用 DeepSeek-V3 开发了一个简单而有效的递归定理证明管道，用来构建冷启动数据集。 然后使用冷启...",
        "url": "https://x.com/karminski3/status/1917746039186223330",
        "source": "Twitter-karminski-牙医",
        "hot": "",
        "time": "2025-05-01 01:01:00",
        "timestamp": 1746032460000,
        "published": "2025-05-01 01:01:00",
        "content": "来看看昨天发布的 DeepSeek-Prover-V2-671B 有哪些新鲜内容：\n先用 DeepSeek-V3 开发了一个简单而有效的递归定理证明管道，用来构建冷启动数据集。\n然后使用冷启动数据集先微调，然后强化学习，测了之后发现在 MiniF2F-test 测试中完成了 88.9% 的问题，直接第一名\n想要这个数据集吗？让然可以送给你，直接开源，叫做 ProverBench 数据集， 5 个问题来自 AIME (美国奥数的前置选拔赛之一)，其余 310 个问题来自精选的教材示例和教育教程\n不相信 MiniF2F-test 测试中完成了 88.9% 的问题？给你们下载 Prover 写的答案自己看\n心动了吗? 想玩一玩吗? 运行教程也给你！\n给跪了..........\n(本人菜鸡，如果解读有误恳请指正)",
        "desc": "来看看昨天发布的 DeepSeek-Prover-V2-671B 有哪些新鲜内容：先用 DeepSeek-V3 开发了一个简单而有效的递归定理证明管道，用来构建冷启动数据集。然后使用冷启动数据集先微调，然后强化学习，测了之后发现在 MiniF2F-test 测试中完成了 88.9% 的问题，直接第一名想要这个数据集吗？让然可以送给你，直接开源，叫做 ProverBench 数据集， 5 个问题来自 AIME (美国奥数的前置选拔赛之一)，其余 310 个问题来自精选的教材示例和教育教程不相信 MiniF2F-test 测试中完成了 88.9% 的问题？给你们下载 Prover 写的答案自己看心动了吗? 想玩一玩吗? 运行教程也给你！给跪了..........(本人菜鸡，如果解读有误恳请指正)",
        "summary": "DeepSeek-Prover-V2-671B 发布，使用 DeepSeek-V3 构建冷启动数据集，并在 MiniF2F-test 测试中取得 88.9% 的成绩，开源 ProverBench 数据集。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "牛逼👍",
        "url": "https://x.com/karminski3/status/1917660840301334934",
        "source": "Twitter-karminski-牙医",
        "hot": "",
        "time": "2025-04-30 19:22:27",
        "timestamp": 1746012147000,
        "published": "2025-04-30 19:22:27",
        "content": "牛逼👍\nyihong0618: 开源了\nhttps://github.com/yihong0618/running_page/pull/829",
        "desc": "牛逼👍yihong0618: 开源了https://github.com/yihong0618/running_page/pull/829",
        "summary": "新闻标题为'牛逼👍'，内容中包含一个GitHub链接和一张图片，可能与开源项目相关。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Qwen3 的 one more thing 来啦！又发布了个新模型：Qwen2.5-Omni-3B 真的是神仙打架 这是个端到端的多模态模型，输入可以是文本、图像、音频和视频，然后能生成...",
        "url": "https://x.com/karminski3/status/1917596467260448789",
        "source": "Twitter-karminski-牙医",
        "hot": "",
        "time": "2025-04-30 15:06:39",
        "timestamp": 1745996799000,
        "published": "2025-04-30 15:06:39",
        "content": "Qwen3 的 one more thing 来啦！又发布了个新模型：Qwen2.5-Omni-3B 真的是神仙打架\n这是个端到端的多模态模型，输入可以是文本、图像、音频和视频，然后能生成文本和音频流。\n🔹 与 Qwen2.5-Omni-7B 模型相比，3B 版本在长上下文序列处理（约 25k 个 token）中实现了令人瞩目的 50%+的 VRAM 消耗降低，同时在典型的 24GB 消费级 GPU 上支持扩展的 30 秒音视频交互。\n🔹 保留了 7B 模型的 90%+的多模态理解能力，自然语音输出的准确性和稳定性与 7B 版本相当。\nGit 仓库： https://github.com/QwenLM/Qwen2.5-Omni\nHugging Face: https://huggingface.co/Qwen/Qwen2.5-Omni-3B\nModelScope: https://modelscope.cn/models/Qwen/Qwen2.5-Omni-3B",
        "desc": "Qwen3 的 one more thing 来啦！又发布了个新模型：Qwen2.5-Omni-3B 真的是神仙打架这是个端到端的多模态模型，输入可以是文本、图像、音频和视频，然后能生成文本和音频流。🔹 与 Qwen2.5-Omni-7B 模型相比，3B 版本在长上下文序列处理（约 25k 个 token）中实现了令人瞩目的 50%+的 VRAM 消耗降低，同时在典型的 24GB 消费级 GPU 上支持扩展的 30 秒音视频交互。🔹 保留了 7B 模型的 90%+的多模态理解能力，自然语音输出的准确性和稳定性与 7B 版本相当。Git 仓库： https://github.com/QwenLM/Qwen2.5-OmniHugging Face: https://huggingface.co/Qwen/Qwen2.5-Omni-3BModelScope: https://modelscope.cn/models/Qwen/Qwen2.5-Omni-3B",
        "summary": "Qwen3 发布了新模型 Qwen2.5-Omni-3B，这是一个端到端的多模态模型，支持文本、图像、音频和视频输入，并能生成文本和音频流。相比 7B 版本，3B 版本在 VRAM 消耗和长上下文处理方面有显著优化。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "这个好~ 轻量级信息聚合(RSS)工具，一站式了解各个信息源的新鲜事。自动整理多个来源的新闻资讯，用 AI 生成简明摘要帮你快速抓重点，支持自由添加订阅源、选择A...",
        "url": "https://x.com/geekbb/status/1917743951999819898",
        "source": "Twitter-Geek",
        "hot": "",
        "time": "2025-05-01 00:52:42",
        "timestamp": 1746031962000,
        "published": "2025-05-01 00:52:42",
        "content": "这个好~ 轻量级信息聚合(RSS)工具，一站式了解各个信息源的新鲜事。自动整理多个来源的新闻资讯，用 AI 生成简明摘要帮你快速抓重点，支持自由添加订阅源、选择AI模型和设置更新频率。可轻松部署到 GitHub Pages / Vercel / Docker。\nFeedMe https://github.com/Seanium/feedme\n🌐 https://feedme.icu/",
        "desc": "这个好~ 轻量级信息聚合(RSS)工具，一站式了解各个信息源的新鲜事。自动整理多个来源的新闻资讯，用 AI 生成简明摘要帮你快速抓重点，支持自由添加订阅源、选择AI模型和设置更新频率。可轻松部署到 GitHub Pages / Vercel / Docker。FeedMe https://github.com/Seanium/feedme🌐 https://feedme.icu/",
        "summary": "FeedMe是一款轻量级RSS信息聚合工具，支持自动整理新闻资讯并用AI生成摘要，用户可自由添加订阅源并部署到GitHub Pages等平台。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Re 晒一下我 AI 4月用量",
        "url": "https://x.com/geekbb/status/1917741289753436407",
        "source": "Twitter-Geek",
        "hot": "",
        "time": "2025-05-01 00:42:08",
        "timestamp": 1746031328000,
        "published": "2025-05-01 00:42:08",
        "content": "Re 晒一下我 AI 4月用量",
        "desc": "Re 晒一下我 AI 4月用量",
        "summary": "用户分享了自己在4月份使用AI的情况，并附上了一张图片。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Grok3 一个月才用 $5 不到，两个帐号 $10 ……我还是用得少",
        "url": "https://x.com/geekbb/status/1917740552126357722",
        "source": "Twitter-Geek",
        "hot": "",
        "time": "2025-05-01 00:39:12",
        "timestamp": 1746031152000,
        "published": "2025-05-01 00:39:12",
        "content": "Grok3 一个月才用 $5 不到，两个帐号 $10 ……我还是用得少",
        "desc": "Grok3 一个月才用 $5 不到，两个帐号 $10 ……我还是用得少",
        "summary": "用户分享使用Grok3的费用情况，表示一个月使用费用不到5美元，两个账号共10美元，并认为自己使用量较少。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "五一就在家看电视，分享一个不错的网盘搜索引擎《盘友圈》，可以搜索 阿里云盘 / 百度网盘 / 夸克网盘 的资源。 📥 https://panyq.com/",
        "url": "https://x.com/geekbb/status/1917591229082358081",
        "source": "Twitter-Geek",
        "hot": "",
        "time": "2025-04-30 14:45:50",
        "timestamp": 1745995550000,
        "published": "2025-04-30 14:45:50",
        "content": "五一就在家看电视，分享一个不错的网盘搜索引擎《盘友圈》，可以搜索 阿里云盘 / 百度网盘 / 夸克网盘 的资源。\n📥 https://panyq.com/",
        "desc": "五一就在家看电视，分享一个不错的网盘搜索引擎《盘友圈》，可以搜索 阿里云盘 / 百度网盘 / 夸克网盘 的资源。📥 https://panyq.com/",
        "summary": "五一期间在家看电视，推荐一个名为《盘友圈》的网盘搜索引擎，可搜索阿里云盘、百度网盘、夸克网盘的资源。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "大家看下我设计的这个T恤怎么样？ 灵感来自于很多年前的一个博客“不许联想”和刚刚发布的 Qwen3 @alibaba_qwen",
        "url": "https://x.com/miantiao_me/status/1917788545365721523",
        "source": "Twitter-面条",
        "hot": "",
        "time": "2025-05-01 03:49:54",
        "timestamp": 1746042594000,
        "published": "2025-05-01 03:49:54",
        "content": "大家看下我设计的这个T恤怎么样？\n灵感来自于很多年前的一个博客“不许联想”和刚刚发布的 Qwen3\n@alibaba_qwen",
        "desc": "大家看下我设计的这个T恤怎么样？灵感来自于很多年前的一个博客“不许联想”和刚刚发布的 Qwen3@alibaba_qwen",
        "summary": "用户展示自己设计的T恤，灵感来源于多年前的博客“不许联想”和刚刚发布的Qwen3。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "It’s official: @SAP Databricks is now GA!\nSAP c...",
        "url": "https://x.com/databricks/status/1917806507590103515",
        "source": "Twitter-Databricks",
        "content": "It’s official: @SAP Databricks is now GA!\nSAP customers can now unlock data intelligence across their SAP data and external sources—enabling improved governance, advanced analytics, and AI use cases. Learn more: https://t.co/p0CpfY0VmG https://t.co/ZieswV7evH",
        "hot": "",
        "time": "2025-05-01 05:01:17",
        "timestamp": 1746075677000,
        "published": "2025-05-01 05:01:17",
        "desc": "It’s official: @SAP Databricks is now GA!\nSAP customers can now unlock data intelligence across their SAP data and external sources—enabling improved governance, advanced analytics, and AI use cases. Learn more: https://t.co/p0CpfY0VmG https://t.co/ZieswV7evH",
        "summary": "SAP Databricks现已正式发布，使客户能够利用SAP数据和外部数据源进行数据分析、治理和AI应用。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "https://t.co/r0qpwRlYQr",
        "url": "https://x.com/garrytan/status/1917790562838798769",
        "source": "Twitter-Garry Tan",
        "content": "https://t.co/r0qpwRlYQr",
        "hot": "",
        "time": "2025-05-01 03:57:55",
        "timestamp": 1746071875000,
        "published": "2025-05-01 03:57:55",
        "desc": "https://t.co/r0qpwRlYQr",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "Microsoft’s most capable new Phi 4 AI model riv...",
        "url": "https://x.com/Kyle_L_Wiggers/status/1917787086440063067",
        "source": "Twitter-Kyle Wiggers",
        "content": "Microsoft’s most capable new Phi 4 AI model rivals the performance of far larger systems https://t.co/SMmHAy3amN",
        "hot": "",
        "time": "2025-05-01 03:44:06",
        "timestamp": 1746071046000,
        "published": "2025-05-01 03:44:06",
        "desc": "Microsoft’s most capable new Phi 4 AI model rivals the performance of far larger systems https://t.co/SMmHAy3amN",
        "summary": "Microsoft发布了新的Phi 4 AI模型，其性能可与更大规模的系统相媲美。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "In 18 mo or so, 30% of design will also be done...",
        "url": "https://x.com/Suhail/status/1917786590887436392",
        "source": "Twitter-Suhail",
        "content": "In 18 mo or so, 30% of design will also be done by AI. It is inevitable. Taste will matter more than ever.",
        "hot": "",
        "time": "2025-05-01 03:42:08",
        "timestamp": 1746070928000,
        "published": "2025-05-01 03:42:08",
        "desc": "In 18 mo or so, 30% of design will also be done by AI. It is inevitable. Taste will matter more than ever.",
        "summary": "新闻提到，在大约18个月内，30%的设计工作将由AI完成，强调品味将变得比以往更加重要。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "直接在代码编辑器里查看Deepwiki内容的MCP：deepwiki-mcp，相当于内置了个文...",
        "url": "https://x.com/aigclink/status/1917780163435323674",
        "source": "Twitter-AIGCLINK",
        "content": "直接在代码编辑器里查看Deepwiki内容的MCP：deepwiki-mcp，相当于内置了个文档浏览器，非官方的但比较实用\n它通过MCP获取Deepwiki的URL，抓取相关页面，转换为Markdown格式，并把结果返回给代码编辑器\n那你就可以直接在Cursor等中查看，不用再打开浏览器，即可实时获取最新文档了 https://t.co/gkL4v7GH0y",
        "hot": "",
        "time": "2025-05-01 03:16:36",
        "timestamp": 1746069396000,
        "published": "2025-05-01 03:16:36",
        "desc": "直接在代码编辑器里查看Deepwiki内容的MCP：deepwiki-mcp，相当于内置了个文档浏览器，非官方的但比较实用\n它通过MCP获取Deepwiki的URL，抓取相关页面，转换为Markdown格式，并把结果返回给代码编辑器\n那你就可以直接在Cursor等中查看，不用再打开浏览器，即可实时获取最新文档了 https://t.co/gkL4v7GH0y",
        "summary": "新闻介绍了一个名为deepwiki-mcp的工具，可在代码编辑器中直接查看Deepwiki内容，无需打开浏览器，支持实时获取最新文档。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "OH (in sf): \"the thing about these tech people ...",
        "url": "https://x.com/bentossell/status/1917779740985065854",
        "source": "Twitter-Ben Tossell",
        "content": "OH (in sf): \"the thing about these tech people is they dont quite get it\"",
        "hot": "",
        "time": "2025-05-01 03:14:55",
        "timestamp": 1746069295000,
        "published": "2025-05-01 03:14:55",
        "desc": "OH (in sf): \"the thing about these tech people is they dont quite get it\"",
        "summary": "新闻内容为一条简短的评论，提到‘这些科技人士似乎没有真正理解事情’，但未提供更多具体信息。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "🤔 https://t.co/6d0ZfImp10",
        "url": "https://x.com/Austen/status/1917777979712680372",
        "source": "Twitter-Austen Allred",
        "content": "🤔 https://t.co/6d0ZfImp10",
        "hot": "",
        "time": "2025-05-01 03:07:55",
        "timestamp": 1746068875000,
        "published": "2025-05-01 03:07:55",
        "desc": "🤔 https://t.co/6d0ZfImp10",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "World partners with Tinder, Visa to bring its I...",
        "url": "https://x.com/Kyle_L_Wiggers/status/1917769659371094503",
        "source": "Twitter-Kyle Wiggers",
        "content": "World partners with Tinder, Visa to bring its ID-verifying tech to more places https://t.co/aHJDhh8Lpf",
        "hot": "",
        "time": "2025-05-01 02:34:51",
        "timestamp": 1746066891000,
        "published": "2025-05-01 02:34:51",
        "desc": "World partners with Tinder, Visa to bring its ID-verifying tech to more places https://t.co/aHJDhh8Lpf",
        "summary": "World与Tinder和Visa合作，将其实名认证技术推广到更多地方。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "goodbye, GPT-4. you kicked off a revolution.\nw...",
        "url": "https://x.com/sama/status/1917766910911078571",
        "source": "Twitter-Sam Altman",
        "content": "goodbye, GPT-4. you kicked off a revolution.\nwe will proudly keep your weights on a special hard drive to give to some historians in the future.",
        "hot": "",
        "time": "2025-05-01 02:23:56",
        "timestamp": 1746066236000,
        "published": "2025-05-01 02:23:56",
        "desc": "goodbye, GPT-4. you kicked off a revolution.\nwe will proudly keep your weights on a special hard drive to give to some historians in the future.",
        "summary": "新闻标题和内容表达了对GPT-4的告别，并提到将保留其权重数据供未来历史学家研究。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "I just want to know how much Epic spent on liti...",
        "url": "https://x.com/Austen/status/1917766149162279419",
        "source": "Twitter-Austen Allred",
        "content": "I just want to know how much Epic spent on litigation against Apple.\nCan’t even imagine how much it all cost them.",
        "hot": "",
        "time": "2025-05-01 02:20:54",
        "timestamp": 1746066054000,
        "published": "2025-05-01 02:20:54",
        "desc": "I just want to know how much Epic spent on litigation against Apple.\nCan’t even imagine how much it all cost them.",
        "summary": "新闻内容表达了对Epic Games在与苹果公司诉讼中所花费金额的疑问，认为诉讼成本可能非常高。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Our team had been working hard for this release...",
        "url": "https://x.com/sytelus/status/1917762872182202494",
        "source": "Twitter-Shital Shah",
        "content": "Our team had been working hard for this release and that day is here!\n🚀 Phi-4-Reasoning (14 B params) + its RL-boosted sibling Phi-4-Reasoning-Plus punch way above their weight.\nThink “small-model swagger” that beats or ties 70B-671B giants on tough reasoning tasks! https://t.co/ryFAILzRsC",
        "hot": "",
        "time": "2025-05-01 02:07:53",
        "timestamp": 1746065273000,
        "published": "2025-05-01 02:07:53",
        "desc": "Our team had been working hard for this release and that day is here!\n🚀 Phi-4-Reasoning (14 B params) + its RL-boosted sibling Phi-4-Reasoning-Plus punch way above their weight.\nThink “small-model swagger” that beats or ties 70B-671B giants on tough reasoning tasks! https://t.co/ryFAILzRsC",
        "summary": "团队发布了Phi-4-Reasoning和Phi-4-Reasoning-Plus两款模型，它们在参数量较少的情况下，在复杂推理任务上表现优异，甚至可与更大参数量的模型媲美。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Meta forecasted it would make $1.4T in revenue ...",
        "url": "https://x.com/Kyle_L_Wiggers/status/1917762144092725685",
        "source": "Twitter-Kyle Wiggers",
        "content": "Meta forecasted it would make $1.4T in revenue from generative AI by 2035 https://t.co/YfvetTZwEY",
        "hot": "",
        "time": "2025-05-01 02:05:00",
        "timestamp": 1746065100000,
        "published": "2025-05-01 02:05:00",
        "desc": "Meta forecasted it would make $1.4T in revenue from generative AI by 2035 https://t.co/YfvetTZwEY",
        "summary": "Meta预测到2035年，其通过生成式AI技术将实现1.4万亿美元的收入。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Phi-4-Mini-Reasoning\nExploring the Limits of S...",
        "url": "https://x.com/_akhaliq/status/1917761687723147707",
        "source": "Twitter-AK",
        "content": "Phi-4-Mini-Reasoning\nExploring the Limits of Small Reasoning Language Models in Math https://t.co/L9jm45tLmN",
        "hot": "",
        "time": "2025-05-01 02:03:11",
        "timestamp": 1746064991000,
        "published": "2025-05-01 02:03:11",
        "desc": "Phi-4-Mini-Reasoning\nExploring the Limits of Small Reasoning Language Models in Math https://t.co/L9jm45tLmN",
        "summary": "新闻标题为Phi-4-Mini-Reasoning，内容涉及探索小型推理语言模型在数学领域的极限。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "小米已入局大模型行列，昨天放出了MiMo-7B，其核心是能解决数学以及代码等复杂的推理问题，说...",
        "url": "https://x.com/aigclink/status/1917760723016638506",
        "source": "Twitter-AIGCLINK",
        "content": "小米已入局大模型行列，昨天放出了MiMo-7B，其核心是能解决数学以及代码等复杂的推理问题，说是性能超32B，MiMo-7B-RL媲美OpenAI o1-mini\n在数学AIME24/25上分别是68.2分和55.4分，超过了OpenAI o1-mini、QwQ-32B-preview\n在代码LiveCodeBench v5上达到了57.8分\n提供了四个版本： https://t.co/siddrZLv0a",
        "hot": "",
        "time": "2025-05-01 01:59:21",
        "timestamp": 1746064761000,
        "published": "2025-05-01 01:59:21",
        "desc": "小米已入局大模型行列，昨天放出了MiMo-7B，其核心是能解决数学以及代码等复杂的推理问题，说是性能超32B，MiMo-7B-RL媲美OpenAI o1-mini\n在数学AIME24/25上分别是68.2分和55.4分，超过了OpenAI o1-mini、QwQ-32B-preview\n在代码LiveCodeBench v5上达到了57.8分\n提供了四个版本： https://t.co/siddrZLv0a",
        "summary": "小米发布了大模型MiMo-7B，专注于解决数学和代码等复杂推理问题，性能超过多个知名模型，并提供了多个版本供使用。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Phi-4-reasoning Technical Report https://t.co/B...",
        "url": "https://x.com/_akhaliq/status/1917759111841673444",
        "source": "Twitter-AK",
        "content": "Phi-4-reasoning Technical Report https://t.co/BI6A9aHC3B",
        "hot": "",
        "time": "2025-05-01 01:52:57",
        "timestamp": 1746064377000,
        "published": "2025-05-01 01:52:57",
        "desc": "Phi-4-reasoning Technical Report https://t.co/BI6A9aHC3B",
        "summary": "新闻标题为Phi-4-reasoning Technical Report，并附有链接。新闻内容仅包含标题和链接，未提供更多细节。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Yes",
        "url": "https://x.com/tunguz/status/1917756215918223377",
        "source": "Twitter-Bojan Tunguz",
        "content": "Yes",
        "hot": "",
        "time": "2025-05-01 01:41:26",
        "timestamp": 1746063686000,
        "published": "2025-05-01 01:41:26",
        "desc": "Yes",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "If we want maximum American innovation, Apple w...",
        "url": "https://x.com/garrytan/status/1917745160664015197",
        "source": "Twitter-Garry Tan",
        "content": "If we want maximum American innovation, Apple would give free choice to consumers to choose OpenAI, Anthropic or Perplexity as their AI providers\nRemember how your OS has to let you choose your browser? That protected Google from Microsoft running the table. How about now? https://t.co/IG0QQbOeL0",
        "hot": "",
        "time": "2025-05-01 00:57:30",
        "timestamp": 1746061050000,
        "published": "2025-05-01 00:57:30",
        "desc": "If we want maximum American innovation, Apple would give free choice to consumers to choose OpenAI, Anthropic or Perplexity as their AI providers\nRemember how your OS has to let you choose your browser? That protected Google from Microsoft running the table. How about now? https://t.co/IG0QQbOeL0",
        "summary": "新闻讨论了如果希望实现最大化的美国创新，苹果应允许消费者自由选择OpenAI、Anthropic或Perplexity作为AI服务提供商，类比操作系统允许用户选择浏览器的做法。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Amazon launches Nova Premier, its most capable ...",
        "url": "https://x.com/Kyle_L_Wiggers/status/1917743075142652257",
        "source": "Twitter-Kyle Wiggers",
        "content": "Amazon launches Nova Premier, its most capable AI model yet https://t.co/1PPcaqIHa7",
        "hot": "",
        "time": "2025-05-01 00:49:13",
        "timestamp": 1746060553000,
        "published": "2025-05-01 00:49:13",
        "desc": "Amazon launches Nova Premier, its most capable AI model yet https://t.co/1PPcaqIHa7",
        "summary": "Amazon推出了其最强大的AI模型Nova Premier。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "What do you mean these coins are tied to real p...",
        "url": "https://x.com/nikitabier/status/1917742710028410962",
        "source": "Twitter-Nikita Bier",
        "content": "What do you mean these coins are tied to real products made by real people? We only know how to trade fleeting memes created by anonymous people",
        "hot": "",
        "time": "2025-05-01 00:47:46",
        "timestamp": 1746060466000,
        "published": "2025-05-01 00:47:46",
        "desc": "What do you mean these coins are tied to real products made by real people? We only know how to trade fleeting memes created by anonymous people",
        "summary": "新闻内容质疑加密货币与实际产品和真实人的关联，认为目前的交易更多是基于匿名人士创造的短暂网络迷因。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Excited for @alistairmbarr’s new BI newsletter!...",
        "url": "https://x.com/RamaswmySridhar/status/1917739624925127093",
        "source": "Twitter-sridhar",
        "content": "Excited for @alistairmbarr’s new BI newsletter!\nhttps://t.co/2G1g7qR3xo",
        "hot": "",
        "time": "2025-05-01 00:35:31",
        "timestamp": 1746059731000,
        "published": "2025-05-01 00:35:31",
        "desc": "Excited for @alistairmbarr’s new BI newsletter!\nhttps://t.co/2G1g7qR3xo",
        "summary": "新闻内容表达了对AlistairMBarr新推出的BI（商业智能）通讯的期待，并附有链接。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Now I am become Prompt Engineer, the destroyer ...",
        "url": "https://x.com/oh_that_hat/status/1917730336693444979",
        "source": "Twitter-Hattie Zhou",
        "content": "Now I am become Prompt Engineer, the destroyer of worlds 💥",
        "hot": "",
        "time": "2025-04-30 23:58:36",
        "timestamp": 1746057516000,
        "published": "2025-04-30 23:58:36",
        "desc": "Now I am become Prompt Engineer, the destroyer of worlds 💥",
        "summary": "新闻标题宣称成为Prompt Engineer，暗示在人工智能或相关技术领域有所作为。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Meet Solo Tech, one of the 10 international rec...",
        "url": "https://x.com/AIatMeta/status/1917727629601616030",
        "source": "Twitter-AI at Meta",
        "content": "Meet Solo Tech, one of the 10 international recipients of the second Llama Impact Grants.\nSolo Tech uses Llama to offer offline, multilingual AI support for underserved rural communities with limited internet access. This grant will help them to equip 50 rural centers with AI https://t.co/6YflcOlE7j",
        "hot": "",
        "time": "2025-04-30 23:47:51",
        "timestamp": 1746056871000,
        "published": "2025-04-30 23:47:51",
        "desc": "Meet Solo Tech, one of the 10 international recipients of the second Llama Impact Grants.\nSolo Tech uses Llama to offer offline, multilingual AI support for underserved rural communities with limited internet access. This grant will help them to equip 50 rural centers with AI https://t.co/6YflcOlE7j",
        "summary": "Solo Tech 获得了第二轮 Llama Impact Grants，他们利用 Llama 技术为缺乏互联网接入的农村社区提供离线、多语言的 AI 支持。该资助将帮助他们为 50 个农村中心配备 AI。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "https://t.co/U6tI9pdin6",
        "url": "https://x.com/elonmusk/status/1917726279195058338",
        "source": "Twitter-Elon Musk",
        "content": "https://t.co/U6tI9pdin6",
        "hot": "",
        "time": "2025-04-30 23:42:29",
        "timestamp": 1746056549000,
        "published": "2025-04-30 23:42:29",
        "desc": "https://t.co/U6tI9pdin6",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "Starting today, we're testing new image editing...",
        "url": "https://x.com/GeminiApp/status/1917723571042017346",
        "source": "Twitter-Google Gemini App",
        "content": "Starting today, we're testing new image editing features in Gemini like changing backgrounds, swapping objects, and more. They’re rolling out gradually to all users. We're continuing to improve image generation, so stay tuned. https://t.co/JsurD7LRck",
        "hot": "",
        "time": "2025-04-30 23:31:43",
        "timestamp": 1746055903000,
        "published": "2025-04-30 23:31:43",
        "desc": "Starting today, we're testing new image editing features in Gemini like changing backgrounds, swapping objects, and more. They’re rolling out gradually to all users. We're continuing to improve image generation, so stay tuned. https://t.co/JsurD7LRck",
        "summary": "今日起，Gemini将测试新的图像编辑功能，包括更换背景、交换物体等，功能将逐步向所有用户推出。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Google’s Gemini chatbot gets upgraded image cre...",
        "url": "https://x.com/Kyle_L_Wiggers/status/1917720549519663229",
        "source": "Twitter-Kyle Wiggers",
        "content": "Google’s Gemini chatbot gets upgraded image creation tools https://t.co/vwbGgqHyI2",
        "hot": "",
        "time": "2025-04-30 23:19:43",
        "timestamp": 1746055183000,
        "published": "2025-04-30 23:19:43",
        "desc": "Google’s Gemini chatbot gets upgraded image creation tools https://t.co/vwbGgqHyI2",
        "summary": "Google的Gemini聊天机器人获得了升级的图像创作工具。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "3 quick updates! We've updated the V7 model wit...",
        "url": "https://x.com/midjourney/status/1917715712854089978",
        "source": "Twitter-Midjourney",
        "content": "3 quick updates! We've updated the V7 model with improved image quality and coherence. There's a new lightbox editor that's easier to use. Last we've added a new experimental aesthetics parameter --exp (goes 0 to 100, 0 is default) that pumps up details and creativity. Have fun!",
        "hot": "",
        "time": "2025-04-30 23:00:30",
        "timestamp": 1746054030000,
        "published": "2025-04-30 23:00:30",
        "desc": "3 quick updates! We've updated the V7 model with improved image quality and coherence. There's a new lightbox editor that's easier to use. Last we've added a new experimental aesthetics parameter --exp (goes 0 to 100, 0 is default) that pumps up details and creativity. Have fun!",
        "summary": "新闻介绍了V7模型的三个更新：图像质量与连贯性提升、新增易于使用的lightbox编辑器以及一个实验性美学参数--exp，用于增强细节和创意。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Join us at #Knowledge25 to explore how enterpri...",
        "url": "https://x.com/NVIDIAAI/status/1917715591588155585",
        "source": "Twitter-NVIDIA AI",
        "content": "Join us at #Knowledge25 to explore how enterprises are leveraging #agenticAI to boost productivity, personalize services, and unlock enterprise-wide efficiency.\nRegister now for NVIDIA expert sessions ➡️ https://t.co/kxOmE4QHPv https://t.co/quUcyLQQSv",
        "hot": "",
        "time": "2025-04-30 23:00:01",
        "timestamp": 1746054001000,
        "published": "2025-04-30 23:00:01",
        "desc": "Join us at #Knowledge25 to explore how enterprises are leveraging #agenticAI to boost productivity, personalize services, and unlock enterprise-wide efficiency.\nRegister now for NVIDIA expert sessions ➡️ https://t.co/kxOmE4QHPv https://t.co/quUcyLQQSv",
        "summary": "新闻邀请参加#Knowledge25活动，探讨企业如何利用#agenticAI提高生产力、个性化服务和实现企业整体效率。注册链接已提供。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Sf right now https://t.co/kcPYpER7S0",
        "url": "https://x.com/bentossell/status/1917714682787553336",
        "source": "Twitter-Ben Tossell",
        "content": "Sf right now https://t.co/kcPYpER7S0",
        "hot": "",
        "time": "2025-04-30 22:56:24",
        "timestamp": 1746053784000,
        "published": "2025-04-30 22:56:24",
        "desc": "Sf right now https://t.co/kcPYpER7S0",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "用 AI 画乐高搭建的城市\n注：\n- 可以用 AI 参考提示词示例帮你生成更多\n- 本图用 ...",
        "url": "https://x.com/dotey/status/1917713810346872902",
        "source": "Twitter-宝玉",
        "content": "用 AI 画乐高搭建的城市\n注：\n- 可以用 AI 参考提示词示例帮你生成更多\n- 本图用 sora 生成\n提示词1: https://t.co/ZFUIYJ0vld",
        "hot": "",
        "time": "2025-04-30 22:52:56",
        "timestamp": 1746053576000,
        "published": "2025-04-30 22:52:56",
        "desc": "用 AI 画乐高搭建的城市\n注：\n- 可以用 AI 参考提示词示例帮你生成更多\n- 本图用 sora 生成\n提示词1: https://t.co/ZFUIYJ0vld",
        "summary": "新闻介绍了使用AI工具生成乐高搭建城市图像的过程，并提到了使用Sora生成图像。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Attendees from past AI Conferences speak highly...",
        "url": "https://x.com/AIconference/status/1917711310072217875",
        "source": "Twitter-The AI Conference",
        "content": "Attendees from past AI Conferences speak highly of the insights, connections, and forward-thinking conversations. If you're serious about the future of AI, this is where it all comes together. Don’t miss your chance to be part of it.",
        "hot": "",
        "time": "2025-04-30 22:43:00",
        "timestamp": 1746052980000,
        "published": "2025-04-30 22:43:00",
        "desc": "Attendees from past AI Conferences speak highly of the insights, connections, and forward-thinking conversations. If you're serious about the future of AI, this is where it all comes together. Don’t miss your chance to be part of it.",
        "summary": "过去参加AI会议的与会者对会议的见解、联系和前瞻性讨论给予高度评价，强调这是关注AI未来的重要平台。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "AvatarFX has officially rolled out to all c.ai+...",
        "url": "https://x.com/character_ai/status/1917710884924973274",
        "source": "Twitter-Character.AI",
        "content": "AvatarFX has officially rolled out to all c.ai+ users — and the creations you’re sharing? Nothing short of masterpieces. #avatarfx #characterai\n🦞 Mob Boss Lobster\nProps to Character.‌AI user WeeklyBots for this underworld undersea icon.\n1/3 https://t.co/pNaM4diQ2w",
        "hot": "",
        "time": "2025-04-30 22:41:18",
        "timestamp": 1746052878000,
        "published": "2025-04-30 22:41:18",
        "desc": "AvatarFX has officially rolled out to all c.ai+ users — and the creations you’re sharing? Nothing short of masterpieces. #avatarfx #characterai\n🦞 Mob Boss Lobster\nProps to Character.‌AI user WeeklyBots for this underworld undersea icon.\n1/3 https://t.co/pNaM4diQ2w",
        "summary": "AvatarFX 已正式向所有 c.ai+ 用户推出，用户分享的创作被描述为杰作。新闻提到了 Character.AI 用户 WeeklyBots 的一个作品。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Vibe check is all you need https://t.co/0Vyf2fEMas",
        "url": "https://x.com/tunguz/status/1917709866619019334",
        "source": "Twitter-Bojan Tunguz",
        "content": "Vibe check is all you need https://t.co/0Vyf2fEMas",
        "hot": "",
        "time": "2025-04-30 22:37:16",
        "timestamp": 1746052636000,
        "published": "2025-04-30 22:37:16",
        "desc": "Vibe check is all you need https://t.co/0Vyf2fEMas",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "[ Alpha‑Factory v1 👁️✨ ]\nGlobal markets seep t...",
        "url": "https://x.com/ceobillionaire/status/1917708680432136427",
        "source": "Twitter-AGI.Eth",
        "content": "[ Alpha‑Factory v1 👁️✨ ]\nGlobal markets seep trillions in latent “alpha” opportunity:\n• Pricing dislocations\n• Supply‑chain inefficiencies\n• Policy loopholes\n• Etc!\nMulti‑Agent AGENTIC α‑AGI: https://t.co/WUfcDL5hjo\n#AGI #AIAgent #AGIALPHA https://t.co/EI0H30XzVx",
        "hot": "",
        "time": "2025-04-30 22:32:33",
        "timestamp": 1746052353000,
        "published": "2025-04-30 22:32:33",
        "desc": "[ Alpha‑Factory v1 👁️✨ ]\nGlobal markets seep trillions in latent “alpha” opportunity:\n• Pricing dislocations\n• Supply‑chain inefficiencies\n• Policy loopholes\n• Etc!\nMulti‑Agent AGENTIC α‑AGI: https://t.co/WUfcDL5hjo\n#AGI #AIAgent #AGIALPHA https://t.co/EI0H30XzVx",
        "summary": "新闻标题为[ Alpha‑Factory v1 👁️✨ ]，内容提到全球市场存在大量未被挖掘的‘alpha’机会，包括定价错位、供应链低效、政策漏洞等，并提及‘Multi‑Agent AGENTIC α‑AGI’相关链接，涉及AGI和AI代理技术。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "So much winning?! https://t.co/TSbWJ1xfDB",
        "url": "https://x.com/GaryMarcus/status/1917698201424990703",
        "source": "Twitter-Gary Marcus",
        "content": "So much winning?! https://t.co/TSbWJ1xfDB",
        "hot": "",
        "time": "2025-04-30 21:50:54",
        "timestamp": 1746049854000,
        "published": "2025-04-30 21:50:54",
        "desc": "So much winning?! https://t.co/TSbWJ1xfDB",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "https://t.co/1c1WjFpOva",
        "url": "https://x.com/elonmusk/status/1917693698281787564",
        "source": "Twitter-Elon Musk",
        "content": "https://t.co/1c1WjFpOva",
        "hot": "",
        "time": "2025-04-30 21:33:01",
        "timestamp": 1746048781000,
        "published": "2025-04-30 21:33:01",
        "desc": "https://t.co/1c1WjFpOva",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "Ticket prices are rising soon—don’t miss your c...",
        "url": "https://x.com/AIconference/status/1917689882790502843",
        "source": "Twitter-The AI Conference",
        "content": "Ticket prices are rising soon—don’t miss your chance to save.\nJoin thousands of developers, engineers, and tech leaders at Mission Rock this September—starting at just $750 (before prices jump to $2,600).",
        "hot": "",
        "time": "2025-04-30 21:17:51",
        "timestamp": 1746047871000,
        "published": "2025-04-30 21:17:51",
        "desc": "Ticket prices are rising soon—don’t miss your chance to save.\nJoin thousands of developers, engineers, and tech leaders at Mission Rock this September—starting at just $750 (before prices jump to $2,600).",
        "summary": "新闻内容提到门票价格即将上涨，提醒读者抓住机会以较低价格参加Mission Rock活动，该活动将于9月举行，面向开发者、工程师和技术领袖，门票价格从750美元起，之后将上涨至2600美元。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Gemma 3 explained: Longer context, image suppor...",
        "url": "https://x.com/googleaidevs/status/1917687406481846591",
        "source": "Twitter-Google AI Developers",
        "content": "Gemma 3 explained: Longer context, image support, and a new 1B model. Read the blog for a deep dive into key enhancements → https://t.co/s1rDYsE7te https://t.co/nwEnqUJgSf",
        "hot": "",
        "time": "2025-04-30 21:08:01",
        "timestamp": 1746047281000,
        "published": "2025-04-30 21:08:01",
        "desc": "Gemma 3 explained: Longer context, image support, and a new 1B model. Read the blog for a deep dive into key enhancements → https://t.co/s1rDYsE7te https://t.co/nwEnqUJgSf",
        "summary": "Gemma 3 introduces longer context support, image capabilities, and a new 1B model. More details are available in the blog post.",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Plot twist https://t.co/2zyCsbDVyv",
        "url": "https://x.com/tunguz/status/1917681630992556069",
        "source": "Twitter-Bojan Tunguz",
        "content": "Plot twist https://t.co/2zyCsbDVyv",
        "hot": "",
        "time": "2025-04-30 20:45:04",
        "timestamp": 1746045904000,
        "published": "2025-04-30 20:45:04",
        "desc": "Plot twist https://t.co/2zyCsbDVyv",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "\"Where we stand today is not defined by the cap...",
        "url": "https://x.com/natolambert/status/1917675819188502582",
        "source": "Twitter-Nathan Lambert",
        "content": "\"Where we stand today is not defined by the capabilities we aspire to see in our AI models, but by the capabilities they achieve with near 100% success. Until we understand why and how these are achieved, we do not know where we stand, and we cannot reliably decide where to go!\"",
        "hot": "",
        "time": "2025-04-30 20:21:58",
        "timestamp": 1746044518000,
        "published": "2025-04-30 20:21:58",
        "desc": "\"Where we stand today is not defined by the capabilities we aspire to see in our AI models, but by the capabilities they achieve with near 100% success. Until we understand why and how these are achieved, we do not know where we stand, and we cannot reliably decide where to go!\"",
        "summary": "新闻内容强调当前AI模型的实际能力应基于其接近100%成功率的表现，而非仅凭期望的未来能力。理解这些成功的原因和方式，是确定当前地位和未来方向的关键。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "On May 21, @NexlaInc presents the Data + AI Int...",
        "url": "https://x.com/KirkDBorne/status/1917663748048802131",
        "source": "Twitter-Kirk Borne",
        "content": "On May 21, @NexlaInc presents the Data + AI Integration Summit—with a remarkable lineup of speakers: https://t.co/QZeBn1g2r8 #Ad\nLearn essential Data Engineering & Data Integration Modernization Best Practices to make your data AI-ready and to succeed with enterprise AI.",
        "hot": "",
        "time": "2025-04-30 19:34:00",
        "timestamp": 1746041640000,
        "published": "2025-04-30 19:34:00",
        "desc": "On May 21, @NexlaInc presents the Data + AI Integration Summit—with a remarkable lineup of speakers: https://t.co/QZeBn1g2r8 #Ad\nLearn essential Data Engineering & Data Integration Modernization Best Practices to make your data AI-ready and to succeed with enterprise AI.",
        "summary": "NexlaInc将于5月21日举办Data + AI集成峰会，分享数据工程与数据集成现代化最佳实践，帮助企业实现数据AI就绪并成功应用企业级AI。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Crypto & Stablecoin Legislation Will Be Pas...",
        "url": "https://x.com/ThinkingCrypto1/status/1917572130461605926",
        "source": "Twitter-Tony Edward (Thinking Crypto Podcast)",
        "content": "Crypto & Stablecoin Legislation Will Be Passed!\nWATCH ▶️ https://t.co/Sc42IZhS1A\nCongressman Tom Emmer joined me to discuss the latest with US crypto regulations.\nTopics:\n- President Trump’s first crypto bill signed into law - repeal of the IRS DeFi Rule\n- Crypto Market https://t.co/47l91bb8tI",
        "hot": "",
        "time": "2025-04-30 13:29:57",
        "timestamp": 1746019797000,
        "published": "2025-04-30 13:29:57",
        "desc": "Crypto & Stablecoin Legislation Will Be Passed!\nWATCH ▶️ https://t.co/Sc42IZhS1A\nCongressman Tom Emmer joined me to discuss the latest with US crypto regulations.\nTopics:\n- President Trump’s first crypto bill signed into law - repeal of the IRS DeFi Rule\n- Crypto Market https://t.co/47l91bb8tI",
        "summary": "新闻讨论了美国加密货币和稳定币立法的进展，包括特朗普签署的首个加密货币法案以及对IRS DeFi规则的废除。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Prompt-to-Earn is now live on web & mobile!...",
        "url": "https://x.com/ChainOpera_AI/status/1917550471784587676",
        "source": "Twitter-ChainOpera AI",
        "content": "Prompt-to-Earn is now live on web & mobile!\nhttps://t.co/tt0vieOgUa\nCreate high-quality prompts to boost our community-owned LLM and improve decentralized model inference across the globe—smarter, faster, cheaper, and more scalable.\nLet’s BUIDL Open AI together! https://t.co/cIWullq2nn",
        "hot": "",
        "time": "2025-04-30 12:03:53",
        "timestamp": 1746014633000,
        "published": "2025-04-30 12:03:53",
        "desc": "Prompt-to-Earn is now live on web & mobile!\nhttps://t.co/tt0vieOgUa\nCreate high-quality prompts to boost our community-owned LLM and improve decentralized model inference across the globe—smarter, faster, cheaper, and more scalable.\nLet’s BUIDL Open AI together! https://t.co/cIWullq2nn",
        "summary": "Prompt-to-Earn功能现已在网页和移动设备上上线，用户可通过创建高质量提示词来增强社区拥有的大型语言模型，推动去中心化模型推理的发展。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Founders, avoid the risks of hidden costs and m...",
        "url": "https://x.com/predotdev/status/1917688611211747794",
        "source": "Twitter-pre.dev",
        "content": "Founders, avoid the risks of hidden costs and missed deadlines that come with hiring your first developers.",
        "hot": "",
        "time": "2025-04-30 21:12:48",
        "timestamp": 1746047568000,
        "published": "2025-04-30 21:12:48",
        "desc": "Founders, avoid the risks of hidden costs and missed deadlines that come with hiring your first developers.",
        "summary": "新闻提醒初创公司创始人在雇佣首批开发者时要注意隐藏成本和可能错过截止日期的风险。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Amazon updates Q Business to let companies buil...",
        "url": "https://x.com/Kyle_L_Wiggers/status/1917673951938986331",
        "source": "Twitter-Kyle Wiggers",
        "content": "Amazon updates Q Business to let companies build public-facing chatbots https://t.co/wii1zoAEqN",
        "hot": "",
        "time": "2025-04-30 20:14:33",
        "timestamp": 1746044073000,
        "published": "2025-04-30 20:14:33",
        "desc": "Amazon updates Q Business to let companies build public-facing chatbots https://t.co/wii1zoAEqN",
        "summary": "Amazon更新了Q Business，使公司能够构建面向公众的聊天机器人。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "🍕🚗 @yumbrands is embracing AI to transform the ...",
        "url": "https://x.com/NVIDIAAI/status/1917670296091344922",
        "source": "Twitter-NVIDIA AI",
        "content": "🍕🚗 @yumbrands is embracing AI to transform the restaurant experience.\nAt #GTC25, we announced a strategic partnership, with a goal of deploying AI solutions in 500 restaurants.\nJoe Park joins the NVIDIA AI Podcast to share more.\n🎧 https://t.co/Oyej7F6OcZ\n📖 https://t.co/6gkQwxI9Y4",
        "hot": "",
        "time": "2025-04-30 20:00:01",
        "timestamp": 1746043201000,
        "published": "2025-04-30 20:00:01",
        "desc": "🍕🚗 @yumbrands is embracing AI to transform the restaurant experience.\nAt #GTC25, we announced a strategic partnership, with a goal of deploying AI solutions in 500 restaurants.\nJoe Park joins the NVIDIA AI Podcast to share more.\n🎧 https://t.co/Oyej7F6OcZ\n📖 https://t.co/6gkQwxI9Y4",
        "summary": "Yum! Brands正在通过AI技术革新餐厅体验，并在GTC25上宣布与合作伙伴达成战略协议，计划在500家餐厅部署AI解决方案。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "One of the top use cases for autonomous code ag...",
        "url": "https://x.com/mathemagic1an/status/1917669780951290268",
        "source": "Twitter-Jay Hack",
        "content": "One of the top use cases for autonomous code agents that has been \"solved\" by the latest wave of capabilities (Claude 3.7):\nComment @codegen on any PR with a modification request ✅\nIn ~1 year will feel crazy that we never had this before. Similar to better autocomplete. https://t.co/1FC7RSRAda",
        "hot": "",
        "time": "2025-04-30 19:57:59",
        "timestamp": 1746043079000,
        "published": "2025-04-30 19:57:59",
        "desc": "One of the top use cases for autonomous code agents that has been \"solved\" by the latest wave of capabilities (Claude 3.7):\nComment @codegen on any PR with a modification request ✅\nIn ~1 year will feel crazy that we never had this before. Similar to better autocomplete. https://t.co/1FC7RSRAda",
        "summary": "新闻讨论了Claude 3.7最新功能中，自主代码代理的一个主要应用场景：在PR中通过@codegen进行修改请求。该功能类似于更智能的自动补全，预计未来一年将变得非常普遍。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "#1 New Release!\nAI Value Creators - Beyond the...",
        "url": "https://x.com/KirkDBorne/status/1917664492877467875",
        "source": "Twitter-Kirk Borne",
        "content": "#1 New Release!\nAI Value Creators - Beyond the Generative AI User Mindset: https://t.co/QmmAdnMGFR from @OReillyMedia https://t.co/gpUxt5TVfh",
        "hot": "",
        "time": "2025-04-30 19:36:58",
        "timestamp": 1746041818000,
        "published": "2025-04-30 19:36:58",
        "desc": "#1 New Release!\nAI Value Creators - Beyond the Generative AI User Mindset: https://t.co/QmmAdnMGFR from @OReillyMedia https://t.co/gpUxt5TVfh",
        "summary": "新闻标题为“New Release! AI Value Creators - Beyond the Generative AI User Mindset”，内容提及一本由OReillyMedia发布的关于AI价值创造的新书，并附有链接。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Here's my conversation with Tim Sweeney (@timsw...",
        "url": "https://x.com/lexfridman/status/1917661573142765988",
        "source": "Twitter-Lex Fridman",
        "content": "Here's my conversation with Tim Sweeney (@timsweeneyepic), a legendary video game programmer, founder and CEO of Epic Games that created the Unreal Engine, Fortnite, Gears of War, Unreal Tournament, and many other groundbreaking and influential video games.\nIt's here on X in https://t.co/JuSChF64CH",
        "hot": "",
        "time": "2025-04-30 19:25:22",
        "timestamp": 1746041122000,
        "published": "2025-04-30 19:25:22",
        "desc": "Here's my conversation with Tim Sweeney (@timsweeneyepic), a legendary video game programmer, founder and CEO of Epic Games that created the Unreal Engine, Fortnite, Gears of War, Unreal Tournament, and many other groundbreaking and influential video games.\nIt's here on X in https://t.co/JuSChF64CH",
        "summary": "本文记录了与Epic Games创始人Tim Sweeney的对话，Epic Games开发了Unreal Engine、Fortnite、Gears of War等知名游戏。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "https://t.co/4QMKJ5wc3m",
        "url": "https://x.com/midjourney/status/1917658404308541701",
        "source": "Twitter-Midjourney",
        "content": "https://t.co/4QMKJ5wc3m",
        "hot": "",
        "time": "2025-04-30 19:12:46",
        "timestamp": 1746040366000,
        "published": "2025-04-30 19:12:46",
        "desc": "https://t.co/4QMKJ5wc3m",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "Tampa is awesome. https://t.co/3emUc2wCnV",
        "url": "https://x.com/tunguz/status/1917657284496482684",
        "source": "Twitter-Bojan Tunguz",
        "content": "Tampa is awesome. https://t.co/3emUc2wCnV",
        "hot": "",
        "time": "2025-04-30 19:08:19",
        "timestamp": 1746040099000,
        "published": "2025-04-30 19:08:19",
        "desc": "Tampa is awesome. https://t.co/3emUc2wCnV",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "it is funny to me that a typewriter company (Re...",
        "url": "https://x.com/wintonARK/status/1917652357346627655",
        "source": "Twitter-Brett Winton",
        "content": "it is funny to me that a typewriter company (Remington Rand) acquired the patents for and sold the first commercial computer (the UNIVAC I)\nBy 1952 they had sold in 5 units--they had the market to themselves!\n1954: 8 more UNIVACs sold. Still healthy growth.\nAnd yet they were",
        "hot": "",
        "time": "2025-04-30 18:48:44",
        "timestamp": 1746038924000,
        "published": "2025-04-30 18:48:44",
        "desc": "it is funny to me that a typewriter company (Remington Rand) acquired the patents for and sold the first commercial computer (the UNIVAC I)\nBy 1952 they had sold in 5 units--they had the market to themselves!\n1954: 8 more UNIVACs sold. Still healthy growth.\nAnd yet they were",
        "summary": "新闻讲述了Remington Rand公司收购并销售了第一台商用计算机UNIVAC I的专利，1952年售出5台，1954年又售出8台，显示其在早期计算机市场的主导地位。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "[ α‑AGI Agents👁️✨ ]\nGitHub: https://t.co/WNdCB...",
        "url": "https://x.com/ceobillionaire/status/1917652076122804564",
        "source": "Twitter-AGI.Eth",
        "content": "[ α‑AGI Agents👁️✨ ]\nGitHub: https://t.co/WNdCB0N7eZ\nMade with ❤️ by the Alpha‑Factory Agentic Core Team\n#AGI #AIAgent #AGIALPHA https://t.co/MPCkJELGqk",
        "hot": "",
        "time": "2025-04-30 18:47:37",
        "timestamp": 1746038857000,
        "published": "2025-04-30 18:47:37",
        "desc": "[ α‑AGI Agents👁️✨ ]\nGitHub: https://t.co/WNdCB0N7eZ\nMade with ❤️ by the Alpha‑Factory Agentic Core Team\n#AGI #AIAgent #AGIALPHA https://t.co/MPCkJELGqk",
        "summary": "新闻标题为[ α‑AGI Agents👁️✨ ]，并提供了GitHub链接。内容包含#AGI、#AIAgent等标签，由Alpha‑Factory Agentic Core Team制作。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "\"OS/2 2.0 is a better DOS than DOS and a better...",
        "url": "https://x.com/wintonARK/status/1917648035716227283",
        "source": "Twitter-Brett Winton",
        "content": "\"OS/2 2.0 is a better DOS than DOS and a better Windows than Windows.\"\n-IBM, while in the process of losing a platform war\nhttps://t.co/lvR1Lq0qrh",
        "hot": "",
        "time": "2025-04-30 18:31:34",
        "timestamp": 1746037894000,
        "published": "2025-04-30 18:31:34",
        "desc": "\"OS/2 2.0 is a better DOS than DOS and a better Windows than Windows.\"\n-IBM, while in the process of losing a platform war\nhttps://t.co/lvR1Lq0qrh",
        "summary": "新闻标题和内容提到OS/2 2.0比DOS和Windows更好，同时提到IBM在失去平台战争的过程中。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "🚀 AI agents are reshaping enterprise automation...",
        "url": "https://x.com/LangChainAI/status/1917646746798416121",
        "source": "Twitter-LangChain",
        "content": "🚀 AI agents are reshaping enterprise automation—and we're thrilled to partner with @UiPath to make building, deploying, and observing them easier than ever.\nRead about their:\n🔍 Native LangSmith support in UiPath LLM Gateway\n🤖 LangGraph agent support via Agent Protocol &",
        "hot": "",
        "time": "2025-04-30 18:26:27",
        "timestamp": 1746037587000,
        "published": "2025-04-30 18:26:27",
        "desc": "🚀 AI agents are reshaping enterprise automation—and we're thrilled to partner with @UiPath to make building, deploying, and observing them easier than ever.\nRead about their:\n🔍 Native LangSmith support in UiPath LLM Gateway\n🤖 LangGraph agent support via Agent Protocol &",
        "summary": "新闻介绍了AI代理如何改变企业自动化，并提到与UiPath合作，简化AI代理的构建、部署和监控过程，包括LangSmith和LangGraph的支持。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "基于你和 AI 聊天会话，让 AI 帮你成长的提示词，使用推理模型效果最佳：\n***",
        "url": "https://x.com/dotey/status/1917644594201714972",
        "source": "Twitter-宝玉",
        "content": "基于你和 AI 聊天会话，让 AI 帮你成长的提示词，使用推理模型效果最佳：\n***",
        "hot": "",
        "time": "2025-04-30 18:17:54",
        "timestamp": 1746037074000,
        "published": "2025-04-30 18:17:54",
        "desc": "基于你和 AI 聊天会话，让 AI 帮你成长的提示词，使用推理模型效果最佳：\n***",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "New video: How to run & finetune OSS on Tog...",
        "url": "https://x.com/togethercompute/status/1917641895699718580",
        "source": "Twitter-Together AI",
        "content": "New video: How to run & finetune OSS on Together AI\nhttps://t.co/R7B0htYvnl",
        "hot": "",
        "time": "2025-04-30 18:07:10",
        "timestamp": 1746036430000,
        "published": "2025-04-30 18:07:10",
        "desc": "New video: How to run & finetune OSS on Together AI\nhttps://t.co/R7B0htYvnl",
        "summary": "新闻内容为一个新视频，介绍如何在Together AI上运行和微调OSS模型。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Universal RAG\nRAG is dead, they said.\nThen yo...",
        "url": "https://x.com/omarsar0/status/1917637837295608180",
        "source": "Twitter-elvis",
        "content": "Universal RAG\nRAG is dead, they said.\nThen you see papers like this and it gives you a better understanding of the opportunities and challenges ahead.\nLots of great ideas in this paper. I've summarized a few below: https://t.co/13VRUFUQbA",
        "hot": "",
        "time": "2025-04-30 17:51:03",
        "timestamp": 1746035463000,
        "published": "2025-04-30 17:51:03",
        "desc": "Universal RAG\nRAG is dead, they said.\nThen you see papers like this and it gives you a better understanding of the opportunities and challenges ahead.\nLots of great ideas in this paper. I've summarized a few below: https://t.co/13VRUFUQbA",
        "summary": "新闻标题为'Universal RAG'，内容提到RAG已死，但随后出现的新论文展示了其未来的机会和挑战，并列举了一些优秀的想法。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "https://t.co/bIGHsxAM5W",
        "url": "https://x.com/tunguz/status/1917636882474692987",
        "source": "Twitter-Bojan Tunguz",
        "content": "https://t.co/bIGHsxAM5W",
        "hot": "",
        "time": "2025-04-30 17:47:15",
        "timestamp": 1746035235000,
        "published": "2025-04-30 17:47:15",
        "desc": "https://t.co/bIGHsxAM5W",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "Glazing-as-a-Service",
        "url": "https://x.com/tunguz/status/1917633984873353695",
        "source": "Twitter-Bojan Tunguz",
        "content": "Glazing-as-a-Service",
        "hot": "",
        "time": "2025-04-30 17:35:44",
        "timestamp": 1746034544000,
        "published": "2025-04-30 17:35:44",
        "desc": "Glazing-as-a-Service",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "✨What Is LangSmith? Explained in 5 Minutes\nHav...",
        "url": "https://x.com/LangChainAI/status/1917632543009972632",
        "source": "Twitter-LangChain",
        "content": "✨What Is LangSmith? Explained in 5 Minutes\nHave you checked out LangSmith yet?\nIn our quick 5-min video, see how LangChain’s commercial platform helps developers improve LLM applications & agent performance at every step of the development lifecycle — from observability, https://t.co/owjebC9MlS",
        "hot": "",
        "time": "2025-04-30 17:30:00",
        "timestamp": 1746034200000,
        "published": "2025-04-30 17:30:00",
        "desc": "✨What Is LangSmith? Explained in 5 Minutes\nHave you checked out LangSmith yet?\nIn our quick 5-min video, see how LangChain’s commercial platform helps developers improve LLM applications & agent performance at every step of the development lifecycle — from observability, https://t.co/owjebC9MlS",
        "summary": "新闻介绍了LangSmith，这是LangChain的商业平台，帮助开发者在开发生命周期的每个阶段提升大型语言模型（LLM）应用和代理的性能，包括可观测性等功能。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "JetBrains releases Mellum, an ‘open’ AI coding ...",
        "url": "https://x.com/Kyle_L_Wiggers/status/1917629925516861890",
        "source": "Twitter-Kyle Wiggers",
        "content": "JetBrains releases Mellum, an ‘open’ AI coding model https://t.co/7slY4yDdin",
        "hot": "",
        "time": "2025-04-30 17:19:36",
        "timestamp": 1746033576000,
        "published": "2025-04-30 17:19:36",
        "desc": "JetBrains releases Mellum, an ‘open’ AI coding model https://t.co/7slY4yDdin",
        "summary": "JetBrains发布了名为Mellum的‘开放’AI编码模型。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "We believe AI development is entering a critica...",
        "url": "https://x.com/jackclarkSF/status/1917629786861756676",
        "source": "Twitter-Jack Clark",
        "content": "We believe AI development is entering a critical period - the moves countries make during the next few years could lead to stable, careful development of powerful technology, or an uncoordinated proliferation of extremely powerful things.",
        "hot": "",
        "time": "2025-04-30 17:19:03",
        "timestamp": 1746033543000,
        "published": "2025-04-30 17:19:03",
        "desc": "We believe AI development is entering a critical period - the moves countries make during the next few years could lead to stable, careful development of powerful technology, or an uncoordinated proliferation of extremely powerful things.",
        "summary": "新闻认为AI发展正进入关键时期，各国未来几年的举措可能引导技术稳定发展，或导致强大技术的无序扩散。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Today Anthropic submitted key recommendations o...",
        "url": "https://x.com/jackclarkSF/status/1917629783090831582",
        "source": "Twitter-Jack Clark",
        "content": "Today Anthropic submitted key recommendations on the \"Diffusion Rule\" - export controls on advanced AI chips. We believe maintaining America's compute advantage is essential for national security as powerful AI systems develop. https://t.co/lnzuK1DmAo",
        "hot": "",
        "time": "2025-04-30 17:19:02",
        "timestamp": 1746033542000,
        "published": "2025-04-30 17:19:02",
        "desc": "Today Anthropic submitted key recommendations on the \"Diffusion Rule\" - export controls on advanced AI chips. We believe maintaining America's compute advantage is essential for national security as powerful AI systems develop. https://t.co/lnzuK1DmAo",
        "summary": "Anthropic提交了关于'扩散规则'的关键建议，涉及对先进AI芯片的出口管制。他们认为保持美国在计算能力上的优势对国家安全至关重要。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Today we are releasing Gen-4 References to all ...",
        "url": "https://x.com/runwayml/status/1917628723903463526",
        "source": "Twitter-Runway",
        "content": "Today we are releasing Gen-4 References to all paid plans. Now anyone can generate consistent characters, locations and more. With References, you can use photos, generated images, 3D models or selfies to place yourself or others into any scene you can imagine.\nMore examples https://t.co/Je59RsRnyW",
        "hot": "",
        "time": "2025-04-30 17:14:50",
        "timestamp": 1746033290000,
        "published": "2025-04-30 17:14:50",
        "desc": "Today we are releasing Gen-4 References to all paid plans. Now anyone can generate consistent characters, locations and more. With References, you can use photos, generated images, 3D models or selfies to place yourself or others into any scene you can imagine.\nMore examples https://t.co/Je59RsRnyW",
        "summary": "该新闻宣布向所有付费计划开放Gen-4 References功能，用户可利用照片、生成图像、3D模型或自拍将人物或场景融入任何想象中的场景。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "smolagents is very small https://t.co/15gUMK1UeS",
        "url": "https://x.com/Thom_Wolf/status/1917617829282496519",
        "source": "Twitter-Thomas Wolf",
        "content": "smolagents is very small https://t.co/15gUMK1UeS",
        "hot": "",
        "time": "2025-04-30 16:31:32",
        "timestamp": 1746030692000,
        "published": "2025-04-30 16:31:32",
        "desc": "smolagents is very small https://t.co/15gUMK1UeS",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "Why Slice is way easier than CapCut for cutting...",
        "url": "https://x.com/aonefischer/status/1917617060827283587",
        "source": "Twitter-Aaron Fischer",
        "content": "Why Slice is way easier than CapCut for cutting clips.\nCapCut is great if you want to spend 30 minutes editing.\nBut what if you just want to cut the best parts from a video fast — and get back to life?\nThat’s why I made Slice 👇 https://t.co/DP3UhXgxqp",
        "hot": "",
        "time": "2025-04-30 16:28:29",
        "timestamp": 1746030509000,
        "published": "2025-04-30 16:28:29",
        "desc": "Why Slice is way easier than CapCut for cutting clips.\nCapCut is great if you want to spend 30 minutes editing.\nBut what if you just want to cut the best parts from a video fast — and get back to life?\nThat’s why I made Slice 👇 https://t.co/DP3UhXgxqp",
        "summary": "文章比较了Slice和CapCut两款视频编辑工具，指出Slice在快速剪辑视频方面更加便捷，适合需要快速完成剪辑任务的用户。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "You can now run inference directly on the Qwen ...",
        "url": "https://x.com/togethercompute/status/1917616701249565120",
        "source": "Twitter-Together AI",
        "content": "You can now run inference directly on the Qwen 3 235B Hugging Face model page – powered by Together AI! https://t.co/0uPZHFXYe6",
        "hot": "",
        "time": "2025-04-30 16:27:03",
        "timestamp": 1746030423000,
        "published": "2025-04-30 16:27:03",
        "desc": "You can now run inference directly on the Qwen 3 235B Hugging Face model page – powered by Together AI! https://t.co/0uPZHFXYe6",
        "summary": "用户现在可以直接在Hugging Face平台上对Qwen 3 235B模型进行推理，该功能由Together AI提供支持。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Improve your LLM-based applications by 200%:\nB...",
        "url": "https://x.com/svpino/status/1917612924639797563",
        "source": "Twitter-Santiago",
        "content": "Improve your LLM-based applications by 200%:\nBuild an LLM-as-a-Judge evaluator and integrate it with your system.\nThis sounds harder than it is.\nHere is how to do it and the things you need to keep in mind:\n1/11 https://t.co/FDgOKSBAw4",
        "hot": "",
        "time": "2025-04-30 16:12:03",
        "timestamp": 1746029523000,
        "published": "2025-04-30 16:12:03",
        "desc": "Improve your LLM-based applications by 200%:\nBuild an LLM-as-a-Judge evaluator and integrate it with your system.\nThis sounds harder than it is.\nHere is how to do it and the things you need to keep in mind:\n1/11 https://t.co/FDgOKSBAw4",
        "summary": "新闻介绍了如何通过构建LLM-as-a-Judge评估器来提升基于大语言模型的应用性能，声称可提高200%。文章提供实现方法和注意事项，并附有链接。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "又是一波节前集中发货，最先进的数学定理证明DeepSeek-Prover V2刚刚放出来了，能...",
        "url": "https://x.com/aigclink/status/1917612344030683564",
        "source": "Twitter-AIGCLINK",
        "content": "又是一波节前集中发货，最先进的数学定理证明DeepSeek-Prover V2刚刚放出来了，能够自动推到和验证复杂的数学定理，像我们这种数学系的学渣有种被拯救的赶脚😄！\nProver-V2是一个用于自动定理证明的模型，它可以理解数学问题，并用Lean 4生成证明，也是首个用RL实现数学证明垂直场景的模型。 https://t.co/h1P60ga8ag",
        "hot": "",
        "time": "2025-04-30 16:09:44",
        "timestamp": 1746029384000,
        "published": "2025-04-30 16:09:44",
        "desc": "又是一波节前集中发货，最先进的数学定理证明DeepSeek-Prover V2刚刚放出来了，能够自动推到和验证复杂的数学定理，像我们这种数学系的学渣有种被拯救的赶脚😄！\nProver-V2是一个用于自动定理证明的模型，它可以理解数学问题，并用Lean 4生成证明，也是首个用RL实现数学证明垂直场景的模型。 https://t.co/h1P60ga8ag",
        "summary": "DeepSeek-Prover V2是一款先进的数学定理证明模型，能够自动推导和验证复杂数学定理，使用Lean 4生成证明，并首次在数学证明领域应用强化学习技术。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "DEI is poor man’s IDE",
        "url": "https://x.com/tunguz/status/1917610676547146208",
        "source": "Twitter-Bojan Tunguz",
        "content": "DEI is poor man’s IDE",
        "hot": "",
        "time": "2025-04-30 16:03:07",
        "timestamp": 1746028987000,
        "published": "2025-04-30 16:03:07",
        "desc": "DEI is poor man’s IDE",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "Don’t miss our CEO Jensen Huang and @Dell Chair...",
        "url": "https://x.com/NVIDIAAI/status/1917609898067570733",
        "source": "Twitter-NVIDIA AI",
        "content": "Don’t miss our CEO Jensen Huang and @Dell Chairman & CEO Michael Dell at the Inventing the Future Keynote at #DellTechWorld.\nGet the latest insights into how we are collaborating with Dell to harness the power of AI and accelerate enterprise solutions.\nRegister now ➡️ https://t.co/TftvzvqCAH",
        "hot": "",
        "time": "2025-04-30 16:00:01",
        "timestamp": 1746028801000,
        "published": "2025-04-30 16:00:01",
        "desc": "Don’t miss our CEO Jensen Huang and @Dell Chairman & CEO Michael Dell at the Inventing the Future Keynote at #DellTechWorld.\nGet the latest insights into how we are collaborating with Dell to harness the power of AI and accelerate enterprise solutions.\nRegister now ➡️ https://t.co/TftvzvqCAH",
        "summary": "NVIDIA CEO Jensen Huang与Dell董事长兼CEO Michael Dell在DellTechWorld的Inventing the Future Keynote上讨论双方合作，利用AI加速企业解决方案。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Join us at #NYTechWeek, featuring events with:\n...",
        "url": "https://x.com/a16z/status/1917609652159930384",
        "source": "Twitter-a16z",
        "content": "Join us at #NYTechWeek, featuring events with:\n@dhaber\n@andrewchen\nThe a16z podcast\n@a16ztxo\n@speedrun\nAnd more, from June 2 to 8.\nRegister now: https://t.co/wON3TgxYe8\nAnd follow @Techweek_ for more updates. https://t.co/aL3zIz1HO3",
        "hot": "",
        "time": "2025-04-30 15:59:03",
        "timestamp": 1746028743000,
        "published": "2025-04-30 15:59:03",
        "desc": "Join us at #NYTechWeek, featuring events with:\n@dhaber\n@andrewchen\nThe a16z podcast\n@a16ztxo\n@speedrun\nAnd more, from June 2 to 8.\nRegister now: https://t.co/wON3TgxYe8\nAnd follow @Techweek_ for more updates. https://t.co/aL3zIz1HO3",
        "summary": "邀请参加#NYTechWeek活动，包括多位科技领域嘉宾和相关事件，活动时间为6月2日至8日，注册链接已提供。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "What's your favorite AI chatbot?",
        "url": "https://x.com/MIT_CSAIL/status/1917608421689549008",
        "source": "Twitter-MIT CSAIL",
        "content": "What's your favorite AI chatbot?",
        "hot": "",
        "time": "2025-04-30 15:54:09",
        "timestamp": 1746028449000,
        "published": "2025-04-30 15:54:09",
        "desc": "What's your favorite AI chatbot?",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "We need to legalize math in California\nToday t...",
        "url": "https://x.com/garrytan/status/1917606751798714627",
        "source": "Twitter-Garry Tan",
        "content": "We need to legalize math in California\nToday the anti-math education bureaucrats are trying to force the UC system to water down math standards to accept fake data science courses that don’t teach algebra\nWe interviewed @minilek, CS division chair @ Berkeley to get the low down https://t.co/cBwYbulQTw",
        "hot": "",
        "time": "2025-04-30 15:47:31",
        "timestamp": 1746028051000,
        "published": "2025-04-30 15:47:31",
        "desc": "We need to legalize math in California\nToday the anti-math education bureaucrats are trying to force the UC system to water down math standards to accept fake data science courses that don’t teach algebra\nWe interviewed @minilek, CS division chair @ Berkeley to get the low down https://t.co/cBwYbulQTw",
        "summary": "新闻讨论加州数学教育政策，批评反数学教育的官僚试图降低加州大学系统的数学标准，接受不教授代数的虚假数据科学课程。采访了伯克利计算机科学系主任以获取更多信息。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "A better title for my most recent piece may hav...",
        "url": "https://x.com/natolambert/status/1917605710344642817",
        "source": "Twitter-Nathan Lambert",
        "content": "A better title for my most recent piece may have been \"The state of play on AI progress,\" but with the share image y'all may think I'm team Gary.\nMore like team Cowen - slow steady march.\nhttps://t.co/01N3av9KaU",
        "hot": "",
        "time": "2025-04-30 15:43:23",
        "timestamp": 1746027803000,
        "published": "2025-04-30 15:43:23",
        "desc": "A better title for my most recent piece may have been \"The state of play on AI progress,\" but with the share image y'all may think I'm team Gary.\nMore like team Cowen - slow steady march.\nhttps://t.co/01N3av9KaU",
        "summary": "作者提到其最近一篇文章的标题可能应为‘AI进展的现状’，并提到由于配图可能让人误以为他支持Gary，但实际上他更倾向于Cowen的‘缓慢稳步前进’的观点。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "The popular course \"LLMs as Operating Systems: ...",
        "url": "https://x.com/DeepLearningAI/status/1917602387381924173",
        "source": "Twitter-DeepLearning.AI",
        "content": "The popular course \"LLMs as Operating Systems: Agent Memory\" just got a memorable update!\nThis free course, created with Letta and taught by its founders Charles Packer and Sarah Wooders, walks you through the MemGPT approach: using an LLM agent to manage long-term memory beyond https://t.co/KQys6c9J6i",
        "hot": "",
        "time": "2025-04-30 15:30:11",
        "timestamp": 1746027011000,
        "published": "2025-04-30 15:30:11",
        "desc": "The popular course \"LLMs as Operating Systems: Agent Memory\" just got a memorable update!\nThis free course, created with Letta and taught by its founders Charles Packer and Sarah Wooders, walks you through the MemGPT approach: using an LLM agent to manage long-term memory beyond https://t.co/KQys6c9J6i",
        "summary": "The popular course 'LLMs as Operating Systems: Agent Memory' has been updated. It teaches the MemGPT approach, using LLM agents to manage long-term memory.",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "We just announced what could become the largest...",
        "url": "https://x.com/ClementDelangue/status/1917598288938782968",
        "source": "Twitter-clem 🤗",
        "content": "We just announced what could become the largest robotics hackathon ever! June 14th (it's my birthday too haha!). https://t.co/QsIPEqKehA",
        "hot": "",
        "time": "2025-04-30 15:13:53",
        "timestamp": 1746026033000,
        "published": "2025-04-30 15:13:53",
        "desc": "We just announced what could become the largest robotics hackathon ever! June 14th (it's my birthday too haha!). https://t.co/QsIPEqKehA",
        "summary": "该新闻宣布将举办可能是有史以来最大的机器人黑客马拉松，活动定于6月14日举行。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "🎟️ Tickets are sold out for Interrupt — stay tu...",
        "url": "https://x.com/LangChainAI/status/1917594807985197213",
        "source": "Twitter-LangChain",
        "content": "🎟️ Tickets are sold out for Interrupt — stay tuned for session highlights at https://t.co/2zVGY758u6. In the meantime, spend some time with event sponsor Cisco and help ensure AI works for you. #LangChain #Interrupt2025\n🔗 https://t.co/tcEXSX9BVQ https://t.co/CKSQRFROQi",
        "hot": "",
        "time": "2025-04-30 15:00:04",
        "timestamp": 1746025204000,
        "published": "2025-04-30 15:00:04",
        "desc": "🎟️ Tickets are sold out for Interrupt — stay tuned for session highlights at https://t.co/2zVGY758u6. In the meantime, spend some time with event sponsor Cisco and help ensure AI works for you. #LangChain #Interrupt2025\n🔗 https://t.co/tcEXSX9BVQ https://t.co/CKSQRFROQi",
        "summary": "Tickets for the Interrupt event have sold out, and attendees are directed to a link for session highlights. The event sponsor Cisco is mentioned, along with a reference to AI and LangChain.",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Join Jensen Huang, Founder and CEO, NVIDIA, and...",
        "url": "https://x.com/NVIDIAAI/status/1917594798447300984",
        "source": "Twitter-NVIDIA AI",
        "content": "Join Jensen Huang, Founder and CEO, NVIDIA, and Anirudh Devgan, President and CEO, @Cadence for an exclusive fireside chat at CadenceLIVE.\nLearn about the future of AI, accelerated computing, and electronic design. ➡️ https://t.co/y1HvWg7tfv https://t.co/keeDdjLKFh",
        "hot": "",
        "time": "2025-04-30 15:00:01",
        "timestamp": 1746025201000,
        "published": "2025-04-30 15:00:01",
        "desc": "Join Jensen Huang, Founder and CEO, NVIDIA, and Anirudh Devgan, President and CEO, @Cadence for an exclusive fireside chat at CadenceLIVE.\nLearn about the future of AI, accelerated computing, and electronic design. ➡️ https://t.co/y1HvWg7tfv https://t.co/keeDdjLKFh",
        "summary": "NVIDIA创始人兼CEO Jensen Huang与Cadence总裁兼CEO Anirudh Devgan将在CadenceLIVE上进行独家对话，探讨AI、加速计算和电子设计的未来。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "We’re helping robots self-improve with the powe...",
        "url": "https://x.com/GoogleDeepMind/status/1917593514566901800",
        "source": "Twitter-Google DeepMind",
        "content": "We’re helping robots self-improve with the power of LLMs. 🤖\nIntroducing the Summarize, Analyze, Synthesize (SAS) prompt, which analyzes how they perform tasks based on previous actions and then suggests ways for them to get better using the medium of table tennis. 🏓 https://t.co/2LupVBkJ7Z",
        "hot": "",
        "time": "2025-04-30 14:54:55",
        "timestamp": 1746024895000,
        "published": "2025-04-30 14:54:55",
        "desc": "We’re helping robots self-improve with the power of LLMs. 🤖\nIntroducing the Summarize, Analyze, Synthesize (SAS) prompt, which analyzes how they perform tasks based on previous actions and then suggests ways for them to get better using the medium of table tennis. 🏓 https://t.co/2LupVBkJ7Z",
        "summary": "新闻介绍了利用大型语言模型（LLMs）帮助机器人通过分析任务表现并提出改进建议的方式，以乒乓球为媒介进行自我提升。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Thrilled to announce that our partnership with ...",
        "url": "https://x.com/PersonalAI_/status/1917592678038134960",
        "source": "Twitter-Personal AI",
        "content": "Thrilled to announce that our partnership with @nvidia has culminated in Personal AI Receptionist, a cutting edge solution for SMBs to adopt AI directly through their telecommunications provider, leveraging Personal AI's latest core technology.\nTo learn more about our work with https://t.co/F4yzAPe6NH",
        "hot": "",
        "time": "2025-04-30 14:51:36",
        "timestamp": 1746024696000,
        "published": "2025-04-30 14:51:36",
        "desc": "Thrilled to announce that our partnership with @nvidia has culminated in Personal AI Receptionist, a cutting edge solution for SMBs to adopt AI directly through their telecommunications provider, leveraging Personal AI's latest core technology.\nTo learn more about our work with https://t.co/F4yzAPe6NH",
        "summary": "公司宣布与NVIDIA合作推出Personal AI Receptionist，为中小企业提供通过电信运营商直接采用AI的解决方案，利用Personal AI的最新核心技术。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "How DocentPro powers AI trip planning with Lang...",
        "url": "https://x.com/LangChainAI/status/1917591537715929190",
        "source": "Twitter-LangChain",
        "content": "How DocentPro powers AI trip planning with LangGraph\n@docentpro_sf is building an AI travel assistant that helps users go from idea → itinerary → booking. Using LangGraph + LangSmith, they’ve created a modular multi-agent system that handles discovery, planning, and real-time https://t.co/lniEAZdEjZ",
        "hot": "",
        "time": "2025-04-30 14:47:04",
        "timestamp": 1746024424000,
        "published": "2025-04-30 14:47:04",
        "desc": "How DocentPro powers AI trip planning with LangGraph\n@docentpro_sf is building an AI travel assistant that helps users go from idea → itinerary → booking. Using LangGraph + LangSmith, they’ve created a modular multi-agent system that handles discovery, planning, and real-time https://t.co/lniEAZdEjZ",
        "summary": "DocentPro利用LangGraph和LangSmith构建了一个模块化的多智能体系统，用于AI旅行规划，帮助用户从想法到行程再到预订。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "AI Replies that Sound Like You\nAmazing Results ...",
        "url": "https://x.com/CranQnow/status/1917591520930324798",
        "source": "Twitter-CRANQ",
        "content": "AI Replies that Sound Like You\nAmazing Results - Free Beta ⚡",
        "hot": "",
        "time": "2025-04-30 14:47:00",
        "timestamp": 1746024420000,
        "published": "2025-04-30 14:47:00",
        "desc": "AI Replies that Sound Like You\nAmazing Results - Free Beta ⚡",
        "summary": "新闻介绍了一项AI技术，能够生成听起来像用户的回复，目前提供免费测试版。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Aero-1-Audio is out on Hugging Face\nTrained in...",
        "url": "https://x.com/_akhaliq/status/1917588659760501001",
        "source": "Twitter-AK",
        "content": "Aero-1-Audio is out on Hugging Face\nTrained in <24h on just 16×H100\nHandles 15+ min audio seamlessly\nOutperforms bigger models like Whisper, Qwen-2-Audio & commercial services from ElevenLabs/Scribe https://t.co/8lyqB4Ypdt",
        "hot": "",
        "time": "2025-04-30 14:35:38",
        "timestamp": 1746023738000,
        "published": "2025-04-30 14:35:38",
        "desc": "Aero-1-Audio is out on Hugging Face\nTrained in <24h on just 16×H100\nHandles 15+ min audio seamlessly\nOutperforms bigger models like Whisper, Qwen-2-Audio & commercial services from ElevenLabs/Scribe https://t.co/8lyqB4Ypdt",
        "summary": "Aero-1-Audio模型已在Hugging Face发布，该模型在不到24小时内使用16个H100 GPU训练完成，能够无缝处理15分钟以上的音频，并在性能上超越了Whisper、Qwen-2-Audio等大型模型及商业服务。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "ChatGPT just helped me recover a couple of Word...",
        "url": "https://x.com/tunguz/status/1917588299985674505",
        "source": "Twitter-Bojan Tunguz",
        "content": "ChatGPT just helped me recover a couple of Word documents that I didn't save before Word was force shut down. So definitely a very useful technology.",
        "hot": "",
        "time": "2025-04-30 14:34:12",
        "timestamp": 1746023652000,
        "published": "2025-04-30 14:34:12",
        "desc": "ChatGPT just helped me recover a couple of Word documents that I didn't save before Word was force shut down. So definitely a very useful technology.",
        "summary": "ChatGPT帮助用户恢复了未保存的Word文档，展示了其在数据恢复方面的实用性。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Building an MCP Server with Gradio is out\nimpo...",
        "url": "https://x.com/_akhaliq/status/1917587214164242728",
        "source": "Twitter-AK",
        "content": "Building an MCP Server with Gradio is out\nimport gradio as gr demo = gr.Interface(fn=your_function, ...) demo.launch(mcp_server=True) # ← that's it 🤯 https://t.co/x62qkRW5MD",
        "hot": "",
        "time": "2025-04-30 14:29:53",
        "timestamp": 1746023393000,
        "published": "2025-04-30 14:29:53",
        "desc": "Building an MCP Server with Gradio is out\nimport gradio as gr demo = gr.Interface(fn=your_function, ...) demo.launch(mcp_server=True) # ← that's it 🤯 https://t.co/x62qkRW5MD",
        "summary": "新闻介绍了如何使用Gradio构建MCP服务器，提供了一个简单的代码示例，并附有相关链接。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Last chance to apply to the @StanfordAILab Post...",
        "url": "https://x.com/StanfordHAI/status/1917587049185698188",
        "source": "Twitter-Stanford HAI",
        "content": "Last chance to apply to the @StanfordAILab Postdoctoral Fellows Program! Join @Stanford’s legacy of excellence in AI and machine learning, and collaborate with world-class experts in advancing cutting-edge research. Application ends today, April 30: https://t.co/zkub9ub4mP https://t.co/6NMonkntP3",
        "hot": "",
        "time": "2025-04-30 14:29:14",
        "timestamp": 1746023354000,
        "published": "2025-04-30 14:29:14",
        "desc": "Last chance to apply to the @StanfordAILab Postdoctoral Fellows Program! Join @Stanford’s legacy of excellence in AI and machine learning, and collaborate with world-class experts in advancing cutting-edge research. Application ends today, April 30: https://t.co/zkub9ub4mP https://t.co/6NMonkntP3",
        "summary": "斯坦福AI实验室（StanfordAILab）博士后研究员项目正在接受申请，截止日期为4月30日。该项目旨在吸引优秀人才参与人工智能和机器学习领域的前沿研究。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "We’re excited to announce the release of Qwen2....",
        "url": "https://x.com/Alibaba_Qwen/status/1917585963775320086",
        "source": "Twitter-Qwen",
        "content": "We’re excited to announce the release of Qwen2.5-Omni-3B, enabling developers with lightweight GPU accessibility!\n🔹 Compared to Qwen2.5-Omni-7B model, the 3B version achieves a remarkable 50%+ reduction 🚀 in VRAM consumption during long-context sequence processing (~25k https://t.co/jU7SyD91ph",
        "hot": "",
        "time": "2025-04-30 14:24:55",
        "timestamp": 1746023095000,
        "published": "2025-04-30 14:24:55",
        "desc": "We’re excited to announce the release of Qwen2.5-Omni-3B, enabling developers with lightweight GPU accessibility!\n🔹 Compared to Qwen2.5-Omni-7B model, the 3B version achieves a remarkable 50%+ reduction 🚀 in VRAM consumption during long-context sequence processing (~25k https://t.co/jU7SyD91ph",
        "summary": "Qwen2.5-Omni-3B模型发布，相比7B版本在长上下文序列处理时VRAM消耗减少50%以上，适合轻量级GPU使用。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "In-Context Edit\nEnabling Instructional Image E...",
        "url": "https://x.com/_akhaliq/status/1917585421325717571",
        "source": "Twitter-AK",
        "content": "In-Context Edit\nEnabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer https://t.co/s9jrW94ynn",
        "hot": "",
        "time": "2025-04-30 14:22:46",
        "timestamp": 1746022966000,
        "published": "2025-04-30 14:22:46",
        "desc": "In-Context Edit\nEnabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer https://t.co/s9jrW94ynn",
        "summary": "该新闻介绍了一种通过上下文生成实现指令图像编辑的技术，利用大规模扩散变换器模型进行图像编辑。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "love gmail design language consistency across t...",
        "url": "https://x.com/nathanbenaich/status/1917585301452775705",
        "source": "Twitter-Nathan Benaich",
        "content": "love gmail design language consistency across the product\nand the 2024 footer https://t.co/RJSYzD2ZoE",
        "hot": "",
        "time": "2025-04-30 14:22:17",
        "timestamp": 1746022937000,
        "published": "2025-04-30 14:22:17",
        "desc": "love gmail design language consistency across the product\nand the 2024 footer https://t.co/RJSYzD2ZoE",
        "summary": "新闻内容表达了对Gmail设计语言在整个产品中保持一致性的喜爱，并提到了2024年页脚的链接。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "NEW: Xiaomi releases MiMo-7B, a new language mo...",
        "url": "https://x.com/omarsar0/status/1917582720341008814",
        "source": "Twitter-elvis",
        "content": "NEW: Xiaomi releases MiMo-7B, a new language model for reasoning tasks.\nMiMo-7B is explicitly designed for advanced reasoning across math and code.\nDon't think I've seen too many good, SMALL reasoning models.\nHere is my quick recap: https://t.co/1Zl5vhbVqz",
        "hot": "",
        "time": "2025-04-30 14:12:02",
        "timestamp": 1746022322000,
        "published": "2025-04-30 14:12:02",
        "desc": "NEW: Xiaomi releases MiMo-7B, a new language model for reasoning tasks.\nMiMo-7B is explicitly designed for advanced reasoning across math and code.\nDon't think I've seen too many good, SMALL reasoning models.\nHere is my quick recap: https://t.co/1Zl5vhbVqz",
        "summary": "Xiaomi has released MiMo-7B, a new language model designed for advanced reasoning tasks in math and code.",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "https://t.co/IttJyF9Cou",
        "url": "https://x.com/tunguz/status/1917579736404066732",
        "source": "Twitter-Bojan Tunguz",
        "content": "https://t.co/IttJyF9Cou",
        "hot": "",
        "time": "2025-04-30 14:00:10",
        "timestamp": 1746021610000,
        "published": "2025-04-30 14:00:10",
        "desc": "https://t.co/IttJyF9Cou",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "The Leaderboard Illusion\nSingh et al.: https:/...",
        "url": "https://x.com/ceobillionaire/status/1917578172587033071",
        "source": "Twitter-AGI.Eth",
        "content": "The Leaderboard Illusion\nSingh et al.: https://t.co/MyRfZCjNjy\n#ArtificialIntelligence #DeepLearning #MachineLearning https://t.co/KdlCgulHHK",
        "hot": "",
        "time": "2025-04-30 13:53:57",
        "timestamp": 1746021237000,
        "published": "2025-04-30 13:53:57",
        "desc": "The Leaderboard Illusion\nSingh et al.: https://t.co/MyRfZCjNjy\n#ArtificialIntelligence #DeepLearning #MachineLearning https://t.co/KdlCgulHHK",
        "summary": "新闻标题为'The Leaderboard Illusion'，内容提及Singh等人的一项研究，并关联到人工智能、深度学习和机器学习领域。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Wish I could use full self driving to text and ...",
        "url": "https://x.com/Austen/status/1917575290584199508",
        "source": "Twitter-Austen Allred",
        "content": "Wish I could use full self driving to text and drive",
        "hot": "",
        "time": "2025-04-30 13:42:30",
        "timestamp": 1746020550000,
        "published": "2025-04-30 13:42:30",
        "desc": "Wish I could use full self driving to text and drive",
        "summary": "用户表达了希望在完全自动驾驶状态下能够进行文字输入和驾驶的愿望。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Intel’s chief commercial officer and sales lead...",
        "url": "https://x.com/Kyle_L_Wiggers/status/1917572030662074770",
        "source": "Twitter-Kyle Wiggers",
        "content": "Intel’s chief commercial officer and sales lead, Christoph Schell, resigns https://t.co/vrXGTpGeuD",
        "hot": "",
        "time": "2025-04-30 13:29:33",
        "timestamp": 1746019773000,
        "published": "2025-04-30 13:29:33",
        "desc": "Intel’s chief commercial officer and sales lead, Christoph Schell, resigns https://t.co/vrXGTpGeuD",
        "summary": "Intel的首席商业官兼销售负责人Christoph Schell辞职。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Supio, an AI-powered legal analysis platform, l...",
        "url": "https://x.com/Kyle_L_Wiggers/status/1917572029508624704",
        "source": "Twitter-Kyle Wiggers",
        "content": "Supio, an AI-powered legal analysis platform, lands $60M https://t.co/UcwuSbDdwz",
        "hot": "",
        "time": "2025-04-30 13:29:33",
        "timestamp": 1746019773000,
        "published": "2025-04-30 13:29:33",
        "desc": "Supio, an AI-powered legal analysis platform, lands $60M https://t.co/UcwuSbDdwz",
        "summary": "Supio，一个基于AI的法律分析平台，成功获得了6000万美元的资金。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Time Series Analysis with Spark — A practical g...",
        "url": "https://x.com/KirkDBorne/status/1917570382313447755",
        "source": "Twitter-Kirk Borne",
        "content": "Time Series Analysis with Spark — A practical guide to master the fundamentals of processing, modeling, and forecasting time series with Apache Spark: https://t.co/1dqgH7wrS6 by Databricks Senior Solutions Architect Yoni Ramaswami, from @PacktDataML #ad\n𝓚𝓮𝔂 𝓕𝓮𝓪𝓽𝓾𝓻𝓮𝓼: https://t.co/raS1rGzu70",
        "hot": "",
        "time": "2025-04-30 13:23:00",
        "timestamp": 1746019380000,
        "published": "2025-04-30 13:23:00",
        "desc": "Time Series Analysis with Spark — A practical guide to master the fundamentals of processing, modeling, and forecasting time series with Apache Spark: https://t.co/1dqgH7wrS6 by Databricks Senior Solutions Architect Yoni Ramaswami, from @PacktDataML #ad\n𝓚𝓮𝔂 𝓕𝓮𝓪𝓽𝓾𝓻𝓮𝓼: https://t.co/raS1rGzu70",
        "summary": "本文由Databricks高级解决方案架构师Yoni Ramaswami撰写，提供使用Apache Spark进行时间序列分析的实用指南，涵盖处理、建模和预测时间序列数据的方法。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "我们用3天时间给无忧渡制作了新的多重结结局，其实这是我一直感兴趣的事，AI让每个故事都能有平行...",
        "url": "https://x.com/hq4ai/status/1917568144295747907",
        "source": "Twitter-汗青 HQ",
        "content": "我们用3天时间给无忧渡制作了新的多重结结局，其实这是我一直感兴趣的事，AI让每个故事都能有平行宇宙的不同剧情走向。\n这次使用了即梦3.0视频和即梦AI的全站创作工具，确实非常方便 https://t.co/ABTE0uaYd1",
        "hot": "",
        "time": "2025-04-30 13:14:06",
        "timestamp": 1746018846000,
        "published": "2025-04-30 13:14:06",
        "desc": "我们用3天时间给无忧渡制作了新的多重结结局，其实这是我一直感兴趣的事，AI让每个故事都能有平行宇宙的不同剧情走向。\n这次使用了即梦3.0视频和即梦AI的全站创作工具，确实非常方便 https://t.co/ABTE0uaYd1",
        "summary": "新闻介绍了使用AI技术在3天内为游戏《无忧渡》制作了多重结局，利用即梦3.0视频和即梦AI的全站创作工具实现平行宇宙的不同剧情走向。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "We’re thrilled to announce the launch of Qwen 3...",
        "url": "https://x.com/togethercompute/status/1917566302455226622",
        "source": "Twitter-Together AI",
        "content": "We’re thrilled to announce the launch of Qwen 3 on Together AI.\nQwen3 235B A22B, a state of the art hybrid reasoning model, is now available on the Together API. It excels in tool calling, coding, multi-lingual tasks, math, and general tasks.\nLink & details below! https://t.co/xaeLc3g83y",
        "hot": "",
        "time": "2025-04-30 13:06:47",
        "timestamp": 1746018407000,
        "published": "2025-04-30 13:06:47",
        "desc": "We’re thrilled to announce the launch of Qwen 3 on Together AI.\nQwen3 235B A22B, a state of the art hybrid reasoning model, is now available on the Together API. It excels in tool calling, coding, multi-lingual tasks, math, and general tasks.\nLink & details below! https://t.co/xaeLc3g83y",
        "summary": "Together AI宣布推出Qwen3 235B A22B，这是一种先进的混合推理模型，擅长工具调用、编程、多语言任务、数学和通用任务，现已通过Together API提供。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "It’s official: @SAP Databricks is now GA on AWS...",
        "url": "https://x.com/databricks/status/1917566068194677137",
        "source": "Twitter-Databricks",
        "content": "It’s official: @SAP Databricks is now GA on AWS. SAP customers can now unlock data intelligence across their SAP data and external sources—enabling improved governance, advanced analytics, and AI use cases https://t.co/3PBn5ExZyu https://t.co/O9nUOLUt3b",
        "hot": "",
        "time": "2025-04-30 13:05:51",
        "timestamp": 1746018351000,
        "published": "2025-04-30 13:05:51",
        "desc": "It’s official: @SAP Databricks is now GA on AWS. SAP customers can now unlock data intelligence across their SAP data and external sources—enabling improved governance, advanced analytics, and AI use cases https://t.co/3PBn5ExZyu https://t.co/O9nUOLUt3b",
        "summary": "SAP Databricks现已在AWS上正式发布，使SAP客户能够整合SAP数据和外部数据源，实现更高级的数据分析和AI应用。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "If you’re picking your AI models based on publi...",
        "url": "https://x.com/ClementDelangue/status/1917565202633023505",
        "source": "Twitter-clem 🤗",
        "content": "If you’re picking your AI models based on public generalist leaderboards, you’re doing it wrong.\nIn my opinion, evaluation & model picking is at least 30% of the work of any great AI builder and it’s a mix of public generalist and specialized leaderboards, social signals (likes https://t.co/3vOHcLd657",
        "hot": "",
        "time": "2025-04-30 13:02:25",
        "timestamp": 1746018145000,
        "published": "2025-04-30 13:02:25",
        "desc": "If you’re picking your AI models based on public generalist leaderboards, you’re doing it wrong.\nIn my opinion, evaluation & model picking is at least 30% of the work of any great AI builder and it’s a mix of public generalist and specialized leaderboards, social signals (likes https://t.co/3vOHcLd657",
        "summary": "新闻指出，仅依据公共通用排行榜选择AI模型是错误的做法，强调评估和模型选择是AI开发中的重要部分，应结合公共和专业排行榜以及社交信号等多方面因素。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Length-Controlled AlpacaEval: A Simple Way to D...",
        "url": "https://x.com/ceobillionaire/status/1917563574836420950",
        "source": "Twitter-AGI.Eth",
        "content": "Length-Controlled AlpacaEval: A Simple Way to Debias Automatic Evaluators\nDubois et al.: https://t.co/UcKX6P0lYS\n#ArtificialIntelligence #DeepLearning #MachineLearning https://t.co/gP3n6vucjl",
        "hot": "",
        "time": "2025-04-30 12:55:57",
        "timestamp": 1746017757000,
        "published": "2025-04-30 12:55:57",
        "desc": "Length-Controlled AlpacaEval: A Simple Way to Debias Automatic Evaluators\nDubois et al.: https://t.co/UcKX6P0lYS\n#ArtificialIntelligence #DeepLearning #MachineLearning https://t.co/gP3n6vucjl",
        "summary": "新闻介绍了一种名为Length-Controlled AlpacaEval的方法，用于减少自动评估器的偏见。该研究由Dubois等人发表，涉及人工智能和机器学习领域。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "DeepSeek upgrades its math-focused AI model Pro...",
        "url": "https://x.com/Kyle_L_Wiggers/status/1917561970871406945",
        "source": "Twitter-Kyle Wiggers",
        "content": "DeepSeek upgrades its math-focused AI model Prover https://t.co/AX2dWe1EOq",
        "hot": "",
        "time": "2025-04-30 12:49:35",
        "timestamp": 1746017375000,
        "published": "2025-04-30 12:49:35",
        "desc": "DeepSeek upgrades its math-focused AI model Prover https://t.co/AX2dWe1EOq",
        "summary": "DeepSeek has upgraded its math-focused AI model called Prover.",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Overall, our work suggests that engagement from...",
        "url": "https://x.com/sarahookr/status/1917556470528500060",
        "source": "Twitter-Sara Hooker",
        "content": "Overall, our work suggests that engagement from a handful of providers and preferential policies from @lmarena_ai towards the same small group have created conditions to overfit to Arena-specific dynamics rather than general model quality.\nI remain optimistic this can be fixed. https://t.co/edVmzBALvU",
        "hot": "",
        "time": "2025-04-30 12:27:43",
        "timestamp": 1746016063000,
        "published": "2025-04-30 12:27:43",
        "desc": "Overall, our work suggests that engagement from a handful of providers and preferential policies from @lmarena_ai towards the same small group have created conditions to overfit to Arena-specific dynamics rather than general model quality.\nI remain optimistic this can be fixed. https://t.co/edVmzBALvU",
        "summary": "该新闻指出，由于少数提供者和@lmarena_ai的偏好政策，导致模型过度适应Arena特定动态，而非普遍模型质量。作者对此仍持乐观态度，并提供了相关链接。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Run this command to get the first clue of a sca...",
        "url": "https://x.com/svpino/status/1917553670667002088",
        "source": "Twitter-Santiago",
        "content": "Run this command to get the first clue of a scavenger hunt and have some fun:\n$ curl -L squ .re/the-great-code-chase\n(Remove the space between \"squ\" and \".re\"):\nThis is for software developers, but feel free to join if you want to have some fun, explore the API, win some https://t.co/V5S0sTnqu5",
        "hot": "",
        "time": "2025-04-30 12:16:36",
        "timestamp": 1746015396000,
        "published": "2025-04-30 12:16:36",
        "desc": "Run this command to get the first clue of a scavenger hunt and have some fun:\n$ curl -L squ .re/the-great-code-chase\n(Remove the space between \"squ\" and \".re\"):\nThis is for software developers, but feel free to join if you want to have some fun, explore the API, win some https://t.co/V5S0sTnqu5",
        "summary": "新闻内容提供了一个命令，用于参与一个寻宝游戏，参与者可以通过执行该命令获取线索并探索API，活动主要面向软件开发者。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Catfishing with AI is absolutely nuts. https://...",
        "url": "https://x.com/tunguz/status/1917553285885747314",
        "source": "Twitter-Bojan Tunguz",
        "content": "Catfishing with AI is absolutely nuts. https://t.co/bMIyyHiso4",
        "hot": "",
        "time": "2025-04-30 12:15:04",
        "timestamp": 1746015304000,
        "published": "2025-04-30 12:15:04",
        "desc": "Catfishing with AI is absolutely nuts. https://t.co/bMIyyHiso4",
        "summary": "新闻标题指出使用AI进行猫钓鱼（网络欺骗）令人震惊，并附有相关链接。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "It is critical for scientific integrity that we...",
        "url": "https://x.com/sarahookr/status/1917547727715721632",
        "source": "Twitter-Sara Hooker",
        "content": "It is critical for scientific integrity that we trust our measure of progress.\nThe @lmarena_ai has become the go-to evaluation for AI progress.\nOur release today demonstrates the difficulty in maintaining fair evaluations on @lmarena_ai, despite best intentions. https://t.co/dHjLF5hI1u",
        "hot": "",
        "time": "2025-04-30 11:52:59",
        "timestamp": 1746013979000,
        "published": "2025-04-30 11:52:59",
        "desc": "It is critical for scientific integrity that we trust our measure of progress.\nThe @lmarena_ai has become the go-to evaluation for AI progress.\nOur release today demonstrates the difficulty in maintaining fair evaluations on @lmarena_ai, despite best intentions. https://t.co/dHjLF5hI1u",
        "summary": "新闻强调了科学诚信的重要性，并指出@lmarena_ai已成为评估AI进展的主要工具。今日发布的消息展示了在@lmarena_ai上保持公平评估的难度。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "✨ Introducing Instant Film Effect🎉\n🏞️Travel sho...",
        "url": "https://x.com/Kling_ai/status/1917535126592053377",
        "source": "Twitter-Kling AI",
        "content": "✨ Introducing Instant Film Effect🎉\n🏞️Travel shots, 👫 group photos, 🐶 pet smiles—Bring Your Moments to Life in 3D Polaroid Style!\n#KlingAI #InstantFilmEffect https://t.co/1MGVD2JLew",
        "hot": "",
        "time": "2025-04-30 11:02:54",
        "timestamp": 1746010974000,
        "published": "2025-04-30 11:02:54",
        "desc": "✨ Introducing Instant Film Effect🎉\n🏞️Travel shots, 👫 group photos, 🐶 pet smiles—Bring Your Moments to Life in 3D Polaroid Style!\n#KlingAI #InstantFilmEffect https://t.co/1MGVD2JLew",
        "summary": "新闻介绍了KlingAI推出的Instant Film Effect功能，可以将旅行照、宠物照等照片转换为3D宝丽来风格，增强照片的视觉效果。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "GM 👁️✨",
        "url": "https://x.com/ceobillionaire/status/1917533050302337497",
        "source": "Twitter-AGI.Eth",
        "content": "GM 👁️✨",
        "hot": "",
        "time": "2025-04-30 10:54:39",
        "timestamp": 1746010479000,
        "published": "2025-04-30 10:54:39",
        "desc": "GM 👁️✨",
        "summary": "[摘要无法生成：无内容或来源信息不足]",
        "is_tech": true,
        "summary_source": "无内容",
        "is_processed": true
    },
    {
        "title": "Morgan Stanley projects humanoid revenues will ...",
        "url": "https://x.com/azeem/status/1917519307850014854",
        "source": "Twitter-Azeem Azhar",
        "content": "Morgan Stanley projects humanoid revenues will explode from effectively zero today to $4.7 trillion by 2050—roughly equivalent to Japan’s current GDP.\nLow-income countries barely register on this chart, suggesting a new dimension of global inequality forming around physical https://t.co/WZ5H9uJ5bC",
        "hot": "",
        "time": "2025-04-30 10:00:03",
        "timestamp": 1746007203000,
        "published": "2025-04-30 10:00:03",
        "desc": "Morgan Stanley projects humanoid revenues will explode from effectively zero today to $4.7 trillion by 2050—roughly equivalent to Japan’s current GDP.\nLow-income countries barely register on this chart, suggesting a new dimension of global inequality forming around physical https://t.co/WZ5H9uJ5bC",
        "summary": "摩根士丹利预测人形机器人收入将从目前的几乎为零增长到2050年的4.7万亿美元，相当于日本当前的GDP。低收入国家在这一增长中几乎不占份额，可能加剧全球不平等。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "Meta released Llama Guard 4 and new Prompt Guar...",
        "url": "https://x.com/mervenoyann/status/1917503204826255730",
        "source": "Twitter-merve",
        "content": "Meta released Llama Guard 4 and new Prompt Guard 2 models 🔥\nLlama Guard 4 is a new model to filter model inputs/outputs both text-only and image 🛡️ use it before and after LLMs/VLMs!\nPrompt Guard 2 22M & 86M are smol models to prevent model jailbreaks and prompt injections ⚔ https://t.co/Txd8RtPheT",
        "hot": "",
        "time": "2025-04-30 08:56:04",
        "timestamp": 1746003364000,
        "published": "2025-04-30 08:56:04",
        "desc": "Meta released Llama Guard 4 and new Prompt Guard 2 models 🔥\nLlama Guard 4 is a new model to filter model inputs/outputs both text-only and image 🛡️ use it before and after LLMs/VLMs!\nPrompt Guard 2 22M & 86M are smol models to prevent model jailbreaks and prompt injections ⚔ https://t.co/Txd8RtPheT",
        "summary": "Meta发布了Llama Guard 4和Prompt Guard 2模型，用于过滤文本和图像输入输出，并防止模型被破解和注入提示。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "我去，来了朋友们！\nDeepseek 开源 DeepSeek-Prover-V2-671B ...",
        "url": "https://x.com/op7418/status/1917502410827915270",
        "source": "Twitter-歸藏(guizang.ai)",
        "content": "我去，来了朋友们！\nDeepseek 开源 DeepSeek-Prover-V2-671B 模型\n看起来像是一个数学证明或者推理模型？ https://t.co/iLdiHAlgcG",
        "hot": "",
        "time": "2025-04-30 08:52:54",
        "timestamp": 1746003174000,
        "published": "2025-04-30 08:52:54",
        "desc": "我去，来了朋友们！\nDeepseek 开源 DeepSeek-Prover-V2-671B 模型\n看起来像是一个数学证明或者推理模型？ https://t.co/iLdiHAlgcG",
        "summary": "Deepseek 开源了 DeepSeek-Prover-V2-671B 模型，该模型可能用于数学证明或推理。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "提示词，只需要改 json 部分自己的信息就行：\n帮我生成一只手（主要是拇指和食指）正捏着一...",
        "url": "https://x.com/op7418/status/1917499615257190573",
        "source": "Twitter-歸藏(guizang.ai)",
        "content": "提示词，只需要改 json 部分自己的信息就行：\n帮我生成一只手（主要是拇指和食指）正捏着一张名片的 2:3 照片。\n名片设计：这张卡片并非传统名片样式，而是设计成了一个深色背景的计算机程序代码编辑器的窗口界面。\n窗口元素：\n- 顶部：左上角有三个模拟窗口控制按钮（红、黄、绿），中间是窗口标题",
        "hot": "",
        "time": "2025-04-30 08:41:48",
        "timestamp": 1746002508000,
        "published": "2025-04-30 08:41:48",
        "desc": "提示词，只需要改 json 部分自己的信息就行：\n帮我生成一只手（主要是拇指和食指）正捏着一张名片的 2:3 照片。\n名片设计：这张卡片并非传统名片样式，而是设计成了一个深色背景的计算机程序代码编辑器的窗口界面。\n窗口元素：\n- 顶部：左上角有三个模拟窗口控制按钮（红、黄、绿），中间是窗口标题",
        "summary": "新闻内容描述了一张由AI生成的照片，展示了一只手捏着一张特殊设计的名片，名片呈现为深色背景的代码编辑器界面，包含窗口控制按钮和标题。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    },
    {
        "title": "A research project related to sycophancy: defin...",
        "url": "https://x.com/johnschulman2/status/1917487672983183433",
        "source": "Twitter-John Schulman",
        "content": "A research project related to sycophancy: define explicit features like \"does the response agree with the user\" as in https://t.co/Ev5Q2PrpjK, and then construct a preference function that subtracts out their effect, as in https://t.co/kEaBgqar9V. I.e., remove some bad causal",
        "hot": "",
        "time": "2025-04-30 07:54:21",
        "timestamp": 1745999661000,
        "published": "2025-04-30 07:54:21",
        "desc": "A research project related to sycophancy: define explicit features like \"does the response agree with the user\" as in https://t.co/Ev5Q2PrpjK, and then construct a preference function that subtracts out their effect, as in https://t.co/kEaBgqar9V. I.e., remove some bad causal",
        "summary": "该研究项目探讨与阿谀奉承相关的特征，例如响应是否符合用户意愿，并构建偏好函数以消除这些影响，旨在去除某些不良因果关系。",
        "is_tech": true,
        "summary_source": "AI生成",
        "is_processed": true
    }
]