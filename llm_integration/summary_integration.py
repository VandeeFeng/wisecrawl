import os
import json
import time
import logging
import requests
from datetime import datetime
from config.config import SOURCE_NAME_MAP
from utils.utils import format_title_for_display

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

def summarize_with_deepseek(hotspots, api_key, api_url=None, model_id=None, max_retries=3, tech_only=False):
    """
    ä½¿ç”¨Deepseek APIå¯¹çƒ­ç‚¹è¿›è¡Œæ±‡æ€»å½’ç±»ï¼Œæ”¯æŒé‡è¯•
    æ ¹æ®tech_onlyå‚æ•°ä½¿ç”¨ä¸åŒçš„prompt
    """
    if api_url is None:
        api_url = "http://127.0.0.1:11434/v1/chat/completions"
    
    if model_id is None:
        model_id = "deepseek-r1:14b"
    
    retry_count = 0
    while retry_count < max_retries:
        try:
            # ç®€åŒ–è¾“å…¥æ•°æ®ï¼Œåªä¼ é€’å¿…è¦ä¿¡æ¯ï¼Œä½†åŒ…å«æ‘˜è¦
            simplified_hotspots = []
            for idx, item in enumerate(hotspots):
                source_name = SOURCE_NAME_MAP.get(item['source'], item['source'])
                simplified_hotspots.append({
                    "id": idx,
                    "title": item['title'],
                    "source": source_name,
                    "summary": item.get('summary', '')  # æ·»åŠ æ‘˜è¦ä¿¡æ¯
                })
            
            # å°†å®Œæ•´æ•°æ®è½¬æ¢ä¸ºå­—å…¸ä»¥ä¾¿åç»­æŸ¥æ‰¾
            hotspot_dict = {idx: item for idx, item in enumerate(hotspots)}
            
            # è½¬æ¢ä¸ºJSONæ ¼å¼çš„è¾“å…¥
            hotspot_json = json.dumps(simplified_hotspots, ensure_ascii=False)
            
            # ä¿å­˜è¾“å…¥çš„JSONæ•°æ®ï¼Œä½¿ç”¨ç›¸å¯¹è·¯å¾„
            save_directory = os.path.join("data", "inputs")
            os.makedirs(save_directory, exist_ok=True)
            today = datetime.now().strftime("%Y-%m-%d")
            timestamp = datetime.now().strftime("%H-%M-%S")
            input_filename = os.path.join(save_directory, f"deepseek_input_{today}_{timestamp}.json")
            with open(input_filename, 'w', encoding='utf-8') as f:
                f.write(hotspot_json)
            logger.info(f"å·²ä¿å­˜Deepseekè¾“å…¥æ•°æ®è‡³ {input_filename}")
            
            # æ ¹æ®tech_onlyå‚æ•°é€‰æ‹©ä¸åŒçš„prompt
            if tech_only:
                prompt = f"""
                ä»¥ä¸‹æ˜¯ä»Šæ—¥ç§‘æŠ€çƒ­ç‚¹ä¿¡æ¯åˆ—è¡¨ï¼ˆåŒ…å«æ–°é—»å’Œç¤¾äº¤åª’ä½“å¸–å­ï¼ŒJSONæ ¼å¼ï¼‰ï¼Œéƒ¨åˆ†æ¡ç›®åŒ…å«å†…å®¹æ‘˜è¦ï¼š
                {hotspot_json}
                è¯·æ€»ç»“å‡º10æ¡æœ€é‡è¦çš„ç§‘æŠ€æ–°é—»ï¼Œä¼˜å…ˆé€‰æ‹©AIç›¸å…³æ–°é—»ï¼Œå»é™¤é‡å¤å’Œæ— å…³å†…å®¹ã€‚
                é‡ç‚¹å…³æ³¨æœ€æ–°å‘å¸ƒçš„AIæŠ€æœ¯æˆ–è€…æ¨¡å‹ç­‰ï¼Œç›¸å…³æ–°é—»åœ¨è¿”å›çš„ç»“æœæ’åºä¸­éœ€è¦å‰ç½®ï¼›å…¬ä¼—å·çš„æ–‡ç« æƒé‡æ›´é«˜ï¼Œå…¶ä½™ç»“æœæŒ‰é‡è¦æ€§æ’åºã€‚
                ä½ éœ€è¦å°†ç›¸ä¼¼çš„æ–°é—»åˆå¹¶ä¸ºä¸€æ¡ï¼Œå¹¶æä¾›ä¸€ä¸ªç›´è§‚ç®€æ´çš„ä¸­æ–‡æ ‡é¢˜ï¼Œéœ€è¦è®²æ¸…æ¥šæ–°é—»å†…å®¹ä¸è¦å¤ªæ³›åŒ–ï¼ˆä¸è¶…è¿‡30ä¸ªå­—ï¼‰ã€‚
                åŒæ—¶ï¼Œä¹Ÿè¯·å…³æ³¨æ¥è‡ª Twitter ç­‰ç¤¾äº¤åª’ä½“æº (source: Twitter) çš„é‡è¦ä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯å…³äºæœ€æ–° AI æŠ€æœ¯çªç ´ã€æ¨¡å‹å‘å¸ƒæˆ–é‡è¦è¡Œä¸šåŠ¨æ€çš„å¸–å­ï¼Œå®ƒä»¬åŒæ ·å…·æœ‰å¾ˆé«˜çš„ä»·å€¼ã€‚
                ç›¸å…³æ–°é—»çš„IDåˆ—è¡¨æœ€å¤šé€‰æ‹©å…¶ä¸­4æ¡ï¼Œå–æœ€å…¸å‹çš„ï¼Œè¶…è¿‡æ•°é‡ä¸éœ€è¦å…¨éƒ¨ç»™å‡ºã€‚è¯·ç‰¹åˆ«æ³¨æ„ï¼Œå¦‚æœåŒä¸€å®¶åª’ä½“åœ¨å¤šä¸ªæ¸ é“å‘å¸ƒç›¸åŒçš„å†…å®¹ï¼Œæˆ–æ–°é—»æ ‡é¢˜ç›¸ä¼¼åº¦æé«˜ï¼Œä¸è¦åŒæ—¶é€‰æ‹©ï¼Œåˆ™ä»…éœ€åˆ—å‡º1æ¡å³å¯ã€‚
                å¦‚æœæœ‰æ‘˜è¦ä¿¡æ¯ï¼Œè¯·å‚è€ƒæ‘˜è¦æä¾›æ›´å‡†ç¡®çš„æ ‡é¢˜ã€‚
                
                è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
                ```json
                [
                  {{
                    "title": "çƒ­ç‚¹æ ‡é¢˜",
                    "related_ids": [ç›¸å…³çƒ­ç‚¹çš„IDåˆ—è¡¨]
                  }},
                  ...
                ]
                ```
                
                åªè¿”å›JSONæ•°æ®ï¼Œä¸è¦æœ‰ä»»ä½•é¢å¤–è¯´æ˜ã€‚
                """
            else:
                prompt = f"""
                ä»¥ä¸‹æ˜¯ä»Šæ—¥çƒ­ç‚¹ä¿¡æ¯åˆ—è¡¨ï¼ˆåŒ…å«æ–°é—»å’Œç¤¾äº¤åª’ä½“å¸–å­ï¼ŒJSONæ ¼å¼ï¼‰ï¼Œéƒ¨åˆ†æ¡ç›®åŒ…å«å†…å®¹æ‘˜è¦ï¼š
                {hotspot_json}
                è¯·æ€»ç»“å‡º10æ¡æœ€é‡è¦çš„çƒ­ç‚¹æ–°é—»ï¼Œä¼˜å…ˆé€‰æ‹©ç§‘æŠ€å’ŒAIç›¸å…³æ–°é—»ï¼Œä½†ä¹Ÿè¦åŒ…å«å…¶ä»–é¢†åŸŸï¼ˆå¦‚ç¤¾ä¼šã€å¨±ä¹ã€ä½“è‚²ç­‰ï¼‰çš„é‡è¦æ–°é—»ï¼Œå»é™¤é‡å¤å†…å®¹ã€‚
                ä½ éœ€è¦å°†ç›¸ä¼¼çš„æ–°é—»åˆå¹¶ä¸ºä¸€æ¡ï¼Œå¹¶æä¾›ä¸€ä¸ªç›´è§‚ç®€æ´çš„ä¸­æ–‡æ ‡é¢˜ï¼Œéœ€è¦è®²æ¸…æ¥šæ–°é—»å†…å®¹ä¸è¦å¤ªæ³›åŒ–ï¼ˆä¸è¶…è¿‡30ä¸ªå­—ï¼‰ã€‚
                åŒæ—¶ï¼Œä¹Ÿè¯·å…³æ³¨æ¥è‡ª Twitter ç­‰ç¤¾äº¤åª’ä½“æº (source: Twitter) çš„é‡è¦ä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯å…³äºæœ€æ–° AI æŠ€æœ¯çªç ´ã€æ¨¡å‹å‘å¸ƒæˆ–é‡è¦è¡Œä¸šåŠ¨æ€çš„å¸–å­ï¼Œå°†å®ƒä»¬ä¸æ–°é—»åŒç­‰å¯¹å¾…è¿›è¡Œç­›é€‰å’Œæ€»ç»“ã€‚
                ç›¸å…³æ–°é—»çš„IDåˆ—è¡¨æœ€å¤šé€‰æ‹©å…¶ä¸­4æ¡ï¼Œå–æœ€å…¸å‹çš„ï¼Œè¶…è¿‡æ•°é‡ä¸éœ€è¦å…¨éƒ¨ç»™å‡ºã€‚è¯·ç‰¹åˆ«æ³¨æ„ï¼Œå¦‚æœåŒä¸€å®¶åª’ä½“åœ¨å¤šä¸ªæ¸ é“å‘å¸ƒç›¸åŒçš„å†…å®¹ï¼Œæˆ–æ–°é—»æ ‡é¢˜ç›¸ä¼¼åº¦æé«˜ï¼Œä¸è¦åŒæ—¶é€‰æ‹©ï¼Œåˆ™ä»…éœ€åˆ—å‡º1æ¡å³å¯ã€‚
                å¦‚æœæœ‰æ‘˜è¦ä¿¡æ¯ï¼Œè¯·å‚è€ƒæ‘˜è¦æä¾›æ›´å‡†ç¡®çš„æ ‡é¢˜ã€‚
                
                è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
                ```json
                [
                  {{
                    "title": "çƒ­ç‚¹æ ‡é¢˜",
                    "related_ids": [ç›¸å…³çƒ­ç‚¹çš„IDåˆ—è¡¨]
                  }},
                  ...
                ]
                ```
                
                åªè¿”å›JSONæ•°æ®ï¼Œä¸è¦æœ‰ä»»ä½•é¢å¤–è¯´æ˜ã€‚
                """
            
            # è°ƒç”¨Deepseek API
            try:
                logger.info(f"æ­£åœ¨è°ƒç”¨ Deepseek APIï¼Œå°è¯•æ¬¡æ•°: {retry_count + 1}/{max_retries}")
                
                # å®šä¹‰payload
                payload = {
                    "model": model_id,
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»ç¼–è¾‘åŠ©æ‰‹ï¼Œæ“…é•¿å½’çº³æ€»ç»“çƒ­ç‚¹æ–°é—»ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": 0.3,
                    "max_tokens": 1000
                }
                
                # ä½¿ç”¨subprocessè°ƒç”¨curlå‘½ä»¤ï¼Œå®Œå…¨ç»•è¿‡Pythonçš„HTTPå®¢æˆ·ç«¯
                import subprocess
                import tempfile
                
                # å°†payloadè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
                payload_json = json.dumps(payload, ensure_ascii=False)
                
                # åˆ›å»ºä¸´æ—¶æ–‡ä»¶å­˜å‚¨è¯·æ±‚ä½“
                with tempfile.NamedTemporaryFile(mode='w+', encoding='utf-8', suffix='.json', delete=False) as temp:
                    temp_path = temp.name
                    temp.write(payload_json)
                
                try:
                    # æ„å»ºcurlå‘½ä»¤
                    curl_cmd = [
                        'curl', '-s', '-X', 'POST',
                        '-H', f'Authorization: Bearer {api_key}',
                        '-H', 'Content-Type: application/json',
                        '-d', f'@{temp_path}',
                        '--insecure',  # å¿½ç•¥SSLè¯ä¹¦éªŒè¯
                        api_url
                    ]
                    
                    logger.info(f"æ‰§è¡Œcurlå‘½ä»¤: {' '.join(curl_cmd).replace(api_key, '***')}")
                    
                    # æ‰§è¡Œcurlå‘½ä»¤
                    process = subprocess.run(
                        curl_cmd,
                        check=True,
                        capture_output=True,
                        text=True,
                        encoding='utf-8'
                    )
                    
                    # æ£€æŸ¥è¿”å›ç 
                    if process.returncode != 0:
                        raise Exception(f"curlå‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {process.returncode}, é”™è¯¯: {process.stderr}")
                    
                    # è§£æJSONå“åº”
                    result = json.loads(process.stdout)
                    
                    # ç¡®è®¤å“åº”æ ¼å¼
                    if "choices" not in result or len(result["choices"]) == 0:
                        raise Exception(f"APIå“åº”æ ¼å¼ä¸æ­£ç¡®: {process.stdout[:200]}...")
                    
                    logger.info("APIè°ƒç”¨æˆåŠŸ!")
                    
                finally:
                    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                    try:
                        os.unlink(temp_path)
                    except:
                        pass
                
            except Exception as e:
                logger.error(f"è°ƒç”¨Deepseek APIæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                logger.error(f"é”™è¯¯ç±»å‹: {type(e)}")
                
                # è®°å½•æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                import traceback
                logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                
                retry_count += 1
                if retry_count < max_retries:
                    logger.info(f"å°†åœ¨3ç§’åé‡è¯•...")
                    time.sleep(3)
                    continue
                else:
                    raise
            
            # æå–å›å¤å†…å®¹
            json_response = result["choices"][0]["message"]["content"]
            
            # æå–JSONéƒ¨åˆ†
            json_str = json_response
            if "```json" in json_response:
                json_str = json_response.split("```json")[1].split("```")[0].strip()
            
            # ä¿å­˜Deepseekçš„å®Œæ•´å“åº”ç»“æœ
            output_directory = os.path.join("data", "outputs")
            os.makedirs(output_directory, exist_ok=True)
            
            # ä¿å­˜åŸå§‹å“åº”
            raw_output_filename = os.path.join(output_directory, f"deepseek_raw_response_{today}_{timestamp}.json")
            with open(raw_output_filename, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            logger.info(f"å·²ä¿å­˜DeepseekåŸå§‹å“åº”è‡³ {raw_output_filename}")
            
            # ä¿å­˜å¤„ç†åçš„JSONè¾“å‡º
            output_filename = os.path.join(output_directory, f"deepseek_output_{today}_{timestamp}.json")
            with open(output_filename, 'w', encoding='utf-8') as f:
                f.write(json_str)
            logger.info(f"å·²ä¿å­˜Deepseekè¾“å‡ºæ•°æ®è‡³ {output_filename}")
            
            # è§£æJSON
            try:
                news_items = json.loads(json_str)
                
                # æ ¹æ®JSONæ„å»ºæœ€ç»ˆè¾“å‡º
                formatted_summary = ""
                for index, news in enumerate(news_items[:20]):
                    num = str(index + 1).zfill(2)
                    title = news.get("title", "æœªçŸ¥æ ‡é¢˜")
                    
                    formatted_summary += f"## ** {num} {title} **  \n"
                    
                    # ç”Ÿæˆæ¯ä¸ªæ¡ç›®çš„æ‘˜è¦ (ä¸è¶…è¿‡100å­—)
                    news_summary = ""
                    related_ids = news.get("related_ids", [])
                    
                    # æ”¶é›†æ‰€æœ‰ç›¸å…³æ–°é—»çš„æ‘˜è¦
                    all_summaries = []
                    for news_id in related_ids:
                        if news_id in hotspot_dict:
                            item = hotspot_dict[news_id]
                            if item.get("summary") and len(item.get("summary").strip()) > 20:  # åªä½¿ç”¨æœ‰æ„ä¹‰çš„æ‘˜è¦
                                all_summaries.append(item.get("summary"))
                    
                    # å¦‚æœæœ‰æ‘˜è¦ï¼Œä½¿ç”¨æœ€é•¿/æœ€è¯¦ç»†çš„é‚£ä¸ª
                    if all_summaries:
                        # æŒ‰é•¿åº¦æ’åºï¼Œé€‰æ‹©æœ€é•¿çš„æ‘˜è¦ï¼ˆé€šå¸¸åŒ…å«æ›´å¤šä¿¡æ¯ï¼‰
                        best_summary = sorted(all_summaries, key=len, reverse=True)[0]
                        if len(best_summary) > 100:
                            news_summary = best_summary[:97] + "..."
                        else:
                            news_summary = best_summary
                    
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ‘˜è¦ï¼Œç”Ÿæˆä¸€ä¸ªåŸºæœ¬æè¿°
                    if not news_summary:
                        # å°è¯•ä»æ ‡é¢˜ç”Ÿæˆç®€è¦æè¿°
                        news_summary = f"{title}ç›¸å…³ä¿¡æ¯ï¼Œè¯¦æƒ…è¯·æŸ¥çœ‹ä»¥ä¸‹é“¾æ¥ã€‚"
                    
                    # æ·»åŠ æ‘˜è¦åˆ°è¾“å‡º
                    formatted_summary += f"{news_summary}\n\n"
                    
                    # æ·»åŠ ç›¸å…³é“¾æ¥ï¼Œç¡®ä¿URLæ­£ç¡®
                    for news_id in related_ids:
                        if news_id in hotspot_dict:
                            item = hotspot_dict[news_id]
                            source_name = SOURCE_NAME_MAP.get(item.get('source', 'unknown'), item.get('source', 'unknown'))
                            item_title = item.get('title', 'æœªçŸ¥æ ‡é¢˜')
                            
                            # å¤„ç†æ ‡é¢˜ä¸­çš„æ¢è¡Œç¬¦å’Œå…¶ä»–ç‰¹æ®Šå­—ç¬¦ï¼Œé¿å…ç ´åMarkdownæ ¼å¼
                            item_title = item_title.replace('\n', ' ').replace('\r', ' ')
                            # ç§»é™¤å¤šä½™çš„ç©ºæ ¼
                            item_title = ' '.join(item_title.split())
                            
                            # ç¡®ä¿URLå­˜åœ¨ï¼Œå¦åˆ™ä½¿ç”¨å ä½ç¬¦
                            url = item.get('url', '#')
                            if not url or url == "#":
                                # å°è¯•æ„å»ºTwitter URL
                                if "Twitter" in source_name:
                                    # ä»sourceæå–ç”¨æˆ·åï¼Œå¹¶æ­£ç¡®å¤„ç†Twitterç”¨æˆ·åä¸­çš„ç©ºæ ¼
                                    username = source_name.replace("Twitter-", "").strip()
                                    username_no_space = username.replace(" ", "")  # ç§»é™¤ç©ºæ ¼
                                    
                                    # æ¨æ–‡URLæ ¼å¼åº”ä¸º https://twitter.com/username/status/tweet_id
                                    # ç”±äºæˆ‘ä»¬æ²¡æœ‰çœŸå®çš„tweet_idï¼Œæ‰€ä»¥åªèƒ½æŒ‡å‘ç”¨æˆ·ä¸»é¡µ
                                    url = f"https://twitter.com/{username_no_space}"
                                else:
                                    url = "#"  # é»˜è®¤å ä½ç¬¦
                            
                            # æ·»åŠ é“¾æ¥
                            formatted_summary += f"- [{item_title}]({url}) `ğŸ·ï¸{source_name}`\n"
                    
                    # æ·»åŠ ç©ºè¡Œåˆ†éš”
                    formatted_summary += "\n"
                
                # ä¿å­˜æ ¼å¼åŒ–åçš„æ‘˜è¦å†…å®¹
                summary_filename = os.path.join(output_directory, f"formatted_summary_{today}_{timestamp}.md")
                with open(summary_filename, 'w', encoding='utf-8') as f:
                    f.write(formatted_summary)
                logger.info(f"å·²ä¿å­˜æ ¼å¼åŒ–æ‘˜è¦è‡³ {summary_filename}")
                
                return formatted_summary
                
            except json.JSONDecodeError as e:
                logger.error(f"è§£æDeepseekè¿”å›çš„JSONå¤±è´¥: {str(e)}")
                return f"è§£æDeepseekè¿”å›çš„JSONå¤±è´¥: {str(e)}"
            
        except requests.exceptions.Timeout:
            retry_count += 1
            logger.warning(f"Deepseek API è¯·æ±‚è¶…æ—¶ï¼Œæ­£åœ¨é‡è¯• ({retry_count}/{max_retries})...")
            time.sleep(5)  # ç­‰å¾…5ç§’åé‡è¯•
        
        except Exception as e:
            logger.error(f"è°ƒç”¨Deepseek APIæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            logger.error(f"é”™è¯¯ç±»å‹: {type(e)}")
            logger.error(f"é”™è¯¯è¯¦æƒ…: {e.__dict__ if hasattr(e, '__dict__') else 'No details available'}")
            retry_count += 1
            if retry_count < max_retries:
                logger.warning(f"5ç§’åé‡è¯• ({retry_count}/{max_retries})...")
                time.sleep(5)
            else:
                break
    
    # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›å‰10æ¡çƒ­ç‚¹ä½œä¸ºå¤‡é€‰
    logger.warning("æ— æ³•ä½¿ç”¨Deepseek APIå½’ç±»çƒ­ç‚¹ï¼Œå°†ä½¿ç”¨åŸå§‹çƒ­ç‚¹")
    fallback = ""
    for i, item in enumerate(hotspots[:10]):
        try:
            num = str(i + 1).zfill(2)
            source_name = SOURCE_NAME_MAP.get(item.get('source', 'unknown'), item.get('source', 'unknown'))
            item_title = item.get('title', 'æœªçŸ¥æ ‡é¢˜')
            
            # å¤„ç†æ ‡é¢˜ä¸­çš„æ¢è¡Œç¬¦å’Œå…¶ä»–ç‰¹æ®Šå­—ç¬¦
            item_title = item_title.replace('\n', ' ').replace('\r', ' ')
            # ç§»é™¤å¤šä½™çš„ç©ºæ ¼
            item_title = ' '.join(item_title.split())
            
            # æ·»åŠ æ ‡é¢˜
            fallback += f"## ** {num} {item_title} **  \n"
            
            # æå–æ‘˜è¦
            item_summary = item.get('summary', '')
            if not item_summary:
                item_summary = f"{item_title}ç›¸å…³ä¿¡æ¯ï¼Œè¯¦æƒ…è¯·æŸ¥çœ‹ä»¥ä¸‹é“¾æ¥ã€‚"
            elif len(item_summary) > 100:
                item_summary = item_summary[:97] + "..."
            
            # æ·»åŠ æ‘˜è¦
            fallback += f"{item_summary}\n\n"
            
            # å®‰å…¨åœ°è®¿é—®URLï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨#
            url = item.get('url', '#')
            if not url or url == "#":
                # å°è¯•æ„å»ºTwitter URL
                if "Twitter" in source_name:
                    username = source_name.replace("Twitter-", "").strip()
                    username_no_space = username.replace(" ", "")  # ç§»é™¤ç©ºæ ¼
                    url = f"https://twitter.com/{username_no_space}"
            
            # æ·»åŠ é“¾æ¥
            fallback += f"- [{item_title}]({url}) `ğŸ·ï¸{source_name}` \n\n"
        except Exception as e:
            logger.error(f"å¤„ç†å¤‡é€‰çƒ­ç‚¹æ—¶å‡ºé”™(è·³è¿‡æ­¤æ¡): {str(e)}")
            continue
    
    return fallback